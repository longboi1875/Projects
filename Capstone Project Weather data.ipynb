{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statistics in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (1.0.3.5)\n",
      "Requirement already satisfied: docutils>=0.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from statistics) (0.15.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorflow in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (2.3.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from protobuf>=3.9.2->tensorflow) (46.1.3.post20200330)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.21.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.5.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!pip install statistics\n",
    "import statistics \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "keras = tf.keras\n",
    "df = pd.read_csv('Canadian_climate_history.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data, we can see it includes `LOCAL_DATE` column and the MEAN_TEMPERATURE and TOTAL_PRECIPITATION columns for many different canadian weather centers. However, we only need the `MEAN_TEMPERATURE_VANCOUVER` and `LOCAL_DATE` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCAL_DATE</th>\n",
       "      <th>MEAN_TEMPERATURE_CALGARY</th>\n",
       "      <th>TOTAL_PRECIPITATION_CALGARY</th>\n",
       "      <th>MEAN_TEMPERATURE_EDMONTON</th>\n",
       "      <th>TOTAL_PRECIPITATION_EDMONTON</th>\n",
       "      <th>MEAN_TEMPERATURE_HALIFAX</th>\n",
       "      <th>TOTAL_PRECIPITATION_HALIFAX</th>\n",
       "      <th>MEAN_TEMPERATURE_MONCTON</th>\n",
       "      <th>TOTAL_PRECIPITATION_MONCTON</th>\n",
       "      <th>MEAN_TEMPERATURE_MONTREAL</th>\n",
       "      <th>...</th>\n",
       "      <th>MEAN_TEMPERATURE_STJOHNS</th>\n",
       "      <th>TOTAL_PRECIPITATION_STJOHNS</th>\n",
       "      <th>MEAN_TEMPERATURE_TORONTO</th>\n",
       "      <th>TOTAL_PRECIPITATION_TORONTO</th>\n",
       "      <th>MEAN_TEMPERATURE_VANCOUVER</th>\n",
       "      <th>TOTAL_PRECIPITATION_VANCOUVER</th>\n",
       "      <th>MEAN_TEMPERATURE_WHITEHORSE</th>\n",
       "      <th>TOTAL_PRECIPITATION_WHITEHORSE</th>\n",
       "      <th>MEAN_TEMPERATURE_WINNIPEG</th>\n",
       "      <th>TOTAL_PRECIPITATION_WINNIPEG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-Jan-1940 00:00:00</td>\n",
       "      <td>-11.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.311584</td>\n",
       "      <td>1.246239</td>\n",
       "      <td>6.565997</td>\n",
       "      <td>3.976417</td>\n",
       "      <td>-8.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.675386</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00718</td>\n",
       "      <td>4.10222</td>\n",
       "      <td>-8.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>-0.41871</td>\n",
       "      <td>0.729778</td>\n",
       "      <td>-20.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02-Jan-1940 00:00:00</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.311584</td>\n",
       "      <td>1.246239</td>\n",
       "      <td>6.565997</td>\n",
       "      <td>3.976417</td>\n",
       "      <td>-14.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.675386</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00718</td>\n",
       "      <td>4.10222</td>\n",
       "      <td>-13.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.1</td>\n",
       "      <td>-0.41871</td>\n",
       "      <td>0.729778</td>\n",
       "      <td>-18.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-Jan-1940 00:00:00</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.311584</td>\n",
       "      <td>1.246239</td>\n",
       "      <td>6.565997</td>\n",
       "      <td>3.976417</td>\n",
       "      <td>-11.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.675386</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00718</td>\n",
       "      <td>4.10222</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.41871</td>\n",
       "      <td>0.729778</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04-Jan-1940 00:00:00</td>\n",
       "      <td>-11.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.311584</td>\n",
       "      <td>1.246239</td>\n",
       "      <td>6.565997</td>\n",
       "      <td>3.976417</td>\n",
       "      <td>-11.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.675386</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00718</td>\n",
       "      <td>4.10222</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.41871</td>\n",
       "      <td>0.729778</td>\n",
       "      <td>-20.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-Jan-1940 00:00:00</td>\n",
       "      <td>-13.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.311584</td>\n",
       "      <td>1.246239</td>\n",
       "      <td>6.565997</td>\n",
       "      <td>3.976417</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.675386</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00718</td>\n",
       "      <td>4.10222</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>16.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.41871</td>\n",
       "      <td>0.729778</td>\n",
       "      <td>-18.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>06-Jan-1940 00:00:00</td>\n",
       "      <td>-9.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.311584</td>\n",
       "      <td>1.246239</td>\n",
       "      <td>6.565997</td>\n",
       "      <td>3.976417</td>\n",
       "      <td>-11.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.675386</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00718</td>\n",
       "      <td>4.10222</td>\n",
       "      <td>-10.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.41871</td>\n",
       "      <td>0.729778</td>\n",
       "      <td>-18.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>07-Jan-1940 00:00:00</td>\n",
       "      <td>-11.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.311584</td>\n",
       "      <td>1.246239</td>\n",
       "      <td>6.565997</td>\n",
       "      <td>3.976417</td>\n",
       "      <td>-14.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.675386</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00718</td>\n",
       "      <td>4.10222</td>\n",
       "      <td>-18.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.41871</td>\n",
       "      <td>0.729778</td>\n",
       "      <td>-14.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08-Jan-1940 00:00:00</td>\n",
       "      <td>-11.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.311584</td>\n",
       "      <td>1.246239</td>\n",
       "      <td>6.565997</td>\n",
       "      <td>3.976417</td>\n",
       "      <td>-17.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.675386</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00718</td>\n",
       "      <td>4.10222</td>\n",
       "      <td>-14.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.41871</td>\n",
       "      <td>0.729778</td>\n",
       "      <td>-11.9</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>09-Jan-1940 00:00:00</td>\n",
       "      <td>-15.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.311584</td>\n",
       "      <td>1.246239</td>\n",
       "      <td>6.565997</td>\n",
       "      <td>3.976417</td>\n",
       "      <td>-13.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.675386</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00718</td>\n",
       "      <td>4.10222</td>\n",
       "      <td>-13.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>-0.41871</td>\n",
       "      <td>0.729778</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10-Jan-1940 00:00:00</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.311584</td>\n",
       "      <td>1.246239</td>\n",
       "      <td>6.565997</td>\n",
       "      <td>3.976417</td>\n",
       "      <td>-15.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.675386</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00718</td>\n",
       "      <td>4.10222</td>\n",
       "      <td>-9.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.41871</td>\n",
       "      <td>0.729778</td>\n",
       "      <td>-10.9</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             LOCAL_DATE  MEAN_TEMPERATURE_CALGARY  \\\n",
       "0  01-Jan-1940 00:00:00                     -11.4   \n",
       "1  02-Jan-1940 00:00:00                     -12.0   \n",
       "2  03-Jan-1940 00:00:00                     -12.0   \n",
       "3  04-Jan-1940 00:00:00                     -11.4   \n",
       "4  05-Jan-1940 00:00:00                     -13.1   \n",
       "5  06-Jan-1940 00:00:00                      -9.8   \n",
       "6  07-Jan-1940 00:00:00                     -11.4   \n",
       "7  08-Jan-1940 00:00:00                     -11.1   \n",
       "8  09-Jan-1940 00:00:00                     -15.6   \n",
       "9  10-Jan-1940 00:00:00                     -10.6   \n",
       "\n",
       "   TOTAL_PRECIPITATION_CALGARY  MEAN_TEMPERATURE_EDMONTON  \\\n",
       "0                          0.5                   2.311584   \n",
       "1                          0.5                   2.311584   \n",
       "2                          1.0                   2.311584   \n",
       "3                          0.8                   2.311584   \n",
       "4                          0.5                   2.311584   \n",
       "5                          0.0                   2.311584   \n",
       "6                          0.0                   2.311584   \n",
       "7                          1.0                   2.311584   \n",
       "8                          0.0                   2.311584   \n",
       "9                          1.3                   2.311584   \n",
       "\n",
       "   TOTAL_PRECIPITATION_EDMONTON  MEAN_TEMPERATURE_HALIFAX  \\\n",
       "0                      1.246239                  6.565997   \n",
       "1                      1.246239                  6.565997   \n",
       "2                      1.246239                  6.565997   \n",
       "3                      1.246239                  6.565997   \n",
       "4                      1.246239                  6.565997   \n",
       "5                      1.246239                  6.565997   \n",
       "6                      1.246239                  6.565997   \n",
       "7                      1.246239                  6.565997   \n",
       "8                      1.246239                  6.565997   \n",
       "9                      1.246239                  6.565997   \n",
       "\n",
       "   TOTAL_PRECIPITATION_HALIFAX  MEAN_TEMPERATURE_MONCTON  \\\n",
       "0                     3.976417                      -8.9   \n",
       "1                     3.976417                     -14.5   \n",
       "2                     3.976417                     -11.1   \n",
       "3                     3.976417                     -11.1   \n",
       "4                     3.976417                      -8.1   \n",
       "5                     3.976417                     -11.4   \n",
       "6                     3.976417                     -14.2   \n",
       "7                     3.976417                     -17.2   \n",
       "8                     3.976417                     -13.7   \n",
       "9                     3.976417                     -15.3   \n",
       "\n",
       "   TOTAL_PRECIPITATION_MONCTON  MEAN_TEMPERATURE_MONTREAL  ...  \\\n",
       "0                          0.0                   6.675386  ...   \n",
       "1                          0.0                   6.675386  ...   \n",
       "2                          0.0                   6.675386  ...   \n",
       "3                          0.3                   6.675386  ...   \n",
       "4                          0.0                   6.675386  ...   \n",
       "5                          3.8                   6.675386  ...   \n",
       "6                          0.0                   6.675386  ...   \n",
       "7                          0.0                   6.675386  ...   \n",
       "8                          0.3                   6.675386  ...   \n",
       "9                          0.0                   6.675386  ...   \n",
       "\n",
       "   MEAN_TEMPERATURE_STJOHNS  TOTAL_PRECIPITATION_STJOHNS  \\\n",
       "0                   5.00718                      4.10222   \n",
       "1                   5.00718                      4.10222   \n",
       "2                   5.00718                      4.10222   \n",
       "3                   5.00718                      4.10222   \n",
       "4                   5.00718                      4.10222   \n",
       "5                   5.00718                      4.10222   \n",
       "6                   5.00718                      4.10222   \n",
       "7                   5.00718                      4.10222   \n",
       "8                   5.00718                      4.10222   \n",
       "9                   5.00718                      4.10222   \n",
       "\n",
       "   MEAN_TEMPERATURE_TORONTO  TOTAL_PRECIPITATION_TORONTO  \\\n",
       "0                      -8.9                          0.0   \n",
       "1                     -13.1                          0.3   \n",
       "2                      -6.1                          0.0   \n",
       "3                      -6.4                          0.5   \n",
       "4                      -7.2                         16.5   \n",
       "5                     -10.3                          0.0   \n",
       "6                     -18.1                          0.0   \n",
       "7                     -14.5                          0.0   \n",
       "8                     -13.3                          0.3   \n",
       "9                      -9.2                          0.0   \n",
       "\n",
       "   MEAN_TEMPERATURE_VANCOUVER  TOTAL_PRECIPITATION_VANCOUVER  \\\n",
       "0                         8.9                            5.8   \n",
       "1                         9.7                            7.1   \n",
       "2                         7.8                            1.0   \n",
       "3                         8.1                            0.5   \n",
       "4                         7.0                            0.8   \n",
       "5                         5.0                            0.0   \n",
       "6                         1.4                            0.0   \n",
       "7                         1.2                            0.0   \n",
       "8                         2.2                            3.3   \n",
       "9                         2.5                            0.0   \n",
       "\n",
       "   MEAN_TEMPERATURE_WHITEHORSE  TOTAL_PRECIPITATION_WHITEHORSE  \\\n",
       "0                     -0.41871                        0.729778   \n",
       "1                     -0.41871                        0.729778   \n",
       "2                     -0.41871                        0.729778   \n",
       "3                     -0.41871                        0.729778   \n",
       "4                     -0.41871                        0.729778   \n",
       "5                     -0.41871                        0.729778   \n",
       "6                     -0.41871                        0.729778   \n",
       "7                     -0.41871                        0.729778   \n",
       "8                     -0.41871                        0.729778   \n",
       "9                     -0.41871                        0.729778   \n",
       "\n",
       "   MEAN_TEMPERATURE_WINNIPEG  TOTAL_PRECIPITATION_WINNIPEG  \n",
       "0                      -20.9                           0.0  \n",
       "1                      -18.4                           0.0  \n",
       "2                      -22.0                           0.0  \n",
       "3                      -20.3                           0.0  \n",
       "4                      -18.7                           0.0  \n",
       "5                      -18.6                           0.0  \n",
       "6                      -14.8                           0.0  \n",
       "7                      -11.9                           0.8  \n",
       "8                      -12.8                           0.5  \n",
       "9                      -10.9                           0.8  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(df.mean(), inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create `df_van` using the `LOCAL_DATE` and `MEAN_TEMP_VANCOUVER` columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCAL_DATE</th>\n",
       "      <th>MEAN_TEMPERATURE_VANCOUVER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-Jan-1940 00:00:00</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02-Jan-1940 00:00:00</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-Jan-1940 00:00:00</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04-Jan-1940 00:00:00</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-Jan-1940 00:00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29216</th>\n",
       "      <td>28-Dec-2019 00:00:00</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29217</th>\n",
       "      <td>29-Dec-2019 00:00:00</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29218</th>\n",
       "      <td>30-Dec-2019 00:00:00</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29219</th>\n",
       "      <td>31-Dec-2019 00:00:00</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29220</th>\n",
       "      <td>01-Jan-2020 00:00:00</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29221 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 LOCAL_DATE MEAN_TEMPERATURE_VANCOUVER\n",
       "0      01-Jan-1940 00:00:00                        8.9\n",
       "1      02-Jan-1940 00:00:00                        9.7\n",
       "2      03-Jan-1940 00:00:00                        7.8\n",
       "3      04-Jan-1940 00:00:00                        8.1\n",
       "4      05-Jan-1940 00:00:00                          7\n",
       "...                     ...                        ...\n",
       "29216  28-Dec-2019 00:00:00                        5.3\n",
       "29217  29-Dec-2019 00:00:00                        7.1\n",
       "29218  30-Dec-2019 00:00:00                        7.5\n",
       "29219  31-Dec-2019 00:00:00                        8.4\n",
       "29220  01-Jan-2020 00:00:00                        7.8\n",
       "\n",
       "[29221 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_van = (df['LOCAL_DATE'], df['MEAN_TEMPERATURE_VANCOUVER'])\n",
    "df_van = pd.DataFrame(df_van)\n",
    "df_van = df_van.transpose()\n",
    "df_van"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replace the nan values with the mean of the entire `MEAN_TEMPERATURE_VANCOUVER` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_van['MEAN_TEMPERATURE_VANCOUVER'].fillna((df['MEAN_TEMPERATURE_VANCOUVER'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also normalize the `MEAN_TEMPERATURE_VANCOUVER` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x, where x the 'scores' column's values as floats\n",
    "x = df[['MEAN_TEMPERATURE_VANCOUVER']].values.astype(float)\n",
    "\n",
    "# Create a minimum and maximum processor object\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Create an object to transform the data to fit minmax processor\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "# Run the normalizer on the dataframe\n",
    "df_van_normal = pd.DataFrame(x_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We give the normalized dataset the column names of the original non normalized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_van_normal['LOCAL_DATE'] = df_van['LOCAL_DATE']\n",
    "df_van_normal.columns = ['MEAN_TEMPERATURE_VANCOUVER', 'LOCAL_DATE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there is still one thing to do. We must make the `LOCAL_DATE` column the index, and change it to pandas datetime so its easier to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 29221 entries, 1940-01-01 to 2020-01-01\n",
      "Data columns (total 1 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   MEAN_TEMPERATURE_VANCOUVER  29221 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 456.6 KB\n"
     ]
    }
   ],
   "source": [
    "# convert the 'LOCAL_DATE' column to datetime format \n",
    "df_van_normal['LOCAL_DATE'] = pd.to_datetime(df['LOCAL_DATE'])\n",
    "# set the 'LOCAL_DATE' column as index\n",
    "df_van_normal.set_index('LOCAL_DATE', inplace=True)\n",
    "# Check the format of 'LOCAL_DATE' column \n",
    "df_van_normal.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see that the `LOCAL_DATE` is set to the pandas datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEAN_TEMPERATURE_VANCOUVER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOCAL_DATE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1940-01-01</th>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940-01-02</th>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940-01-03</th>\n",
       "      <td>0.519814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940-01-04</th>\n",
       "      <td>0.526807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940-01-05</th>\n",
       "      <td>0.501166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28</th>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29</th>\n",
       "      <td>0.503497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>0.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>0.533800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>0.519814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29221 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            MEAN_TEMPERATURE_VANCOUVER\n",
       "LOCAL_DATE                            \n",
       "1940-01-01                    0.545455\n",
       "1940-01-02                    0.564103\n",
       "1940-01-03                    0.519814\n",
       "1940-01-04                    0.526807\n",
       "1940-01-05                    0.501166\n",
       "...                                ...\n",
       "2019-12-28                    0.461538\n",
       "2019-12-29                    0.503497\n",
       "2019-12-30                    0.512821\n",
       "2019-12-31                    0.533800\n",
       "2020-01-01                    0.519814\n",
       "\n",
       "[29221 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_van_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to do the naive forecasting bit of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using matplot, we can visualize all the normalized data of vancouver temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the data \n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "# all data points\n",
    "df_van_normal.plot(title='Global active power', color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data is a bit much, so let's only see one year of the normalized mean temperatures in vancouver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# can plot a slice of daily data\n",
    "end_days = 365 # 1 year\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "df_van_normal[0:end_days].plot(title='Vancouver temperature', color='blue') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see 5 years of data to get more of a trend in the data. We can see that the temperature goes up by quite a bit in Summer, as expected and goes to a low in winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# can plot a slice of daily data\n",
    "end_days = 365*5 # 1 year*5 = 5 years\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "df_van_normal[0:end_days].plot(title='Vancouver temperature', color='blue') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Validation and Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a make_time_series function. It makes yearly time series using which we can train our machine learning models on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_time_series(df, years, freq='D', start_idx=0):\n",
    "    '''Creates as many time series as there are complete years. This code\n",
    "       accounts for the leap year, 2008.\n",
    "      :param mean_power_df: A dataframe of global power consumption, averaged by day.\n",
    "          This dataframe should also be indexed by a datetime.\n",
    "      :param years: A list of years to make time series out of, ex. ['2007', '2008'].\n",
    "      :param freq: The frequency of data recording (D = daily)\n",
    "      :param start_idx: The starting dataframe index of the first point in the first time series.\n",
    "          The default, 16, points to '2017-01-01'. \n",
    "      :return: A list of pd.Series(), time series data.\n",
    "      '''\n",
    "    \n",
    "    # store time series\n",
    "    time_series = []\n",
    "    \n",
    "    # store leap year in this dataset\n",
    "    leap = leap = ('1940', '1944', '1948', '1952', '1956', '1960', '1964', '1968','1972', '1976', '1980', '1984', '1988', '1992', '1996', '2000', '2004', '2008', '2012', '2016', '2020')\n",
    "\n",
    "    # create time series for each year in years\n",
    "    for i in range(len(years)):\n",
    "\n",
    "        year = str(years[i])\n",
    "\n",
    "        if(year in leap):\n",
    "            end_idx = start_idx + 366\n",
    "        else:\n",
    "            end_idx = start_idx + 365\n",
    "\n",
    "        # create start and end datetimes\n",
    "        t_start = year + '-01-01' # Jan 1st of each year = t_start\n",
    "        t_end = year + '-12-31' # Dec 31st = t_end\n",
    "\n",
    "        # get global consumption data\n",
    "        data = df[start_idx:end_idx]\n",
    "\n",
    "        # create time series for the year\n",
    "        index = pd.date_range(start=t_start, end=t_end, freq = freq)\n",
    "        time_series.append(pd.Series(data=data.values.flatten(), index=index))\n",
    "        \n",
    "        start_idx = end_idx\n",
    "    \n",
    "    # return list of time series\n",
    "    return time_series\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a list of years we want to make a time series of. We will make time series out of the 1940-2009 data and use the rest of the data, start of 2010 - end of 2019 as test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "\n",
    "for i in range(1940, 2010):\n",
    "    years.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make series using the dataset and the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series = make_time_series(df = df_van_normal, years = years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the first year (Jan-Dec 1940)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "train_series[0].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining test years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_years = []\n",
    "\n",
    "for i in range(2010, 2020):\n",
    "    test_years.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making test series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_series_sep = make_time_series(df = df_van_normal, years = test_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f855547cb00>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "test_series_sep[0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating moving average function as benchmark for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that will plot a time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(time, series, format=\"-\", start=0, end=None, label=None):\n",
    "    plt.plot(time[start:end], series[start:end], format, label=label)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    if label:\n",
    "        plt.legend(fontsize=14)\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting rid of all nan values in `df_van_normal` and performing rolling/moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_van_normal.fillna(df_van_normal.values.mean(), inplace=True)\n",
    "tester = pd.Series(test_series.values.flatten())\n",
    "rolled = tester.rolling(window=3)\n",
    "moving_averages = rolled.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making new list `without_nans` with all the same values as `moving_averages_list` but without nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 3\n",
    "moving_averages_list = moving_averages.tolist()\n",
    "without_nans = []\n",
    "for i in moving_averages_list:\n",
    "    if np.isnan(i):\n",
    "        x = 0.5\n",
    "        without_nans.append(x)\n",
    "    else:\n",
    "        without_nans.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting mse of each year of time series and finding the mean to get our combined mse for all 10 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028201818652451038"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = []\n",
    "for i in range(10):\n",
    "    mse.append(keras.metrics.mean_squared_error(test_series_sep[i], without_nans[i]).numpy())\n",
    "\n",
    "score = 0\n",
    "for element in mse:\n",
    "    score += element\n",
    "\n",
    "score /= 10\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The moving average got an accuracy of `0.028`. Time to beat that with the ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to write a full json dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json for formatting data\n",
    "import json\n",
    "import os # and os for saving\n",
    "\n",
    "def write_json_dataset(time_series, filename): \n",
    "    with open(filename, 'wb') as f:        # for each of our times series, there is one JSON line\n",
    "\n",
    "        for ts in time_series:\n",
    "            json_line = json.dumps(series_to_json_obj(ts)) + '\\n'\n",
    "            json_line = json_line.encode('utf-8')\n",
    "            f.write(json_line)\n",
    "    print(filename + ' saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making directory to save training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this data to a local directory\n",
    "data_dir = 'json_temp_data'\n",
    "\n",
    "# make data dir, if it does not exist\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert series to json object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_json_obj(ts):\n",
    "    '''Returns a dictionary of values in DeepAR, JSON format.\n",
    "       :param ts: A single time series.\n",
    "       :return: A dictionary of values with \"start\" and \"target\" keys.\n",
    "       '''\n",
    "    # get start time and target from the time series, ts\n",
    "    json_obj = {\"start\": str(ts.index[0]), \"target\": list(ts)}\n",
    "    return json_obj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving training and testing data to directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json_temp_data/train.json saved.\n",
      "json_temp_data/test.json saved.\n"
     ]
    }
   ],
   "source": [
    "train_key = os.path.join(data_dir, 'train.json')\n",
    "test_key = os.path.join(data_dir, 'test.json')\n",
    "\n",
    "# write train/test JSON files\n",
    "write_json_dataset(train_series, train_key)        \n",
    "write_json_dataset(test_series_sep, test_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making an S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session, role, bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploading data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general prefix\n",
    "prefix='deepar-temp-data'\n",
    "\n",
    "# *unique* train/test prefixes\n",
    "train_prefix   = '{}/{}'.format(prefix, 'train')\n",
    "test_prefix    = '{}/{}'.format(prefix, 'test')\n",
    "\n",
    "# uploading data to S3, and saving locations\n",
    "train_path  = sagemaker_session.upload_data(train_key, bucket=bucket, key_prefix=train_prefix)\n",
    "test_path   = sagemaker_session.upload_data(test_key,  bucket=bucket, key_prefix=test_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is stored in: s3://sagemaker-us-west-1-560434839557/deepar-temp-data/train/train.json\n",
      "Test data is stored in: s3://sagemaker-us-west-1-560434839557/deepar-temp-data/test/test.json\n"
     ]
    }
   ],
   "source": [
    "# check locations\n",
    "print('Training data is stored in: '+ train_path)\n",
    "print('Test data is stored in: '+ test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting image region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "image_name = get_image_uri(boto3.Session().region_name, # get the region\n",
    "                           'forecasting-deepar') # specify image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Estimator Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# dir to save model artifacts\n",
    "s3_output_path = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "\n",
    "# instantiate a DeepAR estimator\n",
    "estimator = Estimator(sagemaker_session=sagemaker_session,\n",
    "                      image_name=image_name,\n",
    "                      role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='ml.c5.xlarge',\n",
    "                      output_path=s3_output_path\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq='D'\n",
    "prediction_length=166 # days\n",
    "context_length=4 # days\n",
    "\n",
    "hyperparameters = {\n",
    "    \"epochs\": \"263\",\n",
    "    \"time_freq\": freq,\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"context_length\": str(context_length),\n",
    "    \"num_cells\": \"177\",\n",
    "    \"num_layers\": '2',\n",
    "    \"mini_batch_size\": \"5000\",\n",
    "    \"learning_rate\": \"0.01\",\n",
    "    \"dropout_rate\":'0.10',\n",
    "    'embedding_dimension':'10',\n",
    "    '_num_gpus':'auto',\n",
    "    'test_quantiles':'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]',\n",
    "    '_tuning_objective_metric': 'test:RMSE',\n",
    "    'num_eval_samples': '100',\n",
    "    '_num_kv_servers': 'auto',\n",
    "    'mini_batch_size': '208',\n",
    "    'likelihood': 'student-t',\n",
    "    'num_dynamic_feat': 'auto', \n",
    "    'cardinality': 'auto', \n",
    "    '_num_gpus': 'auto', \n",
    "    'prediction_length': '166', \n",
    "    'context_length': '4', \n",
    "    '_kvstore': 'auto'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hyperparams\n",
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attaching previously trained model to estimator (don't want to train it again, you can see all its parameters in the above cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-19 20:32:38 Starting - Preparing the instances for training\n",
      "2020-09-19 20:32:38 Downloading - Downloading input data\n",
      "2020-09-19 20:32:38 Training - Training image download completed. Training in progress.\n",
      "2020-09-19 20:32:38 Uploading - Uploading generated training model\n",
      "2020-09-19 20:32:38 Completed - Training job completed\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'208', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'test:RMSE', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.01', u'num_cells': u'177', u'num_layers': u'2', u'prediction_length': u'166', u'epochs': u'263', u'embedding_dimension': u'10', u'time_freq': u'D', u'context_length': u'4', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t'}\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'num_eval_samples': u'100', u'epochs': u'263', u'num_layers': u'2', u'_num_kv_servers': u'auto', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'prediction_length': u'166', u'time_freq': u'D', u'context_length': u'4', u'early_stopping_patience': u'', u'_tuning_objective_metric': u'test:RMSE', u'learning_rate': u'0.01', u'embedding_dimension': u'10', u'num_cells': u'177', u'mini_batch_size': u'208', u'likelihood': u'student-t', u'_num_gpus': u'auto', u'_kvstore': u'auto'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] Training set statistics:\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] Real time series\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] number of time series: 70\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] number of observations: 23468\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] mean target length: 335\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] min/mean/max target: 0.00699300691485/0.586140650347/1.0\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] mean abs(target): 0.586140650347\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] contains missing values: no\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] Small number of time series. Doing 30 passes over dataset with prob 0.990476190476 per epoch.\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] Test set statistics:\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] Real time series\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] number of time series: 70\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] number of observations: 25568\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] mean target length: 365\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] min/mean/max target: 0.0/0.572861865405/1.0\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] mean abs(target): 0.572861865405\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] contains missing values: no\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] nvidia-smi took: 0.0251178741455 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 262.876033782959, \"sum\": 262.876033782959, \"min\": 262.876033782959}}, \"EndTime\": 1600540698.61338, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600540698.349741}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:18 INFO 140356611028800] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 877.4399757385254, \"sum\": 877.4399757385254, \"min\": 877.4399757385254}}, \"EndTime\": 1600540699.227273, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600540698.613458}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:22 INFO 140356611028800] Epoch[0] Batch[0] avg_epoch_loss=0.877772\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=0.877772331238\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:34 INFO 140356611028800] Epoch[0] Batch[5] avg_epoch_loss=2.450038\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=2.45003755276\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:34 INFO 140356611028800] Epoch[0] Batch [5]#011Speed: 84.99 samples/sec#011loss=2.450038\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:44 INFO 140356611028800] processed a total of 2043 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 263, \"sum\": 263.0, \"min\": 263}, \"update.time\": {\"count\": 1, \"max\": 25238.81220817566, \"sum\": 25238.81220817566, \"min\": 25238.81220817566}}, \"EndTime\": 1600540724.466678, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600540699.227372}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:44 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.9463441317 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:44 INFO 140356611028800] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=0, train loss <loss>=2.21646849559\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:47 INFO 140356611028800] Epoch[1] Batch[0] avg_epoch_loss=1.705662\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:47 INFO 140356611028800] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=1.70566206712\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:59 INFO 140356611028800] Epoch[1] Batch[5] avg_epoch_loss=1.189606\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:59 INFO 140356611028800] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=1.18960577402\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:38:59 INFO 140356611028800] Epoch[1] Batch [5]#011Speed: 87.66 samples/sec#011loss=1.189606\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:08 INFO 140356611028800] processed a total of 2042 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24104.531049728394, \"sum\": 24104.531049728394, \"min\": 24104.531049728394}}, \"EndTime\": 1600540748.571804, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600540724.466759}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:08 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.7140473866 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:08 INFO 140356611028800] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:08 INFO 140356611028800] #quality_metric: host=algo-1, epoch=1, train loss <loss>=0.607598133271\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:11 INFO 140356611028800] Epoch[2] Batch[0] avg_epoch_loss=-0.289842\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=-0.289841743616\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:23 INFO 140356611028800] Epoch[2] Batch[5] avg_epoch_loss=-0.301087\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:23 INFO 140356611028800] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=-0.301087358059\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:23 INFO 140356611028800] Epoch[2] Batch [5]#011Speed: 87.16 samples/sec#011loss=-0.301087\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:35 INFO 140356611028800] Epoch[2] Batch[10] avg_epoch_loss=-0.415706\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:35 INFO 140356611028800] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=-0.553248632871\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:35 INFO 140356611028800] Epoch[2] Batch [10]#011Speed: 87.59 samples/sec#011loss=-0.553249\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:35 INFO 140356611028800] processed a total of 2165 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26548.521995544434, \"sum\": 26548.521995544434, \"min\": 26548.521995544434}}, \"EndTime\": 1600540775.120711, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600540748.571864}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:35 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.5485314608 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:35 INFO 140356611028800] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:35 INFO 140356611028800] #quality_metric: host=algo-1, epoch=2, train loss <loss>=-0.415706119337\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:37 INFO 140356611028800] Epoch[3] Batch[0] avg_epoch_loss=-0.496137\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=-0.496137215541\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:49 INFO 140356611028800] Epoch[3] Batch[5] avg_epoch_loss=-0.740166\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:49 INFO 140356611028800] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=-0.740166095587\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:49 INFO 140356611028800] Epoch[3] Batch [5]#011Speed: 87.50 samples/sec#011loss=-0.740166\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:59 INFO 140356611028800] processed a total of 2043 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24154.328107833862, \"sum\": 24154.328107833862, \"min\": 24154.328107833862}}, \"EndTime\": 1600540799.275384, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600540775.120771}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:59 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.580806792 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:59 INFO 140356611028800] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:39:59 INFO 140356611028800] #quality_metric: host=algo-1, epoch=3, train loss <loss>=-0.744295066137\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:02 INFO 140356611028800] Epoch[4] Batch[0] avg_epoch_loss=-0.557291\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=-0.557290664086\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:13 INFO 140356611028800] Epoch[4] Batch[5] avg_epoch_loss=-0.958124\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:13 INFO 140356611028800] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=-0.958124466431\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:13 INFO 140356611028800] Epoch[4] Batch [5]#011Speed: 87.46 samples/sec#011loss=-0.958124\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:25 INFO 140356611028800] Epoch[4] Batch[10] avg_epoch_loss=-1.050400\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=-1.1611302009\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:25 INFO 140356611028800] Epoch[4] Batch [10]#011Speed: 87.25 samples/sec#011loss=-1.161130\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:25 INFO 140356611028800] processed a total of 2121 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26610.881090164185, \"sum\": 26610.881090164185, \"min\": 26610.881090164185}}, \"EndTime\": 1600540825.886665, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600540799.27544}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:25 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.7039716471 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:25 INFO 140356611028800] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=4, train loss <loss>=-1.05039980028\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:28 INFO 140356611028800] Epoch[5] Batch[0] avg_epoch_loss=0.441946\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=0.44194646982\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:40 INFO 140356611028800] Epoch[5] Batch[5] avg_epoch_loss=-0.431574\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:40 INFO 140356611028800] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=-0.431573910591\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:40 INFO 140356611028800] Epoch[5] Batch [5]#011Speed: 87.63 samples/sec#011loss=-0.431574\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:52 INFO 140356611028800] Epoch[5] Batch[10] avg_epoch_loss=-0.469823\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:52 INFO 140356611028800] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=-0.515721651224\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:52 INFO 140356611028800] Epoch[5] Batch [10]#011Speed: 87.11 samples/sec#011loss=-0.515722\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:52 INFO 140356611028800] processed a total of 2207 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26573.057889938354, \"sum\": 26573.057889938354, \"min\": 26573.057889938354}}, \"EndTime\": 1600540852.460064, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600540825.886724}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:52 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=83.0537720711 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:52 INFO 140356611028800] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:52 INFO 140356611028800] #quality_metric: host=algo-1, epoch=5, train loss <loss>=-0.469822883606\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:55 INFO 140356611028800] Epoch[6] Batch[0] avg_epoch_loss=-0.545400\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:40:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=-0.545399812552\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:07 INFO 140356611028800] Epoch[6] Batch[5] avg_epoch_loss=-0.779130\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:07 INFO 140356611028800] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=-0.779129816936\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:07 INFO 140356611028800] Epoch[6] Batch [5]#011Speed: 87.40 samples/sec#011loss=-0.779130\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:16 INFO 140356611028800] processed a total of 2069 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24367.366790771484, \"sum\": 24367.366790771484, \"min\": 24367.366790771484}}, \"EndTime\": 1600540876.827793, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600540852.460121}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:16 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.9082156883 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:16 INFO 140356611028800] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:16 INFO 140356611028800] #quality_metric: host=algo-1, epoch=6, train loss <loss>=-0.942456645232\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:19 INFO 140356611028800] Epoch[7] Batch[0] avg_epoch_loss=-1.215742\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=-1.21574240464\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:31 INFO 140356611028800] Epoch[7] Batch[5] avg_epoch_loss=-1.314532\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:31 INFO 140356611028800] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=-1.31453180313\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:31 INFO 140356611028800] Epoch[7] Batch [5]#011Speed: 87.13 samples/sec#011loss=-1.314532\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:43 INFO 140356611028800] Epoch[7] Batch[10] avg_epoch_loss=-1.374139\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=-1.44566744291\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:43 INFO 140356611028800] Epoch[7] Batch [10]#011Speed: 86.96 samples/sec#011loss=-1.445667\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:43 INFO 140356611028800] processed a total of 2198 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26698.195934295654, \"sum\": 26698.195934295654, \"min\": 26698.195934295654}}, \"EndTime\": 1600540903.526348, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600540876.827869}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:43 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.3273829255 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:43 INFO 140356611028800] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=7, train loss <loss>=-1.37413891212\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:46 INFO 140356611028800] Epoch[8] Batch[0] avg_epoch_loss=-1.451447\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=-1.4514465332\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:58 INFO 140356611028800] Epoch[8] Batch[5] avg_epoch_loss=-1.456006\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=-1.45600614792\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:41:58 INFO 140356611028800] Epoch[8] Batch [5]#011Speed: 87.43 samples/sec#011loss=-1.456006\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:07 INFO 140356611028800] processed a total of 2006 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24199.223041534424, \"sum\": 24199.223041534424, \"min\": 24199.223041534424}}, \"EndTime\": 1600540927.72586, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600540903.52641}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:07 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.8948738438 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:07 INFO 140356611028800] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:07 INFO 140356611028800] #quality_metric: host=algo-1, epoch=8, train loss <loss>=-1.47119500087\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:10 INFO 140356611028800] Epoch[9] Batch[0] avg_epoch_loss=-1.555541\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=-1.555540525\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:22 INFO 140356611028800] Epoch[9] Batch[5] avg_epoch_loss=-1.495434\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=-1.49543397855\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:22 INFO 140356611028800] Epoch[9] Batch [5]#011Speed: 87.92 samples/sec#011loss=-1.495434\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:31 INFO 140356611028800] processed a total of 1996 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24055.657148361206, \"sum\": 24055.657148361206, \"min\": 24055.657148361206}}, \"EndTime\": 1600540951.781949, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600540927.725929}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:31 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.9737873649 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:31 INFO 140356611028800] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:31 INFO 140356611028800] #quality_metric: host=algo-1, epoch=9, train loss <loss>=-1.51198001275\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:34 INFO 140356611028800] Epoch[10] Batch[0] avg_epoch_loss=-1.587879\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=-1.58787888747\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:46 INFO 140356611028800] Epoch[10] Batch[5] avg_epoch_loss=-1.526129\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=-1.52612894009\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:46 INFO 140356611028800] Epoch[10] Batch [5]#011Speed: 88.26 samples/sec#011loss=-1.526129\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:55 INFO 140356611028800] processed a total of 2039 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23966.190099716187, \"sum\": 23966.190099716187, \"min\": 23966.190099716187}}, \"EndTime\": 1600540975.748515, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600540951.78205}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:55 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.0778322488 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:55 INFO 140356611028800] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=10, train loss <loss>=-1.52115698594\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:58 INFO 140356611028800] Epoch[11] Batch[0] avg_epoch_loss=-1.534347\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:42:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=-1.53434665386\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:10 INFO 140356611028800] Epoch[11] Batch[5] avg_epoch_loss=-1.544357\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=-1.54435703082\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:10 INFO 140356611028800] Epoch[11] Batch [5]#011Speed: 88.27 samples/sec#011loss=-1.544357\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:19 INFO 140356611028800] processed a total of 2037 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23993.874073028564, \"sum\": 23993.874073028564, \"min\": 23993.874073028564}}, \"EndTime\": 1600540999.74285, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600540975.748582}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:19 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.8963262777 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:19 INFO 140356611028800] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=11, train loss <loss>=-1.52654377864\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:22 INFO 140356611028800] Epoch[12] Batch[0] avg_epoch_loss=-1.592344\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=-1.59234428406\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:34 INFO 140356611028800] Epoch[12] Batch[5] avg_epoch_loss=-1.589088\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=-1.58908834213\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:34 INFO 140356611028800] Epoch[12] Batch [5]#011Speed: 88.25 samples/sec#011loss=-1.589088\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:43 INFO 140356611028800] processed a total of 2053 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24013.39101791382, \"sum\": 24013.39101791382, \"min\": 24013.39101791382}}, \"EndTime\": 1600541023.756649, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600540999.742916}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:43 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.4935511534 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:43 INFO 140356611028800] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=12, train loss <loss>=-1.58782548171\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:46 INFO 140356611028800] Epoch[13] Batch[0] avg_epoch_loss=-1.660707\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=-1.66070688688\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:58 INFO 140356611028800] Epoch[13] Batch[5] avg_epoch_loss=-1.471768\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=-1.47176758448\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:43:58 INFO 140356611028800] Epoch[13] Batch [5]#011Speed: 87.95 samples/sec#011loss=-1.471768\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:10 INFO 140356611028800] Epoch[13] Batch[10] avg_epoch_loss=-1.476530\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=-1.48224399273\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:10 INFO 140356611028800] Epoch[13] Batch [10]#011Speed: 87.67 samples/sec#011loss=-1.482244\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:10 INFO 140356611028800] processed a total of 2089 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26428.198099136353, \"sum\": 26428.198099136353, \"min\": 26428.198099136353}}, \"EndTime\": 1600541050.185197, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541023.756717}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:10 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.0440874233 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:10 INFO 140356611028800] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=13, train loss <loss>=-1.47652958823\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:12 INFO 140356611028800] Epoch[14] Batch[0] avg_epoch_loss=-1.568967\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:12 INFO 140356611028800] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=-1.56896737906\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:24 INFO 140356611028800] Epoch[14] Batch[5] avg_epoch_loss=-1.518401\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:24 INFO 140356611028800] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=-1.5184009014\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:24 INFO 140356611028800] Epoch[14] Batch [5]#011Speed: 87.88 samples/sec#011loss=-1.518401\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:36 INFO 140356611028800] Epoch[14] Batch[10] avg_epoch_loss=-1.553066\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=-1.59466370803\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:36 INFO 140356611028800] Epoch[14] Batch [10]#011Speed: 87.51 samples/sec#011loss=-1.594664\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:36 INFO 140356611028800] processed a total of 2125 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26487.614154815674, \"sum\": 26487.614154815674, \"min\": 26487.614154815674}}, \"EndTime\": 1600541076.673186, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541050.18526}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:36 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.2259162239 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:36 INFO 140356611028800] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=14, train loss <loss>=-1.5530658135\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:39 INFO 140356611028800] Epoch[15] Batch[0] avg_epoch_loss=-1.515179\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:39 INFO 140356611028800] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=-1.51517882714\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:51 INFO 140356611028800] Epoch[15] Batch[5] avg_epoch_loss=-1.586457\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=-1.58645742367\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:44:51 INFO 140356611028800] Epoch[15] Batch [5]#011Speed: 88.10 samples/sec#011loss=-1.586457\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:03 INFO 140356611028800] Epoch[15] Batch[10] avg_epoch_loss=-1.598648\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=-1.61327579205\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:03 INFO 140356611028800] Epoch[15] Batch [10]#011Speed: 87.70 samples/sec#011loss=-1.613276\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:03 INFO 140356611028800] processed a total of 2174 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26419.436931610107, \"sum\": 26419.436931610107, \"min\": 26419.436931610107}}, \"EndTime\": 1600541103.093056, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541076.673243}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:03 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.2876169242 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:03 INFO 140356611028800] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=15, train loss <loss>=-1.59864759112\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:05 INFO 140356611028800] Epoch[16] Batch[0] avg_epoch_loss=-1.503000\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:05 INFO 140356611028800] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=-1.50300040612\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:17 INFO 140356611028800] Epoch[16] Batch[5] avg_epoch_loss=-1.611387\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=-1.61138700828\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:17 INFO 140356611028800] Epoch[16] Batch [5]#011Speed: 87.81 samples/sec#011loss=-1.611387\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:27 INFO 140356611028800] processed a total of 2033 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24102.314949035645, \"sum\": 24102.314949035645, \"min\": 24102.314949035645}}, \"EndTime\": 1600541127.19573, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541103.093115}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:27 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.3484146962 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:27 INFO 140356611028800] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:27 INFO 140356611028800] #quality_metric: host=algo-1, epoch=16, train loss <loss>=-1.63695297241\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:29 INFO 140356611028800] Epoch[17] Batch[0] avg_epoch_loss=-1.599488\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:29 INFO 140356611028800] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=-1.59948759813\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:41 INFO 140356611028800] Epoch[17] Batch[5] avg_epoch_loss=-1.478386\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:41 INFO 140356611028800] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=-1.47838614537\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:41 INFO 140356611028800] Epoch[17] Batch [5]#011Speed: 87.82 samples/sec#011loss=-1.478386\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:53 INFO 140356611028800] Epoch[17] Batch[10] avg_epoch_loss=-1.519552\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:53 INFO 140356611028800] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=-1.56895197355\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:53 INFO 140356611028800] Epoch[17] Batch [10]#011Speed: 87.80 samples/sec#011loss=-1.568952\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:53 INFO 140356611028800] processed a total of 2084 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26442.620038986206, \"sum\": 26442.620038986206, \"min\": 26442.620038986206}}, \"EndTime\": 1600541153.638749, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541127.195795}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:53 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.8118948945 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:53 INFO 140356611028800] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:53 INFO 140356611028800] #quality_metric: host=algo-1, epoch=17, train loss <loss>=-1.51955243091\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:56 INFO 140356611028800] Epoch[18] Batch[0] avg_epoch_loss=-1.609580\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:45:56 INFO 140356611028800] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=-1.60958040678\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:08 INFO 140356611028800] Epoch[18] Batch[5] avg_epoch_loss=-1.534845\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:08 INFO 140356611028800] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=-1.53484498538\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:08 INFO 140356611028800] Epoch[18] Batch [5]#011Speed: 87.83 samples/sec#011loss=-1.534845\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:20 INFO 140356611028800] Epoch[18] Batch[10] avg_epoch_loss=-1.582060\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:20 INFO 140356611028800] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=-1.63871724055\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:20 INFO 140356611028800] Epoch[18] Batch [10]#011Speed: 88.12 samples/sec#011loss=-1.638717\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:20 INFO 140356611028800] processed a total of 2091 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26372.19214439392, \"sum\": 26372.19214439392, \"min\": 26372.19214439392}}, \"EndTime\": 1600541180.011232, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541153.638809}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:20 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.2877972787 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:20 INFO 140356611028800] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:20 INFO 140356611028800] #quality_metric: host=algo-1, epoch=18, train loss <loss>=-1.58205964682\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:22 INFO 140356611028800] Epoch[19] Batch[0] avg_epoch_loss=-1.659234\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=-1.65923441373\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:34 INFO 140356611028800] Epoch[19] Batch[5] avg_epoch_loss=-1.619414\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=-1.61941442734\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:34 INFO 140356611028800] Epoch[19] Batch [5]#011Speed: 87.97 samples/sec#011loss=-1.619414\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:46 INFO 140356611028800] Epoch[19] Batch[10] avg_epoch_loss=-1.610241\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=-1.59923318716\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:46 INFO 140356611028800] Epoch[19] Batch [10]#011Speed: 87.80 samples/sec#011loss=-1.599233\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:46 INFO 140356611028800] processed a total of 2107 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26464.622974395752, \"sum\": 26464.622974395752, \"min\": 26464.622974395752}}, \"EndTime\": 1600541206.476139, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541180.011292}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:46 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.6154491186 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:46 INFO 140356611028800] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=19, train loss <loss>=-1.61024113635\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:49 INFO 140356611028800] Epoch[20] Batch[0] avg_epoch_loss=-1.683852\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:46:49 INFO 140356611028800] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=-1.6838515355\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:01 INFO 140356611028800] Epoch[20] Batch[5] avg_epoch_loss=-1.685543\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:01 INFO 140356611028800] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=-1.68554325593\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:01 INFO 140356611028800] Epoch[20] Batch [5]#011Speed: 86.93 samples/sec#011loss=-1.685543\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:13 INFO 140356611028800] Epoch[20] Batch[10] avg_epoch_loss=-1.671381\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:13 INFO 140356611028800] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=-1.65438549335\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:13 INFO 140356611028800] Epoch[20] Batch [10]#011Speed: 86.94 samples/sec#011loss=-1.654385\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:13 INFO 140356611028800] processed a total of 2106 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26678.89904975891, \"sum\": 26678.89904975891, \"min\": 26678.89904975891}}, \"EndTime\": 1600541233.155376, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541206.4762}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:13 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.9385265134 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:13 INFO 140356611028800] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:13 INFO 140356611028800] #quality_metric: host=algo-1, epoch=20, train loss <loss>=-1.67138063658\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:15 INFO 140356611028800] Epoch[21] Batch[0] avg_epoch_loss=-1.526094\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:15 INFO 140356611028800] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=-1.52609414321\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:27 INFO 140356611028800] Epoch[21] Batch[5] avg_epoch_loss=-1.588840\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:27 INFO 140356611028800] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=-1.58883975102\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:27 INFO 140356611028800] Epoch[21] Batch [5]#011Speed: 87.96 samples/sec#011loss=-1.588840\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:37 INFO 140356611028800] processed a total of 2077 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23984.44890975952, \"sum\": 23984.44890975952, \"min\": 23984.44890975952}}, \"EndTime\": 1600541257.140198, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541233.155433}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:37 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.5974103112 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:37 INFO 140356611028800] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=21, train loss <loss>=-1.62321473635\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:39 INFO 140356611028800] Epoch[22] Batch[0] avg_epoch_loss=-1.724212\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:39 INFO 140356611028800] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=-1.72421176617\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:51 INFO 140356611028800] Epoch[22] Batch[5] avg_epoch_loss=-1.694242\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=-1.69424240406\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:47:51 INFO 140356611028800] Epoch[22] Batch [5]#011Speed: 88.47 samples/sec#011loss=-1.694242\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:03 INFO 140356611028800] Epoch[22] Batch[10] avg_epoch_loss=-1.716661\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=-1.74356404818\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:03 INFO 140356611028800] Epoch[22] Batch [10]#011Speed: 87.95 samples/sec#011loss=-1.743564\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:03 INFO 140356611028800] processed a total of 2117 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26319.94605064392, \"sum\": 26319.94605064392, \"min\": 26319.94605064392}}, \"EndTime\": 1600541283.460512, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541257.140266}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:03 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.4330055841 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:03 INFO 140356611028800] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=22, train loss <loss>=-1.7166613332\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:06 INFO 140356611028800] Epoch[23] Batch[0] avg_epoch_loss=-1.590152\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:06 INFO 140356611028800] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=-1.59015230032\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:17 INFO 140356611028800] Epoch[23] Batch[5] avg_epoch_loss=-1.644050\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=-1.64404976674\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:17 INFO 140356611028800] Epoch[23] Batch [5]#011Speed: 88.37 samples/sec#011loss=-1.644050\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:29 INFO 140356611028800] Epoch[23] Batch[10] avg_epoch_loss=-1.679633\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:29 INFO 140356611028800] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=-1.72233282236\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:29 INFO 140356611028800] Epoch[23] Batch [10]#011Speed: 87.87 samples/sec#011loss=-1.722333\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:29 INFO 140356611028800] processed a total of 2123 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26341.33791923523, \"sum\": 26341.33791923523, \"min\": 26341.33791923523}}, \"EndTime\": 1600541309.802245, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541283.460578}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:29 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.5954997545 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:29 INFO 140356611028800] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:29 INFO 140356611028800] #quality_metric: host=algo-1, epoch=23, train loss <loss>=-1.67963297384\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:32 INFO 140356611028800] Epoch[24] Batch[0] avg_epoch_loss=-1.665374\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=-1.66537358211\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:44 INFO 140356611028800] Epoch[24] Batch[5] avg_epoch_loss=-1.723459\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=-1.72345934159\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:44 INFO 140356611028800] Epoch[24] Batch [5]#011Speed: 87.94 samples/sec#011loss=-1.723459\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:53 INFO 140356611028800] processed a total of 2045 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24062.406063079834, \"sum\": 24062.406063079834, \"min\": 24062.406063079834}}, \"EndTime\": 1600541333.864974, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541309.8023}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:53 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.9870306706 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:53 INFO 140356611028800] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:53 INFO 140356611028800] #quality_metric: host=algo-1, epoch=24, train loss <loss>=-1.74592688634\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:56 INFO 140356611028800] Epoch[25] Batch[0] avg_epoch_loss=-1.793696\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:48:56 INFO 140356611028800] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=-1.79369588999\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:08 INFO 140356611028800] Epoch[25] Batch[5] avg_epoch_loss=-1.730457\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:08 INFO 140356611028800] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=-1.73045659677\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:08 INFO 140356611028800] Epoch[25] Batch [5]#011Speed: 87.59 samples/sec#011loss=-1.730457\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:17 INFO 140356611028800] processed a total of 2080 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24041.202068328857, \"sum\": 24041.202068328857, \"min\": 24041.202068328857}}, \"EndTime\": 1600541357.906512, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541333.865036}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:17 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.517791492 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:17 INFO 140356611028800] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=25, train loss <loss>=-1.63980150956\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:20 INFO 140356611028800] Epoch[26] Batch[0] avg_epoch_loss=-1.582349\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:20 INFO 140356611028800] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=-1.58234904363\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:32 INFO 140356611028800] Epoch[26] Batch[5] avg_epoch_loss=-1.643757\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=-1.64375723325\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:32 INFO 140356611028800] Epoch[26] Batch [5]#011Speed: 87.86 samples/sec#011loss=-1.643757\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:44 INFO 140356611028800] Epoch[26] Batch[10] avg_epoch_loss=-1.660444\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=-1.68046830984\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:44 INFO 140356611028800] Epoch[26] Batch [10]#011Speed: 88.01 samples/sec#011loss=-1.680468\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:44 INFO 140356611028800] processed a total of 2110 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26406.322956085205, \"sum\": 26406.322956085205, \"min\": 26406.322956085205}}, \"EndTime\": 1600541384.313243, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541357.906576}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:44 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.904835579 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:44 INFO 140356611028800] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=26, train loss <loss>=-1.66044408625\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:47 INFO 140356611028800] Epoch[27] Batch[0] avg_epoch_loss=-1.766501\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:47 INFO 140356611028800] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=-1.76650135334\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:58 INFO 140356611028800] Epoch[27] Batch[5] avg_epoch_loss=-1.693802\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=-1.69380195324\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:49:58 INFO 140356611028800] Epoch[27] Batch [5]#011Speed: 87.29 samples/sec#011loss=-1.693802\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:10 INFO 140356611028800] Epoch[27] Batch[10] avg_epoch_loss=-1.737259\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=-1.78940740732\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:10 INFO 140356611028800] Epoch[27] Batch [10]#011Speed: 87.83 samples/sec#011loss=-1.789407\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:10 INFO 140356611028800] processed a total of 2096 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26491.250038146973, \"sum\": 26491.250038146973, \"min\": 26491.250038146973}}, \"EndTime\": 1600541410.804845, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541384.313304}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:10 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.1201985868 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:10 INFO 140356611028800] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=27, train loss <loss>=-1.73725897782\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:13 INFO 140356611028800] Epoch[28] Batch[0] avg_epoch_loss=-1.789584\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:13 INFO 140356611028800] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=-1.78958379305\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:25 INFO 140356611028800] Epoch[28] Batch[5] avg_epoch_loss=-1.643885\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=-1.64388490335\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:25 INFO 140356611028800] Epoch[28] Batch [5]#011Speed: 87.74 samples/sec#011loss=-1.643885\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:37 INFO 140356611028800] Epoch[28] Batch[10] avg_epoch_loss=-1.648116\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=-1.65319237342\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:37 INFO 140356611028800] Epoch[28] Batch [10]#011Speed: 88.01 samples/sec#011loss=-1.653192\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:37 INFO 140356611028800] processed a total of 2180 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26425.235986709595, \"sum\": 26425.235986709595, \"min\": 26425.235986709595}}, \"EndTime\": 1600541437.230366, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541410.804905}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:37 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.4965862141 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:37 INFO 140356611028800] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=28, train loss <loss>=-1.64811557156\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:39 INFO 140356611028800] Epoch[29] Batch[0] avg_epoch_loss=-1.662927\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:39 INFO 140356611028800] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=-1.66292748084\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:51 INFO 140356611028800] Epoch[29] Batch[5] avg_epoch_loss=-1.682307\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=-1.68230663202\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:50:51 INFO 140356611028800] Epoch[29] Batch [5]#011Speed: 88.02 samples/sec#011loss=-1.682307\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:03 INFO 140356611028800] Epoch[29] Batch[10] avg_epoch_loss=-1.724448\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=-1.77501663795\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:03 INFO 140356611028800] Epoch[29] Batch [10]#011Speed: 87.76 samples/sec#011loss=-1.775017\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:03 INFO 140356611028800] processed a total of 2122 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26414.540767669678, \"sum\": 26414.540767669678, \"min\": 26414.540767669678}}, \"EndTime\": 1600541463.645299, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541437.230434}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:03 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.3342267178 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:03 INFO 140356611028800] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=29, train loss <loss>=-1.7244475438\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:06 INFO 140356611028800] Epoch[30] Batch[0] avg_epoch_loss=-1.823605\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:06 INFO 140356611028800] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=-1.82360517062\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:18 INFO 140356611028800] Epoch[30] Batch[5] avg_epoch_loss=-1.676422\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:18 INFO 140356611028800] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=-1.67642155672\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:18 INFO 140356611028800] Epoch[30] Batch [5]#011Speed: 88.21 samples/sec#011loss=-1.676422\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:27 INFO 140356611028800] processed a total of 2036 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24056.565046310425, \"sum\": 24056.565046310425, \"min\": 24056.565046310425}}, \"EndTime\": 1600541487.702174, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541463.645374}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:27 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.6335488715 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:27 INFO 140356611028800] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:27 INFO 140356611028800] #quality_metric: host=algo-1, epoch=30, train loss <loss>=-1.68770009554\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:30 INFO 140356611028800] Epoch[31] Batch[0] avg_epoch_loss=-1.680310\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:30 INFO 140356611028800] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=-1.68031046941\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:42 INFO 140356611028800] Epoch[31] Batch[5] avg_epoch_loss=-1.708860\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:42 INFO 140356611028800] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=-1.70886020171\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:42 INFO 140356611028800] Epoch[31] Batch [5]#011Speed: 87.90 samples/sec#011loss=-1.708860\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:54 INFO 140356611028800] Epoch[31] Batch[10] avg_epoch_loss=-1.744183\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:54 INFO 140356611028800] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=-1.78656968337\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:54 INFO 140356611028800] Epoch[31] Batch [10]#011Speed: 87.57 samples/sec#011loss=-1.786570\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:54 INFO 140356611028800] processed a total of 2119 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26463.299989700317, \"sum\": 26463.299989700317, \"min\": 26463.299989700317}}, \"EndTime\": 1600541514.165993, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541487.702237}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:54 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.0728852591 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:54 INFO 140356611028800] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:54 INFO 140356611028800] #quality_metric: host=algo-1, epoch=31, train loss <loss>=-1.74418269337\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:56 INFO 140356611028800] Epoch[32] Batch[0] avg_epoch_loss=-1.806041\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:51:56 INFO 140356611028800] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=-1.8060406905\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:08 INFO 140356611028800] Epoch[32] Batch[5] avg_epoch_loss=-1.810409\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:08 INFO 140356611028800] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=-1.81040856777\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:08 INFO 140356611028800] Epoch[32] Batch [5]#011Speed: 87.98 samples/sec#011loss=-1.810409\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:20 INFO 140356611028800] Epoch[32] Batch[10] avg_epoch_loss=-1.802625\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:20 INFO 140356611028800] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=-1.79328396137\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:20 INFO 140356611028800] Epoch[32] Batch [10]#011Speed: 87.98 samples/sec#011loss=-1.793284\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:20 INFO 140356611028800] processed a total of 2118 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26412.564039230347, \"sum\": 26412.564039230347, \"min\": 26412.564039230347}}, \"EndTime\": 1600541540.578844, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541514.166054}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:20 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.1888579848 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:20 INFO 140356611028800] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:20 INFO 140356611028800] #quality_metric: host=algo-1, epoch=32, train loss <loss>=-1.80262465577\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:23 INFO 140356611028800] Epoch[33] Batch[0] avg_epoch_loss=-1.872796\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:23 INFO 140356611028800] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=-1.87279627873\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:35 INFO 140356611028800] Epoch[33] Batch[5] avg_epoch_loss=-1.839107\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:35 INFO 140356611028800] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=-1.83910744007\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:35 INFO 140356611028800] Epoch[33] Batch [5]#011Speed: 88.24 samples/sec#011loss=-1.839107\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:46 INFO 140356611028800] Epoch[33] Batch[10] avg_epoch_loss=-1.838807\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=-1.83844727736\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:46 INFO 140356611028800] Epoch[33] Batch [10]#011Speed: 88.21 samples/sec#011loss=-1.838447\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:46 INFO 140356611028800] processed a total of 2131 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26327.084064483643, \"sum\": 26327.084064483643, \"min\": 26327.084064483643}}, \"EndTime\": 1600541566.906197, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541540.578901}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:46 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.9429891173 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:46 INFO 140356611028800] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=33, train loss <loss>=-1.83880736611\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:49 INFO 140356611028800] Epoch[34] Batch[0] avg_epoch_loss=-1.834162\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:52:49 INFO 140356611028800] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=-1.83416190514\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:01 INFO 140356611028800] Epoch[34] Batch[5] avg_epoch_loss=-1.837315\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:01 INFO 140356611028800] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=-1.83731514368\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:01 INFO 140356611028800] Epoch[34] Batch [5]#011Speed: 88.14 samples/sec#011loss=-1.837315\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:10 INFO 140356611028800] processed a total of 2042 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23971.283197402954, \"sum\": 23971.283197402954, \"min\": 23971.283197402954}}, \"EndTime\": 1600541590.877798, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541566.906259}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:10 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.184951947 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:10 INFO 140356611028800] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=34, train loss <loss>=-1.84912106441\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:13 INFO 140356611028800] Epoch[35] Batch[0] avg_epoch_loss=-1.745238\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:13 INFO 140356611028800] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=-1.7452383775\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:25 INFO 140356611028800] Epoch[35] Batch[5] avg_epoch_loss=-1.659392\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=-1.65939247914\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:25 INFO 140356611028800] Epoch[35] Batch [5]#011Speed: 88.08 samples/sec#011loss=-1.659392\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:37 INFO 140356611028800] Epoch[35] Batch[10] avg_epoch_loss=-1.674807\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=-1.69330350436\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:37 INFO 140356611028800] Epoch[35] Batch [10]#011Speed: 88.08 samples/sec#011loss=-1.693304\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:37 INFO 140356611028800] processed a total of 2097 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26335.304975509644, \"sum\": 26335.304975509644, \"min\": 26335.304975509644}}, \"EndTime\": 1600541617.213476, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541590.87786}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:37 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.6266618953 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:37 INFO 140356611028800] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=35, train loss <loss>=-1.67480658151\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:39 INFO 140356611028800] Epoch[36] Batch[0] avg_epoch_loss=-1.411652\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:39 INFO 140356611028800] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=-1.41165175805\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:51 INFO 140356611028800] Epoch[36] Batch[5] avg_epoch_loss=-1.634674\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=-1.63467392555\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:53:51 INFO 140356611028800] Epoch[36] Batch [5]#011Speed: 88.12 samples/sec#011loss=-1.634674\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:03 INFO 140356611028800] Epoch[36] Batch[10] avg_epoch_loss=-1.674218\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=-1.72167070829\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:03 INFO 140356611028800] Epoch[36] Batch [10]#011Speed: 87.58 samples/sec#011loss=-1.721671\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:03 INFO 140356611028800] processed a total of 2122 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26403.008222579956, \"sum\": 26403.008222579956, \"min\": 26403.008222579956}}, \"EndTime\": 1600541643.61685, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541617.21354}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:03 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.3693563327 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:03 INFO 140356611028800] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=36, train loss <loss>=-1.6742179177\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:06 INFO 140356611028800] Epoch[37] Batch[0] avg_epoch_loss=-1.711111\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:06 INFO 140356611028800] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=-1.71111092201\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:18 INFO 140356611028800] Epoch[37] Batch[5] avg_epoch_loss=-1.766383\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:18 INFO 140356611028800] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=-1.76638339116\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:18 INFO 140356611028800] Epoch[37] Batch [5]#011Speed: 88.04 samples/sec#011loss=-1.766383\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:30 INFO 140356611028800] Epoch[37] Batch[10] avg_epoch_loss=-1.787498\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:30 INFO 140356611028800] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=-1.81283472501\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:30 INFO 140356611028800] Epoch[37] Batch [10]#011Speed: 87.51 samples/sec#011loss=-1.812835\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:30 INFO 140356611028800] processed a total of 2151 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26462.645053863525, \"sum\": 26462.645053863525, \"min\": 26462.645053863525}}, \"EndTime\": 1600541670.079794, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541643.61691}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:30 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.2841366199 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:30 INFO 140356611028800] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:30 INFO 140356611028800] #quality_metric: host=algo-1, epoch=37, train loss <loss>=-1.78749763382\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:32 INFO 140356611028800] Epoch[38] Batch[0] avg_epoch_loss=-1.854343\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=-1.85434312087\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:44 INFO 140356611028800] Epoch[38] Batch[5] avg_epoch_loss=-1.808866\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=-1.80886574281\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:44 INFO 140356611028800] Epoch[38] Batch [5]#011Speed: 88.07 samples/sec#011loss=-1.808866\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:56 INFO 140356611028800] Epoch[38] Batch[10] avg_epoch_loss=-1.826829\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:56 INFO 140356611028800] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=-1.84838394752\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:56 INFO 140356611028800] Epoch[38] Batch [10]#011Speed: 87.50 samples/sec#011loss=-1.848384\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:56 INFO 140356611028800] processed a total of 2102 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26430.195093154907, \"sum\": 26430.195093154907, \"min\": 26430.195093154907}}, \"EndTime\": 1600541696.510345, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541670.079848}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:56 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.5299033243 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:56 INFO 140356611028800] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:56 INFO 140356611028800] #quality_metric: host=algo-1, epoch=38, train loss <loss>=-1.82682856313\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:59 INFO 140356611028800] Epoch[39] Batch[0] avg_epoch_loss=-1.646377\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:54:59 INFO 140356611028800] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=-1.64637653644\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:11 INFO 140356611028800] Epoch[39] Batch[5] avg_epoch_loss=-1.640500\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=-1.6404999953\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:11 INFO 140356611028800] Epoch[39] Batch [5]#011Speed: 87.41 samples/sec#011loss=-1.640500\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:23 INFO 140356611028800] Epoch[39] Batch[10] avg_epoch_loss=-1.698320\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:23 INFO 140356611028800] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=-1.76770374592\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:23 INFO 140356611028800] Epoch[39] Batch [10]#011Speed: 87.16 samples/sec#011loss=-1.767704\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:23 INFO 140356611028800] processed a total of 2122 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26578.52792739868, \"sum\": 26578.52792739868, \"min\": 26578.52792739868}}, \"EndTime\": 1600541723.089318, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541696.510405}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:23 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.838585765 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:23 INFO 140356611028800] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:23 INFO 140356611028800] #quality_metric: host=algo-1, epoch=39, train loss <loss>=-1.69831988195\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:25 INFO 140356611028800] Epoch[40] Batch[0] avg_epoch_loss=-1.627258\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=-1.62725756719\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:37 INFO 140356611028800] Epoch[40] Batch[5] avg_epoch_loss=-1.757428\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=-1.75742836488\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:37 INFO 140356611028800] Epoch[40] Batch [5]#011Speed: 87.92 samples/sec#011loss=-1.757428\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:49 INFO 140356611028800] Epoch[40] Batch[10] avg_epoch_loss=-1.784043\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:49 INFO 140356611028800] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=-1.81598061782\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:49 INFO 140356611028800] Epoch[40] Batch [10]#011Speed: 87.61 samples/sec#011loss=-1.815981\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:49 INFO 140356611028800] processed a total of 2115 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26483.0379486084, \"sum\": 26483.0379486084, \"min\": 26483.0379486084}}, \"EndTime\": 1600541749.572721, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541723.089391}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:49 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.8621707204 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:49 INFO 140356611028800] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:49 INFO 140356611028800] #quality_metric: host=algo-1, epoch=40, train loss <loss>=-1.7840430253\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:52 INFO 140356611028800] Epoch[41] Batch[0] avg_epoch_loss=-1.863607\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:55:52 INFO 140356611028800] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=-1.86360711318\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:04 INFO 140356611028800] Epoch[41] Batch[5] avg_epoch_loss=-1.835206\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=-1.83520564055\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:04 INFO 140356611028800] Epoch[41] Batch [5]#011Speed: 87.12 samples/sec#011loss=-1.835206\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:13 INFO 140356611028800] processed a total of 2061 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24240.713834762573, \"sum\": 24240.713834762573, \"min\": 24240.713834762573}}, \"EndTime\": 1600541773.813717, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541749.572781}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:13 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.0219426264 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:13 INFO 140356611028800] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:13 INFO 140356611028800] #quality_metric: host=algo-1, epoch=41, train loss <loss>=-1.84644691761\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:16 INFO 140356611028800] Epoch[42] Batch[0] avg_epoch_loss=-1.846752\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:16 INFO 140356611028800] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=-1.84675231347\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:28 INFO 140356611028800] Epoch[42] Batch[5] avg_epoch_loss=-1.863768\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=-1.86376806406\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:28 INFO 140356611028800] Epoch[42] Batch [5]#011Speed: 87.13 samples/sec#011loss=-1.863768\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:38 INFO 140356611028800] processed a total of 2078 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24268.052101135254, \"sum\": 24268.052101135254, \"min\": 24268.052101135254}}, \"EndTime\": 1600541798.082168, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541773.813775}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:38 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.626601798 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:38 INFO 140356611028800] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:38 INFO 140356611028800] #quality_metric: host=algo-1, epoch=42, train loss <loss>=-1.86575155992\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:40 INFO 140356611028800] Epoch[43] Batch[0] avg_epoch_loss=-1.885714\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:40 INFO 140356611028800] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=-1.88571401743\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:52 INFO 140356611028800] Epoch[43] Batch[5] avg_epoch_loss=-1.873749\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:52 INFO 140356611028800] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=-1.87374855922\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:56:52 INFO 140356611028800] Epoch[43] Batch [5]#011Speed: 87.33 samples/sec#011loss=-1.873749\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:04 INFO 140356611028800] Epoch[43] Batch[10] avg_epoch_loss=-1.848697\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=-1.81863470811\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:04 INFO 140356611028800] Epoch[43] Batch [10]#011Speed: 87.14 samples/sec#011loss=-1.818635\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:04 INFO 140356611028800] processed a total of 2107 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26587.947845458984, \"sum\": 26587.947845458984, \"min\": 26587.947845458984}}, \"EndTime\": 1600541824.67054, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541798.082239}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:04 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.2461811174 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:04 INFO 140356611028800] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=43, train loss <loss>=-1.84869680871\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:07 INFO 140356611028800] Epoch[44] Batch[0] avg_epoch_loss=-1.866794\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:07 INFO 140356611028800] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=-1.86679414602\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:19 INFO 140356611028800] Epoch[44] Batch[5] avg_epoch_loss=-1.869157\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=-1.86915656848\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:19 INFO 140356611028800] Epoch[44] Batch [5]#011Speed: 87.08 samples/sec#011loss=-1.869157\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:28 INFO 140356611028800] processed a total of 2057 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24232.587814331055, \"sum\": 24232.587814331055, \"min\": 24232.587814331055}}, \"EndTime\": 1600541848.90353, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541824.670592}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:28 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.8853485069 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:28 INFO 140356611028800] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=44, train loss <loss>=-1.87264467386\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:31 INFO 140356611028800] Epoch[45] Batch[0] avg_epoch_loss=-1.893109\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:31 INFO 140356611028800] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=-1.89310939495\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:43 INFO 140356611028800] Epoch[45] Batch[5] avg_epoch_loss=-1.883053\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=-1.88305307046\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:43 INFO 140356611028800] Epoch[45] Batch [5]#011Speed: 88.13 samples/sec#011loss=-1.883053\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:52 INFO 140356611028800] processed a total of 2060 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24036.321878433228, \"sum\": 24036.321878433228, \"min\": 24036.321878433228}}, \"EndTime\": 1600541872.940191, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541848.903597}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:52 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.7032824774 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:52 INFO 140356611028800] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:52 INFO 140356611028800] #quality_metric: host=algo-1, epoch=45, train loss <loss>=-1.87878908011\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:55 INFO 140356611028800] Epoch[46] Batch[0] avg_epoch_loss=-1.896832\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:57:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=-1.89683165917\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:07 INFO 140356611028800] Epoch[46] Batch[5] avg_epoch_loss=-1.870820\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:07 INFO 140356611028800] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=-1.87081999656\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:07 INFO 140356611028800] Epoch[46] Batch [5]#011Speed: 87.78 samples/sec#011loss=-1.870820\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:17 INFO 140356611028800] processed a total of 2036 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24117.47717857361, \"sum\": 24117.47717857361, \"min\": 24117.47717857361}}, \"EndTime\": 1600541897.058083, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541872.940254}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:17 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.419778022 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:17 INFO 140356611028800] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=46, train loss <loss>=-1.8315543835\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:19 INFO 140356611028800] Epoch[47] Batch[0] avg_epoch_loss=-1.799245\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=-1.79924524747\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:31 INFO 140356611028800] Epoch[47] Batch[5] avg_epoch_loss=-1.793501\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:31 INFO 140356611028800] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=-1.79350119371\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:31 INFO 140356611028800] Epoch[47] Batch [5]#011Speed: 87.48 samples/sec#011loss=-1.793501\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:43 INFO 140356611028800] Epoch[47] Batch[10] avg_epoch_loss=-1.822516\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=-1.85733401959\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:43 INFO 140356611028800] Epoch[47] Batch [10]#011Speed: 87.71 samples/sec#011loss=-1.857334\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:43 INFO 140356611028800] processed a total of 2103 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26497.452974319458, \"sum\": 26497.452974319458, \"min\": 26497.452974319458}}, \"EndTime\": 1600541923.555876, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541897.058147}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:43 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.3658552658 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:43 INFO 140356611028800] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=47, train loss <loss>=-1.82251611456\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:46 INFO 140356611028800] Epoch[48] Batch[0] avg_epoch_loss=-1.757541\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=-1.75754062946\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:58 INFO 140356611028800] Epoch[48] Batch[5] avg_epoch_loss=-1.855347\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=-1.85534738883\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:58:58 INFO 140356611028800] Epoch[48] Batch [5]#011Speed: 87.83 samples/sec#011loss=-1.855347\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:07 INFO 140356611028800] processed a total of 2078 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24123.396158218384, \"sum\": 24123.396158218384, \"min\": 24123.396158218384}}, \"EndTime\": 1600541947.679671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541923.555932}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:07 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.1400883752 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:07 INFO 140356611028800] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:07 INFO 140356611028800] #quality_metric: host=algo-1, epoch=48, train loss <loss>=-1.86565661797\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:10 INFO 140356611028800] Epoch[49] Batch[0] avg_epoch_loss=-1.875549\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=-1.87554946313\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:22 INFO 140356611028800] Epoch[49] Batch[5] avg_epoch_loss=-1.876640\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=-1.87664000193\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:22 INFO 140356611028800] Epoch[49] Batch [5]#011Speed: 87.58 samples/sec#011loss=-1.876640\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:31 INFO 140356611028800] processed a total of 2019 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24177.20103263855, \"sum\": 24177.20103263855, \"min\": 24177.20103263855}}, \"EndTime\": 1600541971.857302, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541947.679732}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:31 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=83.5079630574 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:31 INFO 140356611028800] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:31 INFO 140356611028800] #quality_metric: host=algo-1, epoch=49, train loss <loss>=-1.88347324958\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:34 INFO 140356611028800] Epoch[50] Batch[0] avg_epoch_loss=-1.907384\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=-1.90738413884\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:46 INFO 140356611028800] Epoch[50] Batch[5] avg_epoch_loss=-1.888979\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=-1.88897917821\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:46 INFO 140356611028800] Epoch[50] Batch [5]#011Speed: 87.57 samples/sec#011loss=-1.888979\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:58 INFO 140356611028800] Epoch[50] Batch[10] avg_epoch_loss=-1.886487\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=-1.88349621113\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:58 INFO 140356611028800] Epoch[50] Batch [10]#011Speed: 87.19 samples/sec#011loss=-1.883496\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:58 INFO 140356611028800] processed a total of 2089 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26581.218004226685, \"sum\": 26581.218004226685, \"min\": 26581.218004226685}}, \"EndTime\": 1600541998.438949, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541971.857403}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:58 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.5890628011 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:58 INFO 140356611028800] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 18:59:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=50, train loss <loss>=-1.88648692044\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:01 INFO 140356611028800] Epoch[51] Batch[0] avg_epoch_loss=-1.888111\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:01 INFO 140356611028800] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=-1.88811126122\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:13 INFO 140356611028800] Epoch[51] Batch[5] avg_epoch_loss=-1.815360\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:13 INFO 140356611028800] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=-1.81535980029\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:13 INFO 140356611028800] Epoch[51] Batch [5]#011Speed: 87.33 samples/sec#011loss=-1.815360\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:25 INFO 140356611028800] Epoch[51] Batch[10] avg_epoch_loss=-1.788551\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=-1.75637978774\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:25 INFO 140356611028800] Epoch[51] Batch [10]#011Speed: 86.80 samples/sec#011loss=-1.756380\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:25 INFO 140356611028800] processed a total of 2116 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26670.85313796997, \"sum\": 26670.85313796997, \"min\": 26670.85313796997}}, \"EndTime\": 1600542025.11015, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600541998.439011}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:25 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.3372807572 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:25 INFO 140356611028800] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=51, train loss <loss>=-1.78855070368\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:27 INFO 140356611028800] Epoch[52] Batch[0] avg_epoch_loss=-1.425675\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:27 INFO 140356611028800] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=-1.42567502535\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:39 INFO 140356611028800] Epoch[52] Batch[5] avg_epoch_loss=-1.600328\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:39 INFO 140356611028800] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=-1.60032822536\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:39 INFO 140356611028800] Epoch[52] Batch [5]#011Speed: 87.69 samples/sec#011loss=-1.600328\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:49 INFO 140356611028800] processed a total of 2080 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24106.04190826416, \"sum\": 24106.04190826416, \"min\": 24106.04190826416}}, \"EndTime\": 1600542049.216527, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542025.110211}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:49 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.2850960528 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:49 INFO 140356611028800] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:49 INFO 140356611028800] #quality_metric: host=algo-1, epoch=52, train loss <loss>=-1.62302567409\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:51 INFO 140356611028800] Epoch[53] Batch[0] avg_epoch_loss=-1.852229\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:00:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=-1.85222875155\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:03 INFO 140356611028800] Epoch[53] Batch[5] avg_epoch_loss=-1.786893\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=-1.78689318437\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:03 INFO 140356611028800] Epoch[53] Batch [5]#011Speed: 87.35 samples/sec#011loss=-1.786893\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:15 INFO 140356611028800] Epoch[53] Batch[10] avg_epoch_loss=-1.813237\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:15 INFO 140356611028800] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=-1.84484930772\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:15 INFO 140356611028800] Epoch[53] Batch [10]#011Speed: 87.31 samples/sec#011loss=-1.844849\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:15 INFO 140356611028800] processed a total of 2144 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26596.431016921997, \"sum\": 26596.431016921997, \"min\": 26596.431016921997}}, \"EndTime\": 1600542075.813324, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542049.216589}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:15 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.6119923477 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:15 INFO 140356611028800] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:15 INFO 140356611028800] #quality_metric: host=algo-1, epoch=53, train loss <loss>=-1.8132368768\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:18 INFO 140356611028800] Epoch[54] Batch[0] avg_epoch_loss=-1.847226\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:18 INFO 140356611028800] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=-1.84722606952\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:30 INFO 140356611028800] Epoch[54] Batch[5] avg_epoch_loss=-1.783736\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:30 INFO 140356611028800] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=-1.78373642457\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:30 INFO 140356611028800] Epoch[54] Batch [5]#011Speed: 87.59 samples/sec#011loss=-1.783736\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:42 INFO 140356611028800] Epoch[54] Batch[10] avg_epoch_loss=-1.802266\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:42 INFO 140356611028800] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=-1.82450086153\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:42 INFO 140356611028800] Epoch[54] Batch [10]#011Speed: 88.02 samples/sec#011loss=-1.824501\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:42 INFO 140356611028800] processed a total of 2156 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26437.60585784912, \"sum\": 26437.60585784912, \"min\": 26437.60585784912}}, \"EndTime\": 1600542102.251346, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542075.813401}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:42 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.5501949485 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:42 INFO 140356611028800] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:42 INFO 140356611028800] #quality_metric: host=algo-1, epoch=54, train loss <loss>=-1.8022657141\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:44 INFO 140356611028800] Epoch[55] Batch[0] avg_epoch_loss=-1.848685\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=-1.84868519123\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:56 INFO 140356611028800] Epoch[55] Batch[5] avg_epoch_loss=-1.856769\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:56 INFO 140356611028800] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=-1.85676917052\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:01:56 INFO 140356611028800] Epoch[55] Batch [5]#011Speed: 87.64 samples/sec#011loss=-1.856769\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:08 INFO 140356611028800] Epoch[55] Batch[10] avg_epoch_loss=-1.859878\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:08 INFO 140356611028800] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=-1.86360954872\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:08 INFO 140356611028800] Epoch[55] Batch [10]#011Speed: 87.16 samples/sec#011loss=-1.863610\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:08 INFO 140356611028800] processed a total of 2188 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26534.605026245117, \"sum\": 26534.605026245117, \"min\": 26534.605026245117}}, \"EndTime\": 1600542128.786365, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542102.251414}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:08 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.4580860904 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:08 INFO 140356611028800] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:08 INFO 140356611028800] #quality_metric: host=algo-1, epoch=55, train loss <loss>=-1.85987843333\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:11 INFO 140356611028800] Epoch[56] Batch[0] avg_epoch_loss=-1.827806\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=-1.82780559246\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:23 INFO 140356611028800] Epoch[56] Batch[5] avg_epoch_loss=-1.861767\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:23 INFO 140356611028800] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=-1.86176701081\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:23 INFO 140356611028800] Epoch[56] Batch [5]#011Speed: 87.36 samples/sec#011loss=-1.861767\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:35 INFO 140356611028800] Epoch[56] Batch[10] avg_epoch_loss=-1.870265\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:35 INFO 140356611028800] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=-1.88046173683\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:35 INFO 140356611028800] Epoch[56] Batch [10]#011Speed: 87.33 samples/sec#011loss=-1.880462\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:35 INFO 140356611028800] processed a total of 2119 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26610.892057418823, \"sum\": 26610.892057418823, \"min\": 26610.892057418823}}, \"EndTime\": 1600542155.397592, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542128.786425}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:35 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.6283958929 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:35 INFO 140356611028800] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:35 INFO 140356611028800] #quality_metric: host=algo-1, epoch=56, train loss <loss>=-1.87026461355\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:38 INFO 140356611028800] Epoch[57] Batch[0] avg_epoch_loss=-1.896523\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:38 INFO 140356611028800] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=-1.89652281541\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:49 INFO 140356611028800] Epoch[57] Batch[5] avg_epoch_loss=-1.884460\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:49 INFO 140356611028800] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=-1.88446008242\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:02:49 INFO 140356611028800] Epoch[57] Batch [5]#011Speed: 88.33 samples/sec#011loss=-1.884460\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:01 INFO 140356611028800] Epoch[57] Batch[10] avg_epoch_loss=-1.888547\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:01 INFO 140356611028800] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=-1.8934511038\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:01 INFO 140356611028800] Epoch[57] Batch [10]#011Speed: 87.88 samples/sec#011loss=-1.893451\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:01 INFO 140356611028800] processed a total of 2103 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26340.00301361084, \"sum\": 26340.00301361084, \"min\": 26340.00301361084}}, \"EndTime\": 1600542181.738139, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542155.397781}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:01 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.8402766747 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:01 INFO 140356611028800] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:01 INFO 140356611028800] #quality_metric: host=algo-1, epoch=57, train loss <loss>=-1.88854691032\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:04 INFO 140356611028800] Epoch[58] Batch[0] avg_epoch_loss=-1.904327\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=-1.90432709914\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:16 INFO 140356611028800] Epoch[58] Batch[5] avg_epoch_loss=-1.894933\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:16 INFO 140356611028800] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=-1.89493301587\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:16 INFO 140356611028800] Epoch[58] Batch [5]#011Speed: 87.72 samples/sec#011loss=-1.894933\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:25 INFO 140356611028800] processed a total of 2067 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24088.836908340454, \"sum\": 24088.836908340454, \"min\": 24088.836908340454}}, \"EndTime\": 1600542205.827311, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542181.738198}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:25 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.8070563104 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:25 INFO 140356611028800] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=58, train loss <loss>=-1.89820641738\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:28 INFO 140356611028800] Epoch[59] Batch[0] avg_epoch_loss=-1.906631\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=-1.90663088285\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:40 INFO 140356611028800] Epoch[59] Batch[5] avg_epoch_loss=-1.907965\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:40 INFO 140356611028800] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=-1.90796473087\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:40 INFO 140356611028800] Epoch[59] Batch [5]#011Speed: 87.43 samples/sec#011loss=-1.907965\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:50 INFO 140356611028800] processed a total of 2045 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24189.23807144165, \"sum\": 24189.23807144165, \"min\": 24189.23807144165}}, \"EndTime\": 1600542230.016955, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542205.827368}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:50 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.5414244521 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:50 INFO 140356611028800] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:50 INFO 140356611028800] #quality_metric: host=algo-1, epoch=59, train loss <loss>=-1.90653908069\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:52 INFO 140356611028800] Epoch[60] Batch[0] avg_epoch_loss=-1.889173\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:03:52 INFO 140356611028800] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=-1.88917292081\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:04 INFO 140356611028800] Epoch[60] Batch[5] avg_epoch_loss=-1.878133\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=-1.87813277122\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:04 INFO 140356611028800] Epoch[60] Batch [5]#011Speed: 87.19 samples/sec#011loss=-1.878133\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:16 INFO 140356611028800] Epoch[60] Batch[10] avg_epoch_loss=-1.866920\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:16 INFO 140356611028800] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=-1.85346471346\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:16 INFO 140356611028800] Epoch[60] Batch [10]#011Speed: 87.77 samples/sec#011loss=-1.853465\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:16 INFO 140356611028800] processed a total of 2095 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26543.344020843506, \"sum\": 26543.344020843506, \"min\": 26543.344020843506}}, \"EndTime\": 1600542256.560721, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542230.017015}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:16 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.9272401117 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:16 INFO 140356611028800] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:16 INFO 140356611028800] #quality_metric: host=algo-1, epoch=60, train loss <loss>=-1.8669200177\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:19 INFO 140356611028800] Epoch[61] Batch[0] avg_epoch_loss=-1.857707\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=-1.85770680354\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:31 INFO 140356611028800] Epoch[61] Batch[5] avg_epoch_loss=-1.817958\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:31 INFO 140356611028800] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=-1.81795763358\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:31 INFO 140356611028800] Epoch[61] Batch [5]#011Speed: 87.47 samples/sec#011loss=-1.817958\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:43 INFO 140356611028800] Epoch[61] Batch[10] avg_epoch_loss=-1.832958\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=-1.8509589562\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:43 INFO 140356611028800] Epoch[61] Batch [10]#011Speed: 87.72 samples/sec#011loss=-1.850959\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:43 INFO 140356611028800] processed a total of 2085 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26512.27307319641, \"sum\": 26512.27307319641, \"min\": 26512.27307319641}}, \"EndTime\": 1600542283.073293, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542256.560781}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:43 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.6425260222 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:43 INFO 140356611028800] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=61, train loss <loss>=-1.83295823477\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:45 INFO 140356611028800] Epoch[62] Batch[0] avg_epoch_loss=-1.779512\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:45 INFO 140356611028800] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=-1.77951225868\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:57 INFO 140356611028800] Epoch[62] Batch[5] avg_epoch_loss=-1.825973\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:57 INFO 140356611028800] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=-1.82597253261\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:04:57 INFO 140356611028800] Epoch[62] Batch [5]#011Speed: 87.68 samples/sec#011loss=-1.825973\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:09 INFO 140356611028800] Epoch[62] Batch[10] avg_epoch_loss=-1.844141\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:09 INFO 140356611028800] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=-1.86594229478\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:09 INFO 140356611028800] Epoch[62] Batch [10]#011Speed: 87.47 samples/sec#011loss=-1.865942\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:09 INFO 140356611028800] processed a total of 2096 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26477.90503501892, \"sum\": 26477.90503501892, \"min\": 26477.90503501892}}, \"EndTime\": 1600542309.551585, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542283.073351}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:09 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.1600811506 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:09 INFO 140356611028800] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:09 INFO 140356611028800] #quality_metric: host=algo-1, epoch=62, train loss <loss>=-1.84414060633\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:12 INFO 140356611028800] Epoch[63] Batch[0] avg_epoch_loss=-1.880094\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:12 INFO 140356611028800] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=-1.88009364788\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:24 INFO 140356611028800] Epoch[63] Batch[5] avg_epoch_loss=-1.849455\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:24 INFO 140356611028800] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=-1.84945524656\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:24 INFO 140356611028800] Epoch[63] Batch [5]#011Speed: 87.96 samples/sec#011loss=-1.849455\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:33 INFO 140356611028800] processed a total of 2070 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24126.80196762085, \"sum\": 24126.80196762085, \"min\": 24126.80196762085}}, \"EndTime\": 1600542333.67875, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542309.551642}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:33 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.7963061578 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:33 INFO 140356611028800] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:33 INFO 140356611028800] #quality_metric: host=algo-1, epoch=63, train loss <loss>=-1.85615969438\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:36 INFO 140356611028800] Epoch[64] Batch[0] avg_epoch_loss=-1.868317\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=-1.86831738399\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:48 INFO 140356611028800] Epoch[64] Batch[5] avg_epoch_loss=-1.886801\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:48 INFO 140356611028800] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=-1.88680071708\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:05:48 INFO 140356611028800] Epoch[64] Batch [5]#011Speed: 87.47 samples/sec#011loss=-1.886801\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:00 INFO 140356611028800] Epoch[64] Batch[10] avg_epoch_loss=-1.881833\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:00 INFO 140356611028800] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=-1.87587098342\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:00 INFO 140356611028800] Epoch[64] Batch [10]#011Speed: 87.57 samples/sec#011loss=-1.875871\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:00 INFO 140356611028800] processed a total of 2127 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26527.57215499878, \"sum\": 26527.57215499878, \"min\": 26527.57215499878}}, \"EndTime\": 1600542360.206722, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542333.67883}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:00 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.180427871 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:00 INFO 140356611028800] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:00 INFO 140356611028800] #quality_metric: host=algo-1, epoch=64, train loss <loss>=-1.88183265633\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:02 INFO 140356611028800] Epoch[65] Batch[0] avg_epoch_loss=-1.903623\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=-1.90362343421\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:14 INFO 140356611028800] Epoch[65] Batch[5] avg_epoch_loss=-1.907794\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:14 INFO 140356611028800] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=-1.90779353411\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:14 INFO 140356611028800] Epoch[65] Batch [5]#011Speed: 87.81 samples/sec#011loss=-1.907794\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:26 INFO 140356611028800] Epoch[65] Batch[10] avg_epoch_loss=-1.902489\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:26 INFO 140356611028800] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=-1.89612250695\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:26 INFO 140356611028800] Epoch[65] Batch [10]#011Speed: 87.88 samples/sec#011loss=-1.896123\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:26 INFO 140356611028800] processed a total of 2172 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26442.800045013428, \"sum\": 26442.800045013428, \"min\": 26442.800045013428}}, \"EndTime\": 1600542386.64992, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542360.206791}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:26 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.1392696837 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:26 INFO 140356611028800] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:26 INFO 140356611028800] #quality_metric: host=algo-1, epoch=65, train loss <loss>=-1.90248852176\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:29 INFO 140356611028800] Epoch[66] Batch[0] avg_epoch_loss=-1.904325\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:29 INFO 140356611028800] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=-1.90432489835\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:41 INFO 140356611028800] Epoch[66] Batch[5] avg_epoch_loss=-1.899653\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:41 INFO 140356611028800] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=-1.89965321467\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:41 INFO 140356611028800] Epoch[66] Batch [5]#011Speed: 87.95 samples/sec#011loss=-1.899653\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:53 INFO 140356611028800] Epoch[66] Batch[10] avg_epoch_loss=-1.907445\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:53 INFO 140356611028800] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=-1.91679455684\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:53 INFO 140356611028800] Epoch[66] Batch [10]#011Speed: 87.92 samples/sec#011loss=-1.916795\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:53 INFO 140356611028800] processed a total of 2114 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26426.002025604248, \"sum\": 26426.002025604248, \"min\": 26426.002025604248}}, \"EndTime\": 1600542413.0763, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542386.649982}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:53 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.9965948509 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:53 INFO 140356611028800] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:53 INFO 140356611028800] #quality_metric: host=algo-1, epoch=66, train loss <loss>=-1.90744473384\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:55 INFO 140356611028800] Epoch[67] Batch[0] avg_epoch_loss=-1.908914\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:06:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=-1.90891353901\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:07 INFO 140356611028800] Epoch[67] Batch[5] avg_epoch_loss=-1.847429\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:07 INFO 140356611028800] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=-1.84742929997\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:07 INFO 140356611028800] Epoch[67] Batch [5]#011Speed: 87.69 samples/sec#011loss=-1.847429\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:19 INFO 140356611028800] Epoch[67] Batch[10] avg_epoch_loss=-1.849692\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=-1.85240821838\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:19 INFO 140356611028800] Epoch[67] Batch [10]#011Speed: 87.92 samples/sec#011loss=-1.852408\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:19 INFO 140356611028800] processed a total of 2106 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26446.63119316101, \"sum\": 26446.63119316101, \"min\": 26446.63119316101}}, \"EndTime\": 1600542439.523274, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542413.076363}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:19 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.6318185343 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:19 INFO 140356611028800] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=67, train loss <loss>=-1.8496924447\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:22 INFO 140356611028800] Epoch[68] Batch[0] avg_epoch_loss=-1.866049\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=-1.86604866615\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:34 INFO 140356611028800] Epoch[68] Batch[5] avg_epoch_loss=-1.866281\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=-1.86628065354\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:34 INFO 140356611028800] Epoch[68] Batch [5]#011Speed: 87.72 samples/sec#011loss=-1.866281\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:45 INFO 140356611028800] Epoch[68] Batch[10] avg_epoch_loss=-1.870686\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:45 INFO 140356611028800] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=-1.87597339337\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:45 INFO 140356611028800] Epoch[68] Batch [10]#011Speed: 88.48 samples/sec#011loss=-1.875973\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:45 INFO 140356611028800] processed a total of 2146 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26355.55601119995, \"sum\": 26355.55601119995, \"min\": 26355.55601119995}}, \"EndTime\": 1600542465.879154, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542439.523332}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:45 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.4246912625 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:45 INFO 140356611028800] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:45 INFO 140356611028800] #quality_metric: host=algo-1, epoch=68, train loss <loss>=-1.87068644437\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:48 INFO 140356611028800] Epoch[69] Batch[0] avg_epoch_loss=-1.867232\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:07:48 INFO 140356611028800] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=-1.86723180918\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:00 INFO 140356611028800] Epoch[69] Batch[5] avg_epoch_loss=-1.842450\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:00 INFO 140356611028800] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=-1.84245021527\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:00 INFO 140356611028800] Epoch[69] Batch [5]#011Speed: 88.27 samples/sec#011loss=-1.842450\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:09 INFO 140356611028800] processed a total of 1984 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23968.261003494263, \"sum\": 23968.261003494263, \"min\": 23968.261003494263}}, \"EndTime\": 1600542489.847692, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542465.879212}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:09 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.7757583534 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:09 INFO 140356611028800] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:09 INFO 140356611028800] #quality_metric: host=algo-1, epoch=69, train loss <loss>=-1.8451129033\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:12 INFO 140356611028800] Epoch[70] Batch[0] avg_epoch_loss=-1.898905\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:12 INFO 140356611028800] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=-1.89890480042\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:24 INFO 140356611028800] Epoch[70] Batch[5] avg_epoch_loss=-1.859310\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:24 INFO 140356611028800] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=-1.85931039468\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:24 INFO 140356611028800] Epoch[70] Batch [5]#011Speed: 88.32 samples/sec#011loss=-1.859310\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:36 INFO 140356611028800] Epoch[70] Batch[10] avg_epoch_loss=-1.859804\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=-1.86039730952\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:36 INFO 140356611028800] Epoch[70] Batch [10]#011Speed: 87.92 samples/sec#011loss=-1.860397\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:36 INFO 140356611028800] processed a total of 2145 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26353.82318496704, \"sum\": 26353.82318496704, \"min\": 26353.82318496704}}, \"EndTime\": 1600542516.201872, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542489.84777}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:36 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.3920941854 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:36 INFO 140356611028800] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=70, train loss <loss>=-1.85980444688\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:38 INFO 140356611028800] Epoch[71] Batch[0] avg_epoch_loss=-1.889509\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:38 INFO 140356611028800] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=-1.88950934777\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:50 INFO 140356611028800] Epoch[71] Batch[5] avg_epoch_loss=-1.843446\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:50 INFO 140356611028800] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=-1.84344590016\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:08:50 INFO 140356611028800] Epoch[71] Batch [5]#011Speed: 87.91 samples/sec#011loss=-1.843446\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:02 INFO 140356611028800] Epoch[71] Batch[10] avg_epoch_loss=-1.856275\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=-1.87166982797\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:02 INFO 140356611028800] Epoch[71] Batch [10]#011Speed: 86.25 samples/sec#011loss=-1.871670\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:02 INFO 140356611028800] processed a total of 2144 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26654.769897460938, \"sum\": 26654.769897460938, \"min\": 26654.769897460938}}, \"EndTime\": 1600542542.856925, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542516.201932}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:02 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.4356156861 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:02 INFO 140356611028800] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=71, train loss <loss>=-1.85627495826\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:05 INFO 140356611028800] Epoch[72] Batch[0] avg_epoch_loss=-1.759581\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:05 INFO 140356611028800] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=-1.75958119906\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:17 INFO 140356611028800] Epoch[72] Batch[5] avg_epoch_loss=-1.827251\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=-1.82725133651\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:17 INFO 140356611028800] Epoch[72] Batch [5]#011Speed: 87.79 samples/sec#011loss=-1.827251\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:27 INFO 140356611028800] processed a total of 2039 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24162.88709640503, \"sum\": 24162.88709640503, \"min\": 24162.88709640503}}, \"EndTime\": 1600542567.020108, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542542.856987}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:27 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.3852691505 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:27 INFO 140356611028800] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:27 INFO 140356611028800] #quality_metric: host=algo-1, epoch=72, train loss <loss>=-1.84329009423\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:29 INFO 140356611028800] Epoch[73] Batch[0] avg_epoch_loss=-1.847915\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:29 INFO 140356611028800] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=-1.84791535598\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:41 INFO 140356611028800] Epoch[73] Batch[5] avg_epoch_loss=-1.875920\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:41 INFO 140356611028800] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=-1.87592027126\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:41 INFO 140356611028800] Epoch[73] Batch [5]#011Speed: 88.17 samples/sec#011loss=-1.875920\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:51 INFO 140356611028800] processed a total of 2054 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24043.318033218384, \"sum\": 24043.318033218384, \"min\": 24043.318033218384}}, \"EndTime\": 1600542591.063841, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542567.020175}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:51 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.4287679982 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:51 INFO 140356611028800] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=73, train loss <loss>=-1.88112615439\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:53 INFO 140356611028800] Epoch[74] Batch[0] avg_epoch_loss=-1.891070\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:09:53 INFO 140356611028800] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=-1.89107029255\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:05 INFO 140356611028800] Epoch[74] Batch[5] avg_epoch_loss=-1.897778\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:05 INFO 140356611028800] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=-1.89777782636\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:05 INFO 140356611028800] Epoch[74] Batch [5]#011Speed: 87.42 samples/sec#011loss=-1.897778\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:17 INFO 140356611028800] Epoch[74] Batch[10] avg_epoch_loss=-1.878870\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=-1.85617992695\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:17 INFO 140356611028800] Epoch[74] Batch [10]#011Speed: 87.80 samples/sec#011loss=-1.856180\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:17 INFO 140356611028800] processed a total of 2124 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26487.246990203857, \"sum\": 26487.246990203857, \"min\": 26487.246990203857}}, \"EndTime\": 1600542617.551421, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542591.063908}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:17 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.1892469829 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:17 INFO 140356611028800] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=74, train loss <loss>=-1.87886969026\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:20 INFO 140356611028800] Epoch[75] Batch[0] avg_epoch_loss=-1.897684\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:20 INFO 140356611028800] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=-1.89768365713\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:32 INFO 140356611028800] Epoch[75] Batch[5] avg_epoch_loss=-1.896148\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=-1.89614767906\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:32 INFO 140356611028800] Epoch[75] Batch [5]#011Speed: 87.68 samples/sec#011loss=-1.896148\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:44 INFO 140356611028800] Epoch[75] Batch[10] avg_epoch_loss=-1.897314\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=-1.89871356671\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:44 INFO 140356611028800] Epoch[75] Batch [10]#011Speed: 87.85 samples/sec#011loss=-1.898714\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:44 INFO 140356611028800] processed a total of 2113 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26461.500883102417, \"sum\": 26461.500883102417, \"min\": 26461.500883102417}}, \"EndTime\": 1600542644.013254, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542617.55149}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:44 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.8515885053 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:44 INFO 140356611028800] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=75, train loss <loss>=-1.89731399163\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:46 INFO 140356611028800] Epoch[76] Batch[0] avg_epoch_loss=-1.890411\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=-1.89041064336\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:58 INFO 140356611028800] Epoch[76] Batch[5] avg_epoch_loss=-1.820497\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=-1.82049665696\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:10:58 INFO 140356611028800] Epoch[76] Batch [5]#011Speed: 87.95 samples/sec#011loss=-1.820497\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:08 INFO 140356611028800] processed a total of 2070 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24120.826959609985, \"sum\": 24120.826959609985, \"min\": 24120.826959609985}}, \"EndTime\": 1600542668.134559, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542644.013315}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:08 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.8176368369 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:08 INFO 140356611028800] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:08 INFO 140356611028800] #quality_metric: host=algo-1, epoch=76, train loss <loss>=-1.83162614382\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:10 INFO 140356611028800] Epoch[77] Batch[0] avg_epoch_loss=-1.868582\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=-1.86858221201\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:22 INFO 140356611028800] Epoch[77] Batch[5] avg_epoch_loss=-1.868925\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=-1.86892499679\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:22 INFO 140356611028800] Epoch[77] Batch [5]#011Speed: 88.01 samples/sec#011loss=-1.868925\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:34 INFO 140356611028800] Epoch[77] Batch[10] avg_epoch_loss=-1.876824\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=-1.88630271325\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:34 INFO 140356611028800] Epoch[77] Batch [10]#011Speed: 87.76 samples/sec#011loss=-1.886303\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:34 INFO 140356611028800] processed a total of 2094 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26511.136054992676, \"sum\": 26511.136054992676, \"min\": 26511.136054992676}}, \"EndTime\": 1600542694.646097, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542668.134615}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:34 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.9854166236 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:34 INFO 140356611028800] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=77, train loss <loss>=-1.87682395882\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:37 INFO 140356611028800] Epoch[78] Batch[0] avg_epoch_loss=-1.872829\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=-1.87282943726\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:49 INFO 140356611028800] Epoch[78] Batch[5] avg_epoch_loss=-1.824409\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:49 INFO 140356611028800] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=-1.8244085801\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:11:49 INFO 140356611028800] Epoch[78] Batch [5]#011Speed: 87.89 samples/sec#011loss=-1.824409\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:01 INFO 140356611028800] Epoch[78] Batch[10] avg_epoch_loss=-1.846612\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:01 INFO 140356611028800] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=-1.873255715\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:01 INFO 140356611028800] Epoch[78] Batch [10]#011Speed: 87.63 samples/sec#011loss=-1.873256\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:01 INFO 140356611028800] processed a total of 2109 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26508.25595855713, \"sum\": 26508.25595855713, \"min\": 26508.25595855713}}, \"EndTime\": 1600542721.154687, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542694.646157}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:01 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.5597405182 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:01 INFO 140356611028800] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:01 INFO 140356611028800] #quality_metric: host=algo-1, epoch=78, train loss <loss>=-1.84661182324\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:03 INFO 140356611028800] Epoch[79] Batch[0] avg_epoch_loss=-1.889488\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=-1.88948778006\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:15 INFO 140356611028800] Epoch[79] Batch[5] avg_epoch_loss=-1.900154\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:15 INFO 140356611028800] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=-1.90015443166\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:15 INFO 140356611028800] Epoch[79] Batch [5]#011Speed: 87.92 samples/sec#011loss=-1.900154\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:27 INFO 140356611028800] Epoch[79] Batch[10] avg_epoch_loss=-1.905088\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:27 INFO 140356611028800] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=-1.91100736765\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:27 INFO 140356611028800] Epoch[79] Batch [10]#011Speed: 87.74 samples/sec#011loss=-1.911007\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:27 INFO 140356611028800] processed a total of 2128 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26461.75479888916, \"sum\": 26461.75479888916, \"min\": 26461.75479888916}}, \"EndTime\": 1600542747.616823, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542721.154751}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:27 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.4176791047 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:27 INFO 140356611028800] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:27 INFO 140356611028800] #quality_metric: host=algo-1, epoch=79, train loss <loss>=-1.90508758438\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:30 INFO 140356611028800] Epoch[80] Batch[0] avg_epoch_loss=-1.903211\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:30 INFO 140356611028800] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=-1.90321086003\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:42 INFO 140356611028800] Epoch[80] Batch[5] avg_epoch_loss=-1.905789\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:42 INFO 140356611028800] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=-1.90578925304\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:42 INFO 140356611028800] Epoch[80] Batch [5]#011Speed: 88.21 samples/sec#011loss=-1.905789\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:51 INFO 140356611028800] processed a total of 2021 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23980.293035507202, \"sum\": 23980.293035507202, \"min\": 23980.293035507202}}, \"EndTime\": 1600542771.597405, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542747.616885}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:51 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.2771878688 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:51 INFO 140356611028800] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=80, train loss <loss>=-1.90631706531\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:54 INFO 140356611028800] Epoch[81] Batch[0] avg_epoch_loss=-1.904769\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:12:54 INFO 140356611028800] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=-1.90476931058\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:06 INFO 140356611028800] Epoch[81] Batch[5] avg_epoch_loss=-1.896054\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:06 INFO 140356611028800] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=-1.89605409671\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:06 INFO 140356611028800] Epoch[81] Batch [5]#011Speed: 88.04 samples/sec#011loss=-1.896054\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:15 INFO 140356611028800] processed a total of 2031 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23982.314109802246, \"sum\": 23982.314109802246, \"min\": 23982.314109802246}}, \"EndTime\": 1600542795.580064, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542771.597473}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:15 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.686909606 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:15 INFO 140356611028800] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:15 INFO 140356611028800] #quality_metric: host=algo-1, epoch=81, train loss <loss>=-1.90714051173\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:18 INFO 140356611028800] Epoch[82] Batch[0] avg_epoch_loss=-1.897650\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:18 INFO 140356611028800] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=-1.89765005845\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:30 INFO 140356611028800] Epoch[82] Batch[5] avg_epoch_loss=-1.894714\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:30 INFO 140356611028800] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=-1.89471352406\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:30 INFO 140356611028800] Epoch[82] Batch [5]#011Speed: 88.36 samples/sec#011loss=-1.894714\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:41 INFO 140356611028800] Epoch[82] Batch[10] avg_epoch_loss=-1.899969\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:41 INFO 140356611028800] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=-1.90627588125\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:41 INFO 140356611028800] Epoch[82] Batch [10]#011Speed: 87.75 samples/sec#011loss=-1.906276\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:41 INFO 140356611028800] processed a total of 2117 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26372.76291847229, \"sum\": 26372.76291847229, \"min\": 26372.76291847229}}, \"EndTime\": 1600542821.953237, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542795.580175}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:41 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.271934181 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:41 INFO 140356611028800] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:41 INFO 140356611028800] #quality_metric: host=algo-1, epoch=82, train loss <loss>=-1.89996914097\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:44 INFO 140356611028800] Epoch[83] Batch[0] avg_epoch_loss=-1.895540\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=-1.89553965055\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:56 INFO 140356611028800] Epoch[83] Batch[5] avg_epoch_loss=-1.905620\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:56 INFO 140356611028800] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=-1.90561964573\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:13:56 INFO 140356611028800] Epoch[83] Batch [5]#011Speed: 88.07 samples/sec#011loss=-1.905620\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:05 INFO 140356611028800] processed a total of 2031 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24030.292987823486, \"sum\": 24030.292987823486, \"min\": 24030.292987823486}}, \"EndTime\": 1600542845.983952, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542821.953297}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:05 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.5179404507 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:05 INFO 140356611028800] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:05 INFO 140356611028800] #quality_metric: host=algo-1, epoch=83, train loss <loss>=-1.9087588677\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:08 INFO 140356611028800] Epoch[84] Batch[0] avg_epoch_loss=-1.901433\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:08 INFO 140356611028800] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=-1.90143291767\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:20 INFO 140356611028800] Epoch[84] Batch[5] avg_epoch_loss=-1.902172\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:20 INFO 140356611028800] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=-1.90217181964\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:20 INFO 140356611028800] Epoch[84] Batch [5]#011Speed: 87.89 samples/sec#011loss=-1.902172\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:32 INFO 140356611028800] Epoch[84] Batch[10] avg_epoch_loss=-1.910863\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=-1.92129314129\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:32 INFO 140356611028800] Epoch[84] Batch [10]#011Speed: 87.56 samples/sec#011loss=-1.921293\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:32 INFO 140356611028800] processed a total of 2105 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26485.605001449585, \"sum\": 26485.605001449585, \"min\": 26485.605001449585}}, \"EndTime\": 1600542872.469911, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542845.98403}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:32 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.4768651198 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:32 INFO 140356611028800] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=84, train loss <loss>=-1.91086332948\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:35 INFO 140356611028800] Epoch[85] Batch[0] avg_epoch_loss=-1.906159\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:35 INFO 140356611028800] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=-1.90615903414\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:47 INFO 140356611028800] Epoch[85] Batch[5] avg_epoch_loss=-1.914219\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:47 INFO 140356611028800] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=-1.9142190004\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:47 INFO 140356611028800] Epoch[85] Batch [5]#011Speed: 87.73 samples/sec#011loss=-1.914219\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:58 INFO 140356611028800] Epoch[85] Batch[10] avg_epoch_loss=-1.920142\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=-1.92724929223\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:58 INFO 140356611028800] Epoch[85] Batch [10]#011Speed: 87.81 samples/sec#011loss=-1.927249\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:58 INFO 140356611028800] processed a total of 2125 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26452.363967895508, \"sum\": 26452.363967895508, \"min\": 26452.363967895508}}, \"EndTime\": 1600542898.92261, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542872.469972}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:58 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.3328177089 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:58 INFO 140356611028800] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:14:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=85, train loss <loss>=-1.92014186032\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:01 INFO 140356611028800] Epoch[86] Batch[0] avg_epoch_loss=-1.894307\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:01 INFO 140356611028800] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=-1.89430676974\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:13 INFO 140356611028800] Epoch[86] Batch[5] avg_epoch_loss=-1.891273\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:13 INFO 140356611028800] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=-1.89127274049\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:13 INFO 140356611028800] Epoch[86] Batch [5]#011Speed: 87.50 samples/sec#011loss=-1.891273\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:23 INFO 140356611028800] processed a total of 2025 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24119.83895301819, \"sum\": 24119.83895301819, \"min\": 24119.83895301819}}, \"EndTime\": 1600542923.042783, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542898.922669}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:23 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=83.9554707513 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:23 INFO 140356611028800] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:23 INFO 140356611028800] #quality_metric: host=algo-1, epoch=86, train loss <loss>=-1.89287854708\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:25 INFO 140356611028800] Epoch[87] Batch[0] avg_epoch_loss=-1.861480\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=-1.86147968586\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:37 INFO 140356611028800] Epoch[87] Batch[5] avg_epoch_loss=-1.897741\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=-1.89774065751\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:37 INFO 140356611028800] Epoch[87] Batch [5]#011Speed: 87.11 samples/sec#011loss=-1.897741\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:49 INFO 140356611028800] Epoch[87] Batch[10] avg_epoch_loss=-1.911152\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:49 INFO 140356611028800] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=-1.92724638719\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:49 INFO 140356611028800] Epoch[87] Batch [10]#011Speed: 87.52 samples/sec#011loss=-1.927246\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:49 INFO 140356611028800] processed a total of 2160 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26575.971126556396, \"sum\": 26575.971126556396, \"min\": 26575.971126556396}}, \"EndTime\": 1600542949.619175, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542923.04284}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:49 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.2761646356 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:49 INFO 140356611028800] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:49 INFO 140356611028800] #quality_metric: host=algo-1, epoch=87, train loss <loss>=-1.91115235282\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:52 INFO 140356611028800] Epoch[88] Batch[0] avg_epoch_loss=-1.889093\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:15:52 INFO 140356611028800] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=-1.88909266545\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:04 INFO 140356611028800] Epoch[88] Batch[5] avg_epoch_loss=-1.890888\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=-1.89088831192\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:04 INFO 140356611028800] Epoch[88] Batch [5]#011Speed: 87.16 samples/sec#011loss=-1.890888\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:16 INFO 140356611028800] Epoch[88] Batch[10] avg_epoch_loss=-1.883047\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:16 INFO 140356611028800] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=-1.87363747817\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:16 INFO 140356611028800] Epoch[88] Batch [10]#011Speed: 87.88 samples/sec#011loss=-1.873637\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:16 INFO 140356611028800] processed a total of 2097 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26503.015995025635, \"sum\": 26503.015995025635, \"min\": 26503.015995025635}}, \"EndTime\": 1600542976.12255, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542949.61923}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:16 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.1228162795 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:16 INFO 140356611028800] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:16 INFO 140356611028800] #quality_metric: host=algo-1, epoch=88, train loss <loss>=-1.88304702385\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:18 INFO 140356611028800] Epoch[89] Batch[0] avg_epoch_loss=-1.810554\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:18 INFO 140356611028800] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=-1.81055406424\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:30 INFO 140356611028800] Epoch[89] Batch[5] avg_epoch_loss=-1.857843\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:30 INFO 140356611028800] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=-1.85784339905\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:30 INFO 140356611028800] Epoch[89] Batch [5]#011Speed: 87.98 samples/sec#011loss=-1.857843\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:40 INFO 140356611028800] processed a total of 2035 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24129.448890686035, \"sum\": 24129.448890686035, \"min\": 24129.448890686035}}, \"EndTime\": 1600543000.252334, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600542976.122603}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:40 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.3364782368 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:40 INFO 140356611028800] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:40 INFO 140356611028800] #quality_metric: host=algo-1, epoch=89, train loss <loss>=-1.87331525362\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:42 INFO 140356611028800] Epoch[90] Batch[0] avg_epoch_loss=-1.887662\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:42 INFO 140356611028800] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=-1.88766215398\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:54 INFO 140356611028800] Epoch[90] Batch[5] avg_epoch_loss=-1.898327\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:54 INFO 140356611028800] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=-1.89832697159\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:16:54 INFO 140356611028800] Epoch[90] Batch [5]#011Speed: 87.83 samples/sec#011loss=-1.898327\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:06 INFO 140356611028800] Epoch[90] Batch[10] avg_epoch_loss=-1.912694\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:06 INFO 140356611028800] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=-1.92993498582\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:06 INFO 140356611028800] Epoch[90] Batch [10]#011Speed: 87.23 samples/sec#011loss=-1.929935\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:06 INFO 140356611028800] processed a total of 2097 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26496.206045150757, \"sum\": 26496.206045150757, \"min\": 26496.206045150757}}, \"EndTime\": 1600543026.748919, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543000.252394}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:06 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.1431491983 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:06 INFO 140356611028800] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:06 INFO 140356611028800] #quality_metric: host=algo-1, epoch=90, train loss <loss>=-1.91269425079\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:09 INFO 140356611028800] Epoch[91] Batch[0] avg_epoch_loss=-1.923373\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:09 INFO 140356611028800] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=-1.92337285555\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:21 INFO 140356611028800] Epoch[91] Batch[5] avg_epoch_loss=-1.811208\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:21 INFO 140356611028800] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=-1.81120808919\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:21 INFO 140356611028800] Epoch[91] Batch [5]#011Speed: 87.34 samples/sec#011loss=-1.811208\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:33 INFO 140356611028800] Epoch[91] Batch[10] avg_epoch_loss=-1.797810\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:33 INFO 140356611028800] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=-1.78173305805\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:33 INFO 140356611028800] Epoch[91] Batch [10]#011Speed: 87.49 samples/sec#011loss=-1.781733\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:33 INFO 140356611028800] processed a total of 2129 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26559.45587158203, \"sum\": 26559.45587158203, \"min\": 26559.45587158203}}, \"EndTime\": 1600543053.308717, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543026.748975}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:33 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.1594754014 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:33 INFO 140356611028800] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:33 INFO 140356611028800] #quality_metric: host=algo-1, epoch=91, train loss <loss>=-1.79781034776\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:36 INFO 140356611028800] Epoch[92] Batch[0] avg_epoch_loss=-1.808597\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=-1.8085968311\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:47 INFO 140356611028800] Epoch[92] Batch[5] avg_epoch_loss=-1.794297\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:47 INFO 140356611028800] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=-1.79429655809\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:47 INFO 140356611028800] Epoch[92] Batch [5]#011Speed: 88.38 samples/sec#011loss=-1.794297\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:57 INFO 140356611028800] processed a total of 2065 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23953.032970428467, \"sum\": 23953.032970428467, \"min\": 23953.032970428467}}, \"EndTime\": 1600543077.262154, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543053.308788}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:57 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.2100130545 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:57 INFO 140356611028800] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:57 INFO 140356611028800] #quality_metric: host=algo-1, epoch=92, train loss <loss>=-1.81200348781\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:59 INFO 140356611028800] Epoch[93] Batch[0] avg_epoch_loss=-1.888522\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:17:59 INFO 140356611028800] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=-1.88852207477\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:11 INFO 140356611028800] Epoch[93] Batch[5] avg_epoch_loss=-1.864567\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=-1.86456670517\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:11 INFO 140356611028800] Epoch[93] Batch [5]#011Speed: 87.65 samples/sec#011loss=-1.864567\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:23 INFO 140356611028800] Epoch[93] Batch[10] avg_epoch_loss=-1.866109\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:23 INFO 140356611028800] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=-1.86795880244\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:23 INFO 140356611028800] Epoch[93] Batch [10]#011Speed: 88.18 samples/sec#011loss=-1.867959\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:23 INFO 140356611028800] processed a total of 2148 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26395.66707611084, \"sum\": 26395.66707611084, \"min\": 26395.66707611084}}, \"EndTime\": 1600543103.65828, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543077.262227}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:23 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.3767065078 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:23 INFO 140356611028800] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:23 INFO 140356611028800] #quality_metric: host=algo-1, epoch=93, train loss <loss>=-1.86610856756\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:26 INFO 140356611028800] Epoch[94] Batch[0] avg_epoch_loss=-1.915007\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:26 INFO 140356611028800] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=-1.91500678429\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:38 INFO 140356611028800] Epoch[94] Batch[5] avg_epoch_loss=-1.903123\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:38 INFO 140356611028800] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=-1.90312304864\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:38 INFO 140356611028800] Epoch[94] Batch [5]#011Speed: 88.14 samples/sec#011loss=-1.903123\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:50 INFO 140356611028800] Epoch[94] Batch[10] avg_epoch_loss=-1.903087\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:50 INFO 140356611028800] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=-1.90304362957\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:50 INFO 140356611028800] Epoch[94] Batch [10]#011Speed: 87.82 samples/sec#011loss=-1.903044\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:50 INFO 140356611028800] processed a total of 2163 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26395.259857177734, \"sum\": 26395.259857177734, \"min\": 26395.259857177734}}, \"EndTime\": 1600543130.05384, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543103.658343}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:50 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.9462364167 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:50 INFO 140356611028800] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:50 INFO 140356611028800] #quality_metric: host=algo-1, epoch=94, train loss <loss>=-1.90308694906\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:52 INFO 140356611028800] Epoch[95] Batch[0] avg_epoch_loss=-1.900240\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:18:52 INFO 140356611028800] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=-1.90023965102\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:04 INFO 140356611028800] Epoch[95] Batch[5] avg_epoch_loss=-1.889441\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=-1.88944136791\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:04 INFO 140356611028800] Epoch[95] Batch [5]#011Speed: 87.60 samples/sec#011loss=-1.889441\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:14 INFO 140356611028800] processed a total of 2026 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24077.380895614624, \"sum\": 24077.380895614624, \"min\": 24077.380895614624}}, \"EndTime\": 1600543154.131704, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543130.053906}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:14 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.1450115612 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:14 INFO 140356611028800] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:14 INFO 140356611028800] #quality_metric: host=algo-1, epoch=95, train loss <loss>=-1.90081728422\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:16 INFO 140356611028800] Epoch[96] Batch[0] avg_epoch_loss=-1.899333\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:16 INFO 140356611028800] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=-1.89933336698\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:28 INFO 140356611028800] Epoch[96] Batch[5] avg_epoch_loss=-1.908751\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=-1.90875119429\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:28 INFO 140356611028800] Epoch[96] Batch [5]#011Speed: 87.98 samples/sec#011loss=-1.908751\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:38 INFO 140356611028800] processed a total of 2064 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24083.02593231201, \"sum\": 24083.02593231201, \"min\": 24083.02593231201}}, \"EndTime\": 1600543178.215157, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543154.131772}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:38 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.7031885683 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:38 INFO 140356611028800] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:38 INFO 140356611028800] #quality_metric: host=algo-1, epoch=96, train loss <loss>=-1.91105188223\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:40 INFO 140356611028800] Epoch[97] Batch[0] avg_epoch_loss=-1.911936\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:40 INFO 140356611028800] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=-1.91193565956\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:52 INFO 140356611028800] Epoch[97] Batch[5] avg_epoch_loss=-1.912658\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:52 INFO 140356611028800] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=-1.91265778664\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:19:52 INFO 140356611028800] Epoch[97] Batch [5]#011Speed: 88.10 samples/sec#011loss=-1.912658\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:04 INFO 140356611028800] Epoch[97] Batch[10] avg_epoch_loss=-1.907498\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=-1.90130635775\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:04 INFO 140356611028800] Epoch[97] Batch [10]#011Speed: 87.76 samples/sec#011loss=-1.901306\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:04 INFO 140356611028800] processed a total of 2138 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26409.178972244263, \"sum\": 26409.178972244263, \"min\": 26409.178972244263}}, \"EndTime\": 1600543204.624721, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543178.215222}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:04 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.9564157468 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:04 INFO 140356611028800] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=97, train loss <loss>=-1.90749804623\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:07 INFO 140356611028800] Epoch[98] Batch[0] avg_epoch_loss=-1.917363\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:07 INFO 140356611028800] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=-1.91736338689\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:19 INFO 140356611028800] Epoch[98] Batch[5] avg_epoch_loss=-1.894784\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=-1.89478370471\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:19 INFO 140356611028800] Epoch[98] Batch [5]#011Speed: 87.98 samples/sec#011loss=-1.894784\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:31 INFO 140356611028800] Epoch[98] Batch[10] avg_epoch_loss=-1.888854\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:31 INFO 140356611028800] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=-1.88173857469\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:31 INFO 140356611028800] Epoch[98] Batch [10]#011Speed: 87.27 samples/sec#011loss=-1.881739\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:31 INFO 140356611028800] processed a total of 2094 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26496.896982192993, \"sum\": 26496.896982192993, \"min\": 26496.896982192993}}, \"EndTime\": 1600543231.122025, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543204.62478}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:31 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.0278116878 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:31 INFO 140356611028800] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:31 INFO 140356611028800] #quality_metric: host=algo-1, epoch=98, train loss <loss>=-1.88885410015\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:33 INFO 140356611028800] Epoch[99] Batch[0] avg_epoch_loss=-1.918467\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:33 INFO 140356611028800] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=-1.91846700815\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:45 INFO 140356611028800] Epoch[99] Batch[5] avg_epoch_loss=-1.863799\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:45 INFO 140356611028800] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=-1.86379853273\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:45 INFO 140356611028800] Epoch[99] Batch [5]#011Speed: 88.11 samples/sec#011loss=-1.863799\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:55 INFO 140356611028800] processed a total of 2067 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24028.295040130615, \"sum\": 24028.295040130615, \"min\": 24028.295040130615}}, \"EndTime\": 1600543255.150634, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543231.122097}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:55 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.0232308255 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:55 INFO 140356611028800] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=99, train loss <loss>=-1.86245896266\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:57 INFO 140356611028800] Epoch[100] Batch[0] avg_epoch_loss=-1.844619\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:20:57 INFO 140356611028800] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=-1.84461931082\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:09 INFO 140356611028800] Epoch[100] Batch[5] avg_epoch_loss=-1.884833\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:09 INFO 140356611028800] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=-1.88483314025\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:09 INFO 140356611028800] Epoch[100] Batch [5]#011Speed: 87.65 samples/sec#011loss=-1.884833\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:19 INFO 140356611028800] processed a total of 2072 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24126.30605697632, \"sum\": 24126.30605697632, \"min\": 24126.30605697632}}, \"EndTime\": 1600543279.277299, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543255.150702}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:19 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.8809120431 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:19 INFO 140356611028800] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=100, train loss <loss>=-1.87159825839\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:22 INFO 140356611028800] Epoch[101] Batch[0] avg_epoch_loss=-1.854252\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=-1.85425230173\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:33 INFO 140356611028800] Epoch[101] Batch[5] avg_epoch_loss=-1.863258\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:33 INFO 140356611028800] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=-1.863258264\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:33 INFO 140356611028800] Epoch[101] Batch [5]#011Speed: 87.58 samples/sec#011loss=-1.863258\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:45 INFO 140356611028800] Epoch[101] Batch[10] avg_epoch_loss=-1.878913\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:45 INFO 140356611028800] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=-1.89769941477\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:45 INFO 140356611028800] Epoch[101] Batch [10]#011Speed: 87.91 samples/sec#011loss=-1.897699\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:45 INFO 140356611028800] processed a total of 2104 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26487.51997947693, \"sum\": 26487.51997947693, \"min\": 26487.51997947693}}, \"EndTime\": 1600543305.765221, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543279.277393}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:45 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.4332577068 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:45 INFO 140356611028800] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:45 INFO 140356611028800] #quality_metric: host=algo-1, epoch=101, train loss <loss>=-1.87891333253\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:48 INFO 140356611028800] Epoch[102] Batch[0] avg_epoch_loss=-1.712221\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:21:48 INFO 140356611028800] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=-1.71222070547\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:00 INFO 140356611028800] Epoch[102] Batch[5] avg_epoch_loss=-1.799267\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:00 INFO 140356611028800] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=-1.79926723089\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:00 INFO 140356611028800] Epoch[102] Batch [5]#011Speed: 87.69 samples/sec#011loss=-1.799267\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:12 INFO 140356611028800] Epoch[102] Batch[10] avg_epoch_loss=-1.827564\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:12 INFO 140356611028800] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=-1.86151909461\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:12 INFO 140356611028800] Epoch[102] Batch [10]#011Speed: 86.79 samples/sec#011loss=-1.861519\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:12 INFO 140356611028800] processed a total of 2103 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26603.869199752808, \"sum\": 26603.869199752808, \"min\": 26603.869199752808}}, \"EndTime\": 1600543332.36947, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543305.765318}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:12 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.0483857024 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:12 INFO 140356611028800] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:12 INFO 140356611028800] #quality_metric: host=algo-1, epoch=102, train loss <loss>=-1.82756353258\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:15 INFO 140356611028800] Epoch[103] Batch[0] avg_epoch_loss=-1.827098\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:15 INFO 140356611028800] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=-1.82709811284\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:26 INFO 140356611028800] Epoch[103] Batch[5] avg_epoch_loss=-1.843687\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:26 INFO 140356611028800] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=-1.84368720421\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:26 INFO 140356611028800] Epoch[103] Batch [5]#011Speed: 87.69 samples/sec#011loss=-1.843687\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:36 INFO 140356611028800] processed a total of 2068 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24104.62212562561, \"sum\": 24104.62212562561, \"min\": 24104.62212562561}}, \"EndTime\": 1600543356.474403, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543332.369532}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:36 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.7923613784 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:36 INFO 140356611028800] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=103, train loss <loss>=-1.86127939958\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:39 INFO 140356611028800] Epoch[104] Batch[0] avg_epoch_loss=-1.863896\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:39 INFO 140356611028800] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=-1.8638957097\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:50 INFO 140356611028800] Epoch[104] Batch[5] avg_epoch_loss=-1.898363\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:50 INFO 140356611028800] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=-1.8983630645\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:22:50 INFO 140356611028800] Epoch[104] Batch [5]#011Speed: 88.45 samples/sec#011loss=-1.898363\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:00 INFO 140356611028800] processed a total of 2072 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23947.453022003174, \"sum\": 23947.453022003174, \"min\": 23947.453022003174}}, \"EndTime\": 1600543380.42231, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543356.474464}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:00 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.5224249701 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:00 INFO 140356611028800] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:00 INFO 140356611028800] #quality_metric: host=algo-1, epoch=104, train loss <loss>=-1.90190907992\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:03 INFO 140356611028800] Epoch[105] Batch[0] avg_epoch_loss=-1.917648\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=-1.91764816871\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:14 INFO 140356611028800] Epoch[105] Batch[5] avg_epoch_loss=-1.915409\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:14 INFO 140356611028800] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=-1.91540894142\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:14 INFO 140356611028800] Epoch[105] Batch [5]#011Speed: 88.15 samples/sec#011loss=-1.915409\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:26 INFO 140356611028800] Epoch[105] Batch[10] avg_epoch_loss=-1.919430\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:26 INFO 140356611028800] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=-1.92425425603\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:26 INFO 140356611028800] Epoch[105] Batch [10]#011Speed: 88.21 samples/sec#011loss=-1.924254\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:26 INFO 140356611028800] processed a total of 2133 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26352.272033691406, \"sum\": 26352.272033691406, \"min\": 26352.272033691406}}, \"EndTime\": 1600543406.774961, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543380.422377}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:26 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.9415105705 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:26 INFO 140356611028800] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:26 INFO 140356611028800] #quality_metric: host=algo-1, epoch=105, train loss <loss>=-1.91942953897\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:29 INFO 140356611028800] Epoch[106] Batch[0] avg_epoch_loss=-1.920020\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:29 INFO 140356611028800] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=-1.92001958994\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:41 INFO 140356611028800] Epoch[106] Batch[5] avg_epoch_loss=-1.919680\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:41 INFO 140356611028800] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=-1.91968020415\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:41 INFO 140356611028800] Epoch[106] Batch [5]#011Speed: 88.14 samples/sec#011loss=-1.919680\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:53 INFO 140356611028800] Epoch[106] Batch[10] avg_epoch_loss=-1.922893\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:53 INFO 140356611028800] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=-1.92674751282\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:53 INFO 140356611028800] Epoch[106] Batch [10]#011Speed: 87.70 samples/sec#011loss=-1.926748\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:53 INFO 140356611028800] processed a total of 2095 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26390.726804733276, \"sum\": 26390.726804733276, \"min\": 26390.726804733276}}, \"EndTime\": 1600543433.166029, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543406.775022}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:53 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.3836794522 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:53 INFO 140356611028800] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:53 INFO 140356611028800] #quality_metric: host=algo-1, epoch=106, train loss <loss>=-1.92289261718\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:55 INFO 140356611028800] Epoch[107] Batch[0] avg_epoch_loss=-1.916701\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:23:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=-1.9167006566\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:07 INFO 140356611028800] Epoch[107] Batch[5] avg_epoch_loss=-1.919929\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:07 INFO 140356611028800] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=-1.91992874635\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:07 INFO 140356611028800] Epoch[107] Batch [5]#011Speed: 87.45 samples/sec#011loss=-1.919929\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:19 INFO 140356611028800] Epoch[107] Batch[10] avg_epoch_loss=-1.928909\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=-1.93968590956\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:19 INFO 140356611028800] Epoch[107] Batch [10]#011Speed: 87.95 samples/sec#011loss=-1.939686\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:19 INFO 140356611028800] processed a total of 2083 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26472.73898124695, \"sum\": 26472.73898124695, \"min\": 26472.73898124695}}, \"EndTime\": 1600543459.639057, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543433.166089}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:19 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.6844741714 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:19 INFO 140356611028800] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=107, train loss <loss>=-1.92890927508\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:22 INFO 140356611028800] Epoch[108] Batch[0] avg_epoch_loss=-1.845752\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=-1.84575242263\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:34 INFO 140356611028800] Epoch[108] Batch[5] avg_epoch_loss=-1.798039\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=-1.79803946079\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:34 INFO 140356611028800] Epoch[108] Batch [5]#011Speed: 87.54 samples/sec#011loss=-1.798039\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:43 INFO 140356611028800] processed a total of 2058 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24090.306043624878, \"sum\": 24090.306043624878, \"min\": 24090.306043624878}}, \"EndTime\": 1600543483.729733, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543459.639108}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:43 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.4281815474 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:43 INFO 140356611028800] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=108, train loss <loss>=-1.81638711783\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:46 INFO 140356611028800] Epoch[109] Batch[0] avg_epoch_loss=-1.830827\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=-1.83082712614\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:58 INFO 140356611028800] Epoch[109] Batch[5] avg_epoch_loss=-1.869135\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=-1.86913509858\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:24:58 INFO 140356611028800] Epoch[109] Batch [5]#011Speed: 87.86 samples/sec#011loss=-1.869135\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:10 INFO 140356611028800] Epoch[109] Batch[10] avg_epoch_loss=-1.872057\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=-1.87556293194\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:10 INFO 140356611028800] Epoch[109] Batch [10]#011Speed: 87.35 samples/sec#011loss=-1.875563\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:10 INFO 140356611028800] processed a total of 2110 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26478.68299484253, \"sum\": 26478.68299484253, \"min\": 26478.68299484253}}, \"EndTime\": 1600543510.20891, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543483.729802}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:10 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.6864657846 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:10 INFO 140356611028800] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=109, train loss <loss>=-1.87205684102\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:12 INFO 140356611028800] Epoch[110] Batch[0] avg_epoch_loss=-1.924248\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:12 INFO 140356611028800] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=-1.9242477417\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:24 INFO 140356611028800] Epoch[110] Batch[5] avg_epoch_loss=-1.883465\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:24 INFO 140356611028800] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=-1.88346510667\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:24 INFO 140356611028800] Epoch[110] Batch [5]#011Speed: 88.01 samples/sec#011loss=-1.883465\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:34 INFO 140356611028800] processed a total of 1992 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24061.12003326416, \"sum\": 24061.12003326416, \"min\": 24061.12003326416}}, \"EndTime\": 1600543534.270337, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543510.208973}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:34 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.7887918666 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:34 INFO 140356611028800] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=110, train loss <loss>=-1.89668265123\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:37 INFO 140356611028800] Epoch[111] Batch[0] avg_epoch_loss=-1.902818\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=-1.90281809293\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:48 INFO 140356611028800] Epoch[111] Batch[5] avg_epoch_loss=-1.885288\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:48 INFO 140356611028800] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=-1.88528816517\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:25:48 INFO 140356611028800] Epoch[111] Batch [5]#011Speed: 87.48 samples/sec#011loss=-1.885288\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:00 INFO 140356611028800] Epoch[111] Batch[10] avg_epoch_loss=-1.892867\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:00 INFO 140356611028800] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=-1.90196166405\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:00 INFO 140356611028800] Epoch[111] Batch [10]#011Speed: 87.67 samples/sec#011loss=-1.901962\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:00 INFO 140356611028800] processed a total of 2113 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26512.712001800537, \"sum\": 26512.712001800537, \"min\": 26512.712001800537}}, \"EndTime\": 1600543560.783658, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543534.27041}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:00 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.6973473462 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:00 INFO 140356611028800] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:00 INFO 140356611028800] #quality_metric: host=algo-1, epoch=111, train loss <loss>=-1.8928670283\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:03 INFO 140356611028800] Epoch[112] Batch[0] avg_epoch_loss=-1.908990\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=-1.90898968623\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:15 INFO 140356611028800] Epoch[112] Batch[5] avg_epoch_loss=-1.911514\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:15 INFO 140356611028800] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=-1.91151393988\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:15 INFO 140356611028800] Epoch[112] Batch [5]#011Speed: 87.45 samples/sec#011loss=-1.911514\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:24 INFO 140356611028800] processed a total of 2048 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24133.189916610718, \"sum\": 24133.189916610718, \"min\": 24133.189916610718}}, \"EndTime\": 1600543584.917207, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543560.783714}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:24 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.8620415441 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:24 INFO 140356611028800] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:24 INFO 140356611028800] #quality_metric: host=algo-1, epoch=112, train loss <loss>=-1.91588083414\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:27 INFO 140356611028800] Epoch[113] Batch[0] avg_epoch_loss=-1.922851\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:27 INFO 140356611028800] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=-1.92285141578\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:39 INFO 140356611028800] Epoch[113] Batch[5] avg_epoch_loss=-1.919857\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:39 INFO 140356611028800] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=-1.91985726968\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:39 INFO 140356611028800] Epoch[113] Batch [5]#011Speed: 86.63 samples/sec#011loss=-1.919857\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:51 INFO 140356611028800] Epoch[113] Batch[10] avg_epoch_loss=-1.912301\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=-1.903233132\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:51 INFO 140356611028800] Epoch[113] Batch [10]#011Speed: 88.20 samples/sec#011loss=-1.903233\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:51 INFO 140356611028800] processed a total of 2114 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26566.484928131104, \"sum\": 26566.484928131104, \"min\": 26566.484928131104}}, \"EndTime\": 1600543611.484071, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543584.917274}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:51 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.5736660947 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:51 INFO 140356611028800] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=113, train loss <loss>=-1.91230084346\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:54 INFO 140356611028800] Epoch[114] Batch[0] avg_epoch_loss=-1.905173\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:26:54 INFO 140356611028800] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=-1.9051729349\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:06 INFO 140356611028800] Epoch[114] Batch[5] avg_epoch_loss=-1.905494\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:06 INFO 140356611028800] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=-1.90549385853\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:06 INFO 140356611028800] Epoch[114] Batch [5]#011Speed: 87.78 samples/sec#011loss=-1.905494\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:17 INFO 140356611028800] Epoch[114] Batch[10] avg_epoch_loss=-1.913628\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=-1.92338946416\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:17 INFO 140356611028800] Epoch[114] Batch [10]#011Speed: 88.02 samples/sec#011loss=-1.923389\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:17 INFO 140356611028800] processed a total of 2095 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26395.364999771118, \"sum\": 26395.364999771118, \"min\": 26395.364999771118}}, \"EndTime\": 1600543637.879817, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543611.484135}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:17 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.3697244589 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:17 INFO 140356611028800] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=114, train loss <loss>=-1.91362822473\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:20 INFO 140356611028800] Epoch[115] Batch[0] avg_epoch_loss=-1.922848\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:20 INFO 140356611028800] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=-1.92284789452\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:32 INFO 140356611028800] Epoch[115] Batch[5] avg_epoch_loss=-1.909353\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=-1.9093534274\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:32 INFO 140356611028800] Epoch[115] Batch [5]#011Speed: 87.78 samples/sec#011loss=-1.909353\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:41 INFO 140356611028800] processed a total of 2075 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24092.05913543701, \"sum\": 24092.05913543701, \"min\": 24092.05913543701}}, \"EndTime\": 1600543661.972181, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543637.879878}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:41 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.1275923045 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:41 INFO 140356611028800] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:41 INFO 140356611028800] #quality_metric: host=algo-1, epoch=115, train loss <loss>=-1.90922547854\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:44 INFO 140356611028800] Epoch[116] Batch[0] avg_epoch_loss=-1.926830\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=-1.92682955815\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:56 INFO 140356611028800] Epoch[116] Batch[5] avg_epoch_loss=-1.916389\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:56 INFO 140356611028800] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=-1.91638931861\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:27:56 INFO 140356611028800] Epoch[116] Batch [5]#011Speed: 88.41 samples/sec#011loss=-1.916389\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:08 INFO 140356611028800] Epoch[116] Batch[10] avg_epoch_loss=-1.919947\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:08 INFO 140356611028800] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=-1.92421546349\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:08 INFO 140356611028800] Epoch[116] Batch [10]#011Speed: 87.99 samples/sec#011loss=-1.924215\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:08 INFO 140356611028800] processed a total of 2098 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26315.68694114685, \"sum\": 26315.68694114685, \"min\": 26315.68694114685}}, \"EndTime\": 1600543688.288293, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543661.972251}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:08 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.724071545 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:08 INFO 140356611028800] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:08 INFO 140356611028800] #quality_metric: host=algo-1, epoch=116, train loss <loss>=-1.91994665719\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:11 INFO 140356611028800] Epoch[117] Batch[0] avg_epoch_loss=-1.911027\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=-1.91102688129\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:22 INFO 140356611028800] Epoch[117] Batch[5] avg_epoch_loss=-1.891267\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=-1.89126657828\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:22 INFO 140356611028800] Epoch[117] Batch [5]#011Speed: 88.45 samples/sec#011loss=-1.891267\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:32 INFO 140356611028800] processed a total of 2008 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23903.820991516113, \"sum\": 23903.820991516113, \"min\": 23903.820991516113}}, \"EndTime\": 1600543712.192471, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543688.288345}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:32 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.0029478462 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:32 INFO 140356611028800] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=117, train loss <loss>=-1.8909537242\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:34 INFO 140356611028800] Epoch[118] Batch[0] avg_epoch_loss=-1.915355\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=-1.91535480206\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:46 INFO 140356611028800] Epoch[118] Batch[5] avg_epoch_loss=-1.912262\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=-1.91226186508\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:46 INFO 140356611028800] Epoch[118] Batch [5]#011Speed: 88.08 samples/sec#011loss=-1.912262\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:58 INFO 140356611028800] Epoch[118] Batch[10] avg_epoch_loss=-1.904896\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=-1.89605803856\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:58 INFO 140356611028800] Epoch[118] Batch [10]#011Speed: 87.60 samples/sec#011loss=-1.896058\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:58 INFO 140356611028800] processed a total of 2105 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26405.638933181763, \"sum\": 26405.638933181763, \"min\": 26405.638933181763}}, \"EndTime\": 1600543738.598548, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543712.19254}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:58 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.7175518846 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:58 INFO 140356611028800] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:28:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=118, train loss <loss>=-1.90489648939\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:01 INFO 140356611028800] Epoch[119] Batch[0] avg_epoch_loss=-1.926555\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:01 INFO 140356611028800] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=-1.92655475323\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:13 INFO 140356611028800] Epoch[119] Batch[5] avg_epoch_loss=-1.905328\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:13 INFO 140356611028800] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=-1.90532799256\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:13 INFO 140356611028800] Epoch[119] Batch [5]#011Speed: 87.69 samples/sec#011loss=-1.905328\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:25 INFO 140356611028800] Epoch[119] Batch[10] avg_epoch_loss=-1.909838\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=-1.91524954576\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:25 INFO 140356611028800] Epoch[119] Batch [10]#011Speed: 88.09 samples/sec#011loss=-1.915250\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:25 INFO 140356611028800] processed a total of 2146 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26446.587800979614, \"sum\": 26446.587800979614, \"min\": 26446.587800979614}}, \"EndTime\": 1600543765.045485, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543738.598607}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:25 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.1444283201 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:25 INFO 140356611028800] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=119, train loss <loss>=-1.90983778947\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:27 INFO 140356611028800] Epoch[120] Batch[0] avg_epoch_loss=-1.926122\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:27 INFO 140356611028800] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=-1.92612207853\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:39 INFO 140356611028800] Epoch[120] Batch[5] avg_epoch_loss=-1.918746\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:39 INFO 140356611028800] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=-1.9187458234\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:39 INFO 140356611028800] Epoch[120] Batch [5]#011Speed: 87.59 samples/sec#011loss=-1.918746\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:51 INFO 140356611028800] Epoch[120] Batch[10] avg_epoch_loss=-1.921160\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=-1.92405732962\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:51 INFO 140356611028800] Epoch[120] Batch [10]#011Speed: 87.70 samples/sec#011loss=-1.924057\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:51 INFO 140356611028800] processed a total of 2182 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26519.2449092865, \"sum\": 26519.2449092865, \"min\": 26519.2449092865}}, \"EndTime\": 1600543791.565048, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543765.045542}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:51 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.2795835745 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:51 INFO 140356611028800] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=120, train loss <loss>=-1.92116014441\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:54 INFO 140356611028800] Epoch[121] Batch[0] avg_epoch_loss=-1.912425\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:29:54 INFO 140356611028800] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=-1.912425408\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:06 INFO 140356611028800] Epoch[121] Batch[5] avg_epoch_loss=-1.907234\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:06 INFO 140356611028800] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=-1.90723421635\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:06 INFO 140356611028800] Epoch[121] Batch [5]#011Speed: 87.20 samples/sec#011loss=-1.907234\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:18 INFO 140356611028800] Epoch[121] Batch[10] avg_epoch_loss=-1.913897\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:18 INFO 140356611028800] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=-1.92189289973\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:18 INFO 140356611028800] Epoch[121] Batch [10]#011Speed: 87.73 samples/sec#011loss=-1.921893\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:18 INFO 140356611028800] processed a total of 2168 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26541.229009628296, \"sum\": 26541.229009628296, \"min\": 26541.229009628296}}, \"EndTime\": 1600543818.106732, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543791.565106}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:18 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.6839617731 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:18 INFO 140356611028800] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:18 INFO 140356611028800] #quality_metric: host=algo-1, epoch=121, train loss <loss>=-1.91389725425\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:20 INFO 140356611028800] Epoch[122] Batch[0] avg_epoch_loss=-1.884264\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:20 INFO 140356611028800] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=-1.88426355215\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:32 INFO 140356611028800] Epoch[122] Batch[5] avg_epoch_loss=-1.908431\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=-1.90843090644\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:32 INFO 140356611028800] Epoch[122] Batch [5]#011Speed: 87.41 samples/sec#011loss=-1.908431\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:44 INFO 140356611028800] Epoch[122] Batch[10] avg_epoch_loss=-1.918240\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=-1.93000998864\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:44 INFO 140356611028800] Epoch[122] Batch [10]#011Speed: 87.63 samples/sec#011loss=-1.930010\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:44 INFO 140356611028800] processed a total of 2107 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26512.73488998413, \"sum\": 26512.73488998413, \"min\": 26512.73488998413}}, \"EndTime\": 1600543844.619869, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543818.106792}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:44 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.470970115 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:44 INFO 140356611028800] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=122, train loss <loss>=-1.91823958017\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:47 INFO 140356611028800] Epoch[123] Batch[0] avg_epoch_loss=-1.934445\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:47 INFO 140356611028800] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=-1.9344453078\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:59 INFO 140356611028800] Epoch[123] Batch[5] avg_epoch_loss=-1.897004\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:59 INFO 140356611028800] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=-1.89700405414\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:30:59 INFO 140356611028800] Epoch[123] Batch [5]#011Speed: 87.77 samples/sec#011loss=-1.897004\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:11 INFO 140356611028800] Epoch[123] Batch[10] avg_epoch_loss=-1.906819\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=-1.91859703064\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:11 INFO 140356611028800] Epoch[123] Batch [10]#011Speed: 87.42 samples/sec#011loss=-1.918597\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:11 INFO 140356611028800] processed a total of 2106 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26509.96708869934, \"sum\": 26509.96708869934, \"min\": 26509.96708869934}}, \"EndTime\": 1600543871.130135, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543844.61993}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:11 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.4415493782 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:11 INFO 140356611028800] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=123, train loss <loss>=-1.90681904346\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:13 INFO 140356611028800] Epoch[124] Batch[0] avg_epoch_loss=-1.871965\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:13 INFO 140356611028800] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=-1.87196526161\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:25 INFO 140356611028800] Epoch[124] Batch[5] avg_epoch_loss=-1.871901\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=-1.87190072964\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:25 INFO 140356611028800] Epoch[124] Batch [5]#011Speed: 87.58 samples/sec#011loss=-1.871901\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:37 INFO 140356611028800] Epoch[124] Batch[10] avg_epoch_loss=-1.896585\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=-1.92620603121\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:37 INFO 140356611028800] Epoch[124] Batch [10]#011Speed: 87.58 samples/sec#011loss=-1.926206\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:37 INFO 140356611028800] processed a total of 2082 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26565.43779373169, \"sum\": 26565.43779373169, \"min\": 26565.43779373169}}, \"EndTime\": 1600543897.695865, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543871.130196}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:37 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.3722454652 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:37 INFO 140356611028800] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=124, train loss <loss>=-1.89658495763\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:40 INFO 140356611028800] Epoch[125] Batch[0] avg_epoch_loss=-1.854043\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:40 INFO 140356611028800] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=-1.85404337369\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:52 INFO 140356611028800] Epoch[125] Batch[5] avg_epoch_loss=-1.888758\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:52 INFO 140356611028800] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=-1.88875753452\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:31:52 INFO 140356611028800] Epoch[125] Batch [5]#011Speed: 86.81 samples/sec#011loss=-1.888758\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:01 INFO 140356611028800] processed a total of 2080 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24212.472200393677, \"sum\": 24212.472200393677, \"min\": 24212.472200393677}}, \"EndTime\": 1600543921.908627, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543897.695926}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:01 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.9057531676 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:01 INFO 140356611028800] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:01 INFO 140356611028800] #quality_metric: host=algo-1, epoch=125, train loss <loss>=-1.89606111967\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:04 INFO 140356611028800] Epoch[126] Batch[0] avg_epoch_loss=-1.923125\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=-1.92312490023\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:16 INFO 140356611028800] Epoch[126] Batch[5] avg_epoch_loss=-1.920810\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:16 INFO 140356611028800] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=-1.92081043048\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:16 INFO 140356611028800] Epoch[126] Batch [5]#011Speed: 87.78 samples/sec#011loss=-1.920810\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:28 INFO 140356611028800] Epoch[126] Batch[10] avg_epoch_loss=-1.926941\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=126, batch=10 train loss <loss>=-1.93429811918\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:28 INFO 140356611028800] Epoch[126] Batch [10]#011Speed: 87.86 samples/sec#011loss=-1.934298\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:28 INFO 140356611028800] processed a total of 2115 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26456.45308494568, \"sum\": 26456.45308494568, \"min\": 26456.45308494568}}, \"EndTime\": 1600543948.365475, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543921.908705}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:28 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.942420245 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:28 INFO 140356611028800] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=126, train loss <loss>=-1.92694119807\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:31 INFO 140356611028800] Epoch[127] Batch[0] avg_epoch_loss=-1.908552\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:31 INFO 140356611028800] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=-1.90855246324\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:42 INFO 140356611028800] Epoch[127] Batch[5] avg_epoch_loss=-1.912153\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:42 INFO 140356611028800] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=-1.91215331738\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:42 INFO 140356611028800] Epoch[127] Batch [5]#011Speed: 87.65 samples/sec#011loss=-1.912153\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:54 INFO 140356611028800] Epoch[127] Batch[10] avg_epoch_loss=-1.910176\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:54 INFO 140356611028800] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=-1.90780363816\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:54 INFO 140356611028800] Epoch[127] Batch [10]#011Speed: 88.40 samples/sec#011loss=-1.907804\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:54 INFO 140356611028800] processed a total of 2106 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26381.09302520752, \"sum\": 26381.09302520752, \"min\": 26381.09302520752}}, \"EndTime\": 1600543974.746883, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543948.365537}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:54 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.8296294886 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:54 INFO 140356611028800] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:54 INFO 140356611028800] #quality_metric: host=algo-1, epoch=127, train loss <loss>=-1.91017619046\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:57 INFO 140356611028800] Epoch[128] Batch[0] avg_epoch_loss=-1.860777\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:32:57 INFO 140356611028800] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=-1.86077748812\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:09 INFO 140356611028800] Epoch[128] Batch[5] avg_epoch_loss=-1.860231\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:09 INFO 140356611028800] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=-1.86023088602\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:09 INFO 140356611028800] Epoch[128] Batch [5]#011Speed: 87.78 samples/sec#011loss=-1.860231\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:21 INFO 140356611028800] Epoch[128] Batch[10] avg_epoch_loss=-1.887754\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:21 INFO 140356611028800] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=-1.92078112089\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:21 INFO 140356611028800] Epoch[128] Batch [10]#011Speed: 88.43 samples/sec#011loss=-1.920781\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:21 INFO 140356611028800] processed a total of 2131 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26340.386152267456, \"sum\": 26340.386152267456, \"min\": 26340.386152267456}}, \"EndTime\": 1600544001.087617, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600543974.746942}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:21 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.9021095228 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:21 INFO 140356611028800] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:21 INFO 140356611028800] #quality_metric: host=algo-1, epoch=128, train loss <loss>=-1.88775372005\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:23 INFO 140356611028800] Epoch[129] Batch[0] avg_epoch_loss=-1.905403\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:23 INFO 140356611028800] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=-1.90540284377\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:35 INFO 140356611028800] Epoch[129] Batch[5] avg_epoch_loss=-1.820442\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:35 INFO 140356611028800] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=-1.82044158838\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:35 INFO 140356611028800] Epoch[129] Batch [5]#011Speed: 88.34 samples/sec#011loss=-1.820442\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:47 INFO 140356611028800] Epoch[129] Batch[10] avg_epoch_loss=-1.779639\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:47 INFO 140356611028800] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=-1.73067500775\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:47 INFO 140356611028800] Epoch[129] Batch [10]#011Speed: 88.14 samples/sec#011loss=-1.730675\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:47 INFO 140356611028800] processed a total of 2088 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26319.03100013733, \"sum\": 26319.03100013733, \"min\": 26319.03100013733}}, \"EndTime\": 1600544027.406931, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544001.087677}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:47 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.3339568296 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:47 INFO 140356611028800] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:47 INFO 140356611028800] #quality_metric: host=algo-1, epoch=129, train loss <loss>=-1.77963859718\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:50 INFO 140356611028800] Epoch[130] Batch[0] avg_epoch_loss=-1.812192\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:33:50 INFO 140356611028800] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=-1.81219188984\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:02 INFO 140356611028800] Epoch[130] Batch[5] avg_epoch_loss=-1.782673\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=-1.78267332224\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:02 INFO 140356611028800] Epoch[130] Batch [5]#011Speed: 87.95 samples/sec#011loss=-1.782673\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:13 INFO 140356611028800] Epoch[130] Batch[10] avg_epoch_loss=-1.806556\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:13 INFO 140356611028800] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=-1.83521537781\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:13 INFO 140356611028800] Epoch[130] Batch [10]#011Speed: 87.35 samples/sec#011loss=-1.835215\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:13 INFO 140356611028800] processed a total of 2125 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26510.92505455017, \"sum\": 26510.92505455017, \"min\": 26510.92505455017}}, \"EndTime\": 1600544053.918155, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544027.406992}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:13 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.1553468858 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:13 INFO 140356611028800] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:13 INFO 140356611028800] #quality_metric: host=algo-1, epoch=130, train loss <loss>=-1.80655607477\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:16 INFO 140356611028800] Epoch[131] Batch[0] avg_epoch_loss=-1.863654\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:16 INFO 140356611028800] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=-1.86365376986\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:28 INFO 140356611028800] Epoch[131] Batch[5] avg_epoch_loss=-1.881368\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=-1.88136792794\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:28 INFO 140356611028800] Epoch[131] Batch [5]#011Speed: 87.88 samples/sec#011loss=-1.881368\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:40 INFO 140356611028800] Epoch[131] Batch[10] avg_epoch_loss=-1.894052\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:40 INFO 140356611028800] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=-1.90927391052\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:40 INFO 140356611028800] Epoch[131] Batch [10]#011Speed: 87.45 samples/sec#011loss=-1.909274\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:40 INFO 140356611028800] processed a total of 2104 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26457.88288116455, \"sum\": 26457.88288116455, \"min\": 26457.88288116455}}, \"EndTime\": 1600544080.376417, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544053.918219}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:40 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.5223277905 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:40 INFO 140356611028800] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:40 INFO 140356611028800] #quality_metric: host=algo-1, epoch=131, train loss <loss>=-1.89405246548\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:43 INFO 140356611028800] Epoch[132] Batch[0] avg_epoch_loss=-1.909875\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=-1.909874696\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:54 INFO 140356611028800] Epoch[132] Batch[5] avg_epoch_loss=-1.899663\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:54 INFO 140356611028800] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=-1.89966346056\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:34:54 INFO 140356611028800] Epoch[132] Batch [5]#011Speed: 87.83 samples/sec#011loss=-1.899663\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:04 INFO 140356611028800] processed a total of 2048 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24065.32883644104, \"sum\": 24065.32883644104, \"min\": 24065.32883644104}}, \"EndTime\": 1600544104.442126, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544080.37648}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:04 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.1013151453 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:04 INFO 140356611028800] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=132, train loss <loss>=-1.90375609765\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:07 INFO 140356611028800] Epoch[133] Batch[0] avg_epoch_loss=-1.899462\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:07 INFO 140356611028800] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=-1.8994615995\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:19 INFO 140356611028800] Epoch[133] Batch[5] avg_epoch_loss=-1.908684\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=-1.908684486\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:19 INFO 140356611028800] Epoch[133] Batch [5]#011Speed: 87.74 samples/sec#011loss=-1.908684\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:28 INFO 140356611028800] processed a total of 2079 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24044.044971466064, \"sum\": 24044.044971466064, \"min\": 24044.044971466064}}, \"EndTime\": 1600544128.486592, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544104.442196}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:28 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.4659674412 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:28 INFO 140356611028800] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=133, train loss <loss>=-1.91125978323\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:31 INFO 140356611028800] Epoch[134] Batch[0] avg_epoch_loss=-1.916597\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:31 INFO 140356611028800] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=-1.91659721961\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:43 INFO 140356611028800] Epoch[134] Batch[5] avg_epoch_loss=-1.914856\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=-1.91485647055\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:43 INFO 140356611028800] Epoch[134] Batch [5]#011Speed: 86.76 samples/sec#011loss=-1.914856\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:55 INFO 140356611028800] Epoch[134] Batch[10] avg_epoch_loss=-1.913729\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=-1.91237514202\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:55 INFO 140356611028800] Epoch[134] Batch [10]#011Speed: 87.74 samples/sec#011loss=-1.912375\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:55 INFO 140356611028800] processed a total of 2151 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26626.394033432007, \"sum\": 26626.394033432007, \"min\": 26626.394033432007}}, \"EndTime\": 1600544155.113386, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544128.486659}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:55 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.7841959699 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:55 INFO 140356611028800] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=134, train loss <loss>=-1.91372859395\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:57 INFO 140356611028800] Epoch[135] Batch[0] avg_epoch_loss=-1.897770\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:35:57 INFO 140356611028800] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=-1.89776978126\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:09 INFO 140356611028800] Epoch[135] Batch[5] avg_epoch_loss=-1.899763\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:09 INFO 140356611028800] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=-1.89976283831\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:09 INFO 140356611028800] Epoch[135] Batch [5]#011Speed: 87.55 samples/sec#011loss=-1.899763\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:21 INFO 140356611028800] Epoch[135] Batch[10] avg_epoch_loss=-1.911623\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:21 INFO 140356611028800] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=-1.925854903\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:21 INFO 140356611028800] Epoch[135] Batch [10]#011Speed: 87.41 samples/sec#011loss=-1.925855\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:21 INFO 140356611028800] processed a total of 2124 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26516.72387123108, \"sum\": 26516.72387123108, \"min\": 26516.72387123108}}, \"EndTime\": 1600544181.630416, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544155.113446}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:21 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.1000241387 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:21 INFO 140356611028800] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:21 INFO 140356611028800] #quality_metric: host=algo-1, epoch=135, train loss <loss>=-1.91162286772\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:24 INFO 140356611028800] Epoch[136] Batch[0] avg_epoch_loss=-1.918291\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:24 INFO 140356611028800] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=-1.9182909452\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:36 INFO 140356611028800] Epoch[136] Batch[5] avg_epoch_loss=-1.917670\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=-1.91767005431\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:36 INFO 140356611028800] Epoch[136] Batch [5]#011Speed: 88.06 samples/sec#011loss=-1.917670\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:45 INFO 140356611028800] processed a total of 2077 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24056.608200073242, \"sum\": 24056.608200073242, \"min\": 24056.608200073242}}, \"EndTime\": 1600544205.68736, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544181.630509}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:45 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.3374825473 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:45 INFO 140356611028800] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:45 INFO 140356611028800] #quality_metric: host=algo-1, epoch=136, train loss <loss>=-1.91955447564\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:48 INFO 140356611028800] Epoch[137] Batch[0] avg_epoch_loss=-1.920865\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:36:48 INFO 140356611028800] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=-1.9208654257\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:00 INFO 140356611028800] Epoch[137] Batch[5] avg_epoch_loss=-1.918894\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:00 INFO 140356611028800] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=-1.91889356956\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:00 INFO 140356611028800] Epoch[137] Batch [5]#011Speed: 87.61 samples/sec#011loss=-1.918894\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:12 INFO 140356611028800] Epoch[137] Batch[10] avg_epoch_loss=-1.882621\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:12 INFO 140356611028800] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=-1.83909445543\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:12 INFO 140356611028800] Epoch[137] Batch [10]#011Speed: 87.61 samples/sec#011loss=-1.839094\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:12 INFO 140356611028800] processed a total of 2124 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26491.584062576294, \"sum\": 26491.584062576294, \"min\": 26491.584062576294}}, \"EndTime\": 1600544232.179408, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544205.68748}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:12 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.1761217255 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:12 INFO 140356611028800] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:12 INFO 140356611028800] #quality_metric: host=algo-1, epoch=137, train loss <loss>=-1.88262124495\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:14 INFO 140356611028800] Epoch[138] Batch[0] avg_epoch_loss=-1.868604\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:14 INFO 140356611028800] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=-1.8686043666\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:26 INFO 140356611028800] Epoch[138] Batch[5] avg_epoch_loss=-1.870815\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:26 INFO 140356611028800] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=-1.87081498366\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:26 INFO 140356611028800] Epoch[138] Batch [5]#011Speed: 86.91 samples/sec#011loss=-1.870815\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:38 INFO 140356611028800] Epoch[138] Batch[10] avg_epoch_loss=-1.884796\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:38 INFO 140356611028800] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=-1.90157297575\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:38 INFO 140356611028800] Epoch[138] Batch [10]#011Speed: 87.61 samples/sec#011loss=-1.901573\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:38 INFO 140356611028800] processed a total of 2159 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26584.967136383057, \"sum\": 26584.967136383057, \"min\": 26584.967136383057}}, \"EndTime\": 1600544258.764753, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544232.17947}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:38 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.2110351451 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:38 INFO 140356611028800] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:38 INFO 140356611028800] #quality_metric: host=algo-1, epoch=138, train loss <loss>=-1.88479588915\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:41 INFO 140356611028800] Epoch[139] Batch[0] avg_epoch_loss=-1.916382\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:41 INFO 140356611028800] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=-1.91638198266\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:53 INFO 140356611028800] Epoch[139] Batch[5] avg_epoch_loss=-1.916224\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:53 INFO 140356611028800] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=-1.91622413733\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:37:53 INFO 140356611028800] Epoch[139] Batch [5]#011Speed: 88.34 samples/sec#011loss=-1.916224\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:02 INFO 140356611028800] processed a total of 2053 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23968.74499320984, \"sum\": 23968.74499320984, \"min\": 23968.74499320984}}, \"EndTime\": 1600544282.733803, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544258.764814}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:02 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.6528475018 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:02 INFO 140356611028800] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=139, train loss <loss>=-1.91612001566\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:05 INFO 140356611028800] Epoch[140] Batch[0] avg_epoch_loss=-1.926660\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:05 INFO 140356611028800] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=-1.926660391\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:17 INFO 140356611028800] Epoch[140] Batch[5] avg_epoch_loss=-1.915338\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=-1.91533817389\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:17 INFO 140356611028800] Epoch[140] Batch [5]#011Speed: 88.16 samples/sec#011loss=-1.915338\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:29 INFO 140356611028800] Epoch[140] Batch[10] avg_epoch_loss=-1.911585\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:29 INFO 140356611028800] #quality_metric: host=algo-1, epoch=140, batch=10 train loss <loss>=-1.90708043025\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:29 INFO 140356611028800] Epoch[140] Batch [10]#011Speed: 88.32 samples/sec#011loss=-1.907080\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:29 INFO 140356611028800] processed a total of 2127 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26309.482097625732, \"sum\": 26309.482097625732, \"min\": 26309.482097625732}}, \"EndTime\": 1600544309.043729, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544282.733875}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:29 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.8450913199 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:29 INFO 140356611028800] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:29 INFO 140356611028800] #quality_metric: host=algo-1, epoch=140, train loss <loss>=-1.91158465405\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:31 INFO 140356611028800] Epoch[141] Batch[0] avg_epoch_loss=-1.890090\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:31 INFO 140356611028800] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=-1.89008976863\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:43 INFO 140356611028800] Epoch[141] Batch[5] avg_epoch_loss=-1.868275\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=-1.86827507997\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:43 INFO 140356611028800] Epoch[141] Batch [5]#011Speed: 88.04 samples/sec#011loss=-1.868275\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:55 INFO 140356611028800] Epoch[141] Batch[10] avg_epoch_loss=-1.890603\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=-1.91739727901\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:55 INFO 140356611028800] Epoch[141] Batch [10]#011Speed: 88.18 samples/sec#011loss=-1.917397\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:55 INFO 140356611028800] processed a total of 2142 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26333.33420753479, \"sum\": 26333.33420753479, \"min\": 26333.33420753479}}, \"EndTime\": 1600544335.377407, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544309.043794}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:55 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.3415050641 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:55 INFO 140356611028800] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=141, train loss <loss>=-1.89060335226\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:58 INFO 140356611028800] Epoch[142] Batch[0] avg_epoch_loss=-1.893087\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:38:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=-1.89308709365\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:10 INFO 140356611028800] Epoch[142] Batch[5] avg_epoch_loss=-1.873823\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=-1.87382343488\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:10 INFO 140356611028800] Epoch[142] Batch [5]#011Speed: 87.15 samples/sec#011loss=-1.873823\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:19 INFO 140356611028800] processed a total of 2054 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24169.930934906006, \"sum\": 24169.930934906006, \"min\": 24169.930934906006}}, \"EndTime\": 1600544359.547663, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544335.377463}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:19 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.9811359958 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:19 INFO 140356611028800] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=142, train loss <loss>=-1.88338662661\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:22 INFO 140356611028800] Epoch[143] Batch[0] avg_epoch_loss=-1.898024\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=-1.89802448566\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:35 INFO 140356611028800] Epoch[143] Batch[5] avg_epoch_loss=-1.907553\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:35 INFO 140356611028800] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=-1.90755306146\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:35 INFO 140356611028800] Epoch[143] Batch [5]#011Speed: 81.79 samples/sec#011loss=-1.907553\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:45 INFO 140356611028800] processed a total of 2077 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 25467.978954315186, \"sum\": 25467.978954315186, \"min\": 25467.978954315186}}, \"EndTime\": 1600544385.016063, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544359.547772}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:45 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.5529441118 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:45 INFO 140356611028800] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:45 INFO 140356611028800] #quality_metric: host=algo-1, epoch=143, train loss <loss>=-1.91201584156\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:47 INFO 140356611028800] Epoch[144] Batch[0] avg_epoch_loss=-1.921931\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:47 INFO 140356611028800] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=-1.92193119343\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:59 INFO 140356611028800] Epoch[144] Batch[5] avg_epoch_loss=-1.922556\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:59 INFO 140356611028800] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=-1.92255575229\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:39:59 INFO 140356611028800] Epoch[144] Batch [5]#011Speed: 87.93 samples/sec#011loss=-1.922556\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:11 INFO 140356611028800] Epoch[144] Batch[10] avg_epoch_loss=-1.925055\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=-1.92805413466\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:11 INFO 140356611028800] Epoch[144] Batch [10]#011Speed: 87.41 samples/sec#011loss=-1.928054\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:11 INFO 140356611028800] processed a total of 2169 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26495.94521522522, \"sum\": 26495.94521522522, \"min\": 26495.94521522522}}, \"EndTime\": 1600544411.512419, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544385.016171}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:11 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.8612957632 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:11 INFO 140356611028800] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=144, train loss <loss>=-1.925055017\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:14 INFO 140356611028800] Epoch[145] Batch[0] avg_epoch_loss=-1.912555\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:14 INFO 140356611028800] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=-1.91255452083\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:26 INFO 140356611028800] Epoch[145] Batch[5] avg_epoch_loss=-1.914007\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:26 INFO 140356611028800] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=-1.91400706462\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:26 INFO 140356611028800] Epoch[145] Batch [5]#011Speed: 87.84 samples/sec#011loss=-1.914007\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:35 INFO 140356611028800] processed a total of 2038 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24072.453022003174, \"sum\": 24072.453022003174, \"min\": 24072.453022003174}}, \"EndTime\": 1600544435.585249, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544411.51248}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:35 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.6607759493 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:35 INFO 140356611028800] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:35 INFO 140356611028800] #quality_metric: host=algo-1, epoch=145, train loss <loss>=-1.91574872824\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:38 INFO 140356611028800] Epoch[146] Batch[0] avg_epoch_loss=-1.918640\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:38 INFO 140356611028800] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=-1.91864043016\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:50 INFO 140356611028800] Epoch[146] Batch[5] avg_epoch_loss=-1.920697\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:50 INFO 140356611028800] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=-1.92069696769\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:40:50 INFO 140356611028800] Epoch[146] Batch [5]#011Speed: 86.99 samples/sec#011loss=-1.920697\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:02 INFO 140356611028800] Epoch[146] Batch[10] avg_epoch_loss=-1.924798\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=146, batch=10 train loss <loss>=-1.92971857511\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:02 INFO 140356611028800] Epoch[146] Batch [10]#011Speed: 87.87 samples/sec#011loss=-1.929719\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:02 INFO 140356611028800] processed a total of 2166 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26548.274040222168, \"sum\": 26548.274040222168, \"min\": 26548.274040222168}}, \"EndTime\": 1600544462.134068, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544435.585311}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:02 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.5869609472 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:02 INFO 140356611028800] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=146, train loss <loss>=-1.92479769833\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:04 INFO 140356611028800] Epoch[147] Batch[0] avg_epoch_loss=-1.872993\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=-1.87299302908\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:16 INFO 140356611028800] Epoch[147] Batch[5] avg_epoch_loss=-1.889731\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:16 INFO 140356611028800] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=-1.88973133381\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:16 INFO 140356611028800] Epoch[147] Batch [5]#011Speed: 87.52 samples/sec#011loss=-1.889731\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:28 INFO 140356611028800] Epoch[147] Batch[10] avg_epoch_loss=-1.907049\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=-1.92782956637\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:28 INFO 140356611028800] Epoch[147] Batch [10]#011Speed: 87.69 samples/sec#011loss=-1.927830\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:28 INFO 140356611028800] processed a total of 2097 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26503.0300617218, \"sum\": 26503.0300617218, \"min\": 26503.0300617218}}, \"EndTime\": 1600544488.637465, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544462.134123}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:28 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.1227685903 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:28 INFO 140356611028800] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=147, train loss <loss>=-1.90704871224\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:31 INFO 140356611028800] Epoch[148] Batch[0] avg_epoch_loss=-1.907220\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:31 INFO 140356611028800] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=-1.90721981342\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:43 INFO 140356611028800] Epoch[148] Batch[5] avg_epoch_loss=-1.780400\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=-1.78039990939\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:43 INFO 140356611028800] Epoch[148] Batch [5]#011Speed: 87.30 samples/sec#011loss=-1.780400\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:55 INFO 140356611028800] Epoch[148] Batch[10] avg_epoch_loss=-1.783012\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=-1.7861466041\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:55 INFO 140356611028800] Epoch[148] Batch [10]#011Speed: 88.13 samples/sec#011loss=-1.786147\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:55 INFO 140356611028800] processed a total of 2100 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26451.472997665405, \"sum\": 26451.472997665405, \"min\": 26451.472997665405}}, \"EndTime\": 1600544515.089264, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544488.637523}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:55 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.3903303486 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:55 INFO 140356611028800] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=148, train loss <loss>=-1.78301204335\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:57 INFO 140356611028800] Epoch[149] Batch[0] avg_epoch_loss=-1.814232\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:41:57 INFO 140356611028800] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=-1.81423201928\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:09 INFO 140356611028800] Epoch[149] Batch[5] avg_epoch_loss=-1.858635\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:09 INFO 140356611028800] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=-1.85863455748\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:09 INFO 140356611028800] Epoch[149] Batch [5]#011Speed: 87.39 samples/sec#011loss=-1.858635\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:21 INFO 140356611028800] Epoch[149] Batch[10] avg_epoch_loss=-1.844303\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:21 INFO 140356611028800] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=-1.82710477389\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:21 INFO 140356611028800] Epoch[149] Batch [10]#011Speed: 88.01 samples/sec#011loss=-1.827105\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:21 INFO 140356611028800] processed a total of 2123 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26437.089920043945, \"sum\": 26437.089920043945, \"min\": 26437.089920043945}}, \"EndTime\": 1600544541.526789, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544515.089343}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:21 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.3035607532 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:21 INFO 140356611028800] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:21 INFO 140356611028800] #quality_metric: host=algo-1, epoch=149, train loss <loss>=-1.84430283767\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:24 INFO 140356611028800] Epoch[150] Batch[0] avg_epoch_loss=-1.896875\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:24 INFO 140356611028800] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=-1.89687538147\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:36 INFO 140356611028800] Epoch[150] Batch[5] avg_epoch_loss=-1.856067\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=-1.85606704614\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:36 INFO 140356611028800] Epoch[150] Batch [5]#011Speed: 87.76 samples/sec#011loss=-1.856067\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:48 INFO 140356611028800] Epoch[150] Batch[10] avg_epoch_loss=-1.883900\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:48 INFO 140356611028800] #quality_metric: host=algo-1, epoch=150, batch=10 train loss <loss>=-1.91729982816\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:48 INFO 140356611028800] Epoch[150] Batch [10]#011Speed: 87.65 samples/sec#011loss=-1.917300\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:48 INFO 140356611028800] processed a total of 2103 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26491.56403541565, \"sum\": 26491.56403541565, \"min\": 26491.56403541565}}, \"EndTime\": 1600544568.018726, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544541.526853}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:48 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.3834285302 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:48 INFO 140356611028800] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:48 INFO 140356611028800] #quality_metric: host=algo-1, epoch=150, train loss <loss>=-1.88390012888\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:50 INFO 140356611028800] Epoch[151] Batch[0] avg_epoch_loss=-1.893709\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:42:50 INFO 140356611028800] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=-1.89370859586\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:02 INFO 140356611028800] Epoch[151] Batch[5] avg_epoch_loss=-1.897384\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=-1.89738447238\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:02 INFO 140356611028800] Epoch[151] Batch [5]#011Speed: 88.28 samples/sec#011loss=-1.897384\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:11 INFO 140356611028800] processed a total of 2060 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23979.835033416748, \"sum\": 23979.835033416748, \"min\": 23979.835033416748}}, \"EndTime\": 1600544591.998917, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544568.018784}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:11 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.905120559 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:11 INFO 140356611028800] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=151, train loss <loss>=-1.90176711449\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:14 INFO 140356611028800] Epoch[152] Batch[0] avg_epoch_loss=-1.906558\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:14 INFO 140356611028800] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=-1.90655752329\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:26 INFO 140356611028800] Epoch[152] Batch[5] avg_epoch_loss=-1.914201\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:26 INFO 140356611028800] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=-1.91420110067\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:26 INFO 140356611028800] Epoch[152] Batch [5]#011Speed: 88.30 samples/sec#011loss=-1.914201\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:35 INFO 140356611028800] processed a total of 2051 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23957.86690711975, \"sum\": 23957.86690711975, \"min\": 23957.86690711975}}, \"EndTime\": 1600544615.957147, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544591.998995}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:35 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.6082372422 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:35 INFO 140356611028800] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:35 INFO 140356611028800] #quality_metric: host=algo-1, epoch=152, train loss <loss>=-1.91528315911\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:38 INFO 140356611028800] Epoch[153] Batch[0] avg_epoch_loss=-1.914833\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:38 INFO 140356611028800] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=-1.91483262869\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:50 INFO 140356611028800] Epoch[153] Batch[5] avg_epoch_loss=-1.913913\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:50 INFO 140356611028800] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=-1.91391282204\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:43:50 INFO 140356611028800] Epoch[153] Batch [5]#011Speed: 88.23 samples/sec#011loss=-1.913913\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:02 INFO 140356611028800] Epoch[153] Batch[10] avg_epoch_loss=-1.913826\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=-1.91372173016\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:02 INFO 140356611028800] Epoch[153] Batch [10]#011Speed: 87.70 samples/sec#011loss=-1.913722\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:02 INFO 140356611028800] processed a total of 2156 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26389.250993728638, \"sum\": 26389.250993728638, \"min\": 26389.250993728638}}, \"EndTime\": 1600544642.346766, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544615.957224}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:02 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.6996591857 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:02 INFO 140356611028800] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=153, train loss <loss>=-1.91382596209\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:05 INFO 140356611028800] Epoch[154] Batch[0] avg_epoch_loss=-1.933439\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:05 INFO 140356611028800] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=-1.93343852117\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:16 INFO 140356611028800] Epoch[154] Batch[5] avg_epoch_loss=-1.928234\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:16 INFO 140356611028800] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=-1.92823422261\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:16 INFO 140356611028800] Epoch[154] Batch [5]#011Speed: 87.83 samples/sec#011loss=-1.928234\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:28 INFO 140356611028800] Epoch[154] Batch[10] avg_epoch_loss=-1.923905\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=-1.91870979896\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:28 INFO 140356611028800] Epoch[154] Batch [10]#011Speed: 87.93 samples/sec#011loss=-1.918710\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:28 INFO 140356611028800] processed a total of 2123 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26431.512117385864, \"sum\": 26431.512117385864, \"min\": 26431.512117385864}}, \"EndTime\": 1600544668.778564, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544642.346827}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:28 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.3205222485 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:28 INFO 140356611028800] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=154, train loss <loss>=-1.92390493913\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:31 INFO 140356611028800] Epoch[155] Batch[0] avg_epoch_loss=-1.836989\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:31 INFO 140356611028800] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=-1.83698903597\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:43 INFO 140356611028800] Epoch[155] Batch[5] avg_epoch_loss=-1.841953\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=-1.84195342431\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:43 INFO 140356611028800] Epoch[155] Batch [5]#011Speed: 87.90 samples/sec#011loss=-1.841953\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:55 INFO 140356611028800] Epoch[155] Batch[10] avg_epoch_loss=-1.835868\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=-1.82856650719\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:55 INFO 140356611028800] Epoch[155] Batch [10]#011Speed: 87.68 samples/sec#011loss=-1.828567\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:55 INFO 140356611028800] processed a total of 2107 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26457.638025283813, \"sum\": 26457.638025283813, \"min\": 26457.638025283813}}, \"EndTime\": 1600544695.236536, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544668.778625}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:55 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.6363775039 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:55 INFO 140356611028800] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=155, train loss <loss>=-1.83586846198\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:57 INFO 140356611028800] Epoch[156] Batch[0] avg_epoch_loss=-1.897375\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:44:57 INFO 140356611028800] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=-1.89737466665\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:09 INFO 140356611028800] Epoch[156] Batch[5] avg_epoch_loss=-1.837705\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:09 INFO 140356611028800] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=-1.83770522093\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:09 INFO 140356611028800] Epoch[156] Batch [5]#011Speed: 87.41 samples/sec#011loss=-1.837705\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:21 INFO 140356611028800] Epoch[156] Batch[10] avg_epoch_loss=-1.853974\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:21 INFO 140356611028800] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=-1.87349574749\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:21 INFO 140356611028800] Epoch[156] Batch [10]#011Speed: 87.75 samples/sec#011loss=-1.873496\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:21 INFO 140356611028800] processed a total of 2197 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26488.636016845703, \"sum\": 26488.636016845703, \"min\": 26488.636016845703}}, \"EndTime\": 1600544721.725504, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544695.23663}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:21 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.9409682333 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:21 INFO 140356611028800] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:21 INFO 140356611028800] #quality_metric: host=algo-1, epoch=156, train loss <loss>=-1.8539736421\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:24 INFO 140356611028800] Epoch[157] Batch[0] avg_epoch_loss=-1.883259\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:24 INFO 140356611028800] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=-1.88325940646\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:36 INFO 140356611028800] Epoch[157] Batch[5] avg_epoch_loss=-1.881841\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=-1.88184082814\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:36 INFO 140356611028800] Epoch[157] Batch [5]#011Speed: 87.73 samples/sec#011loss=-1.881841\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:48 INFO 140356611028800] Epoch[157] Batch[10] avg_epoch_loss=-1.895156\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:48 INFO 140356611028800] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=-1.91113427969\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:48 INFO 140356611028800] Epoch[157] Batch [10]#011Speed: 87.02 samples/sec#011loss=-1.911134\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:48 INFO 140356611028800] processed a total of 2207 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26553.802013397217, \"sum\": 26553.802013397217, \"min\": 26553.802013397217}}, \"EndTime\": 1600544748.279653, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544721.72556}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:48 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=83.1140032561 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:48 INFO 140356611028800] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:48 INFO 140356611028800] #quality_metric: host=algo-1, epoch=157, train loss <loss>=-1.89515603339\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:51 INFO 140356611028800] Epoch[158] Batch[0] avg_epoch_loss=-1.861512\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:45:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=-1.86151240422\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:02 INFO 140356611028800] Epoch[158] Batch[5] avg_epoch_loss=-1.883225\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=-1.88322458512\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:02 INFO 140356611028800] Epoch[158] Batch [5]#011Speed: 87.85 samples/sec#011loss=-1.883225\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:12 INFO 140356611028800] processed a total of 2041 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24194.149017333984, \"sum\": 24194.149017333984, \"min\": 24194.149017333984}}, \"EndTime\": 1600544772.474183, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544748.27971}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:12 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.3588591202 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:12 INFO 140356611028800] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:12 INFO 140356611028800] #quality_metric: host=algo-1, epoch=158, train loss <loss>=-1.89080074017\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:15 INFO 140356611028800] Epoch[159] Batch[0] avg_epoch_loss=-1.907001\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:15 INFO 140356611028800] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=-1.90700090848\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:27 INFO 140356611028800] Epoch[159] Batch[5] avg_epoch_loss=-1.918736\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:27 INFO 140356611028800] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=-1.91873599321\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:27 INFO 140356611028800] Epoch[159] Batch [5]#011Speed: 87.76 samples/sec#011loss=-1.918736\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:36 INFO 140356611028800] processed a total of 2074 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24070.916175842285, \"sum\": 24070.916175842285, \"min\": 24070.916175842285}}, \"EndTime\": 1600544796.545566, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544772.474257}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:36 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.1617249868 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:36 INFO 140356611028800] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=159, train loss <loss>=-1.91806518848\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:39 INFO 140356611028800] Epoch[160] Batch[0] avg_epoch_loss=-1.926308\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:39 INFO 140356611028800] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=-1.92630841182\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:51 INFO 140356611028800] Epoch[160] Batch[5] avg_epoch_loss=-1.921482\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=-1.92148245298\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:46:51 INFO 140356611028800] Epoch[160] Batch [5]#011Speed: 87.57 samples/sec#011loss=-1.921482\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:03 INFO 140356611028800] Epoch[160] Batch[10] avg_epoch_loss=-1.928705\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=-1.93737165011\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:03 INFO 140356611028800] Epoch[160] Batch [10]#011Speed: 87.76 samples/sec#011loss=-1.937372\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:03 INFO 140356611028800] processed a total of 2183 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26469.08402442932, \"sum\": 26469.08402442932, \"min\": 26469.08402442932}}, \"EndTime\": 1600544823.014994, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544796.545631}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:03 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.4732984195 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:03 INFO 140356611028800] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=160, train loss <loss>=-1.92870481531\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:05 INFO 140356611028800] Epoch[161] Batch[0] avg_epoch_loss=-1.878640\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:05 INFO 140356611028800] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=-1.87864010151\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:17 INFO 140356611028800] Epoch[161] Batch[5] avg_epoch_loss=-1.869373\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=-1.86937268575\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:17 INFO 140356611028800] Epoch[161] Batch [5]#011Speed: 87.48 samples/sec#011loss=-1.869373\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:27 INFO 140356611028800] processed a total of 2080 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24153.741121292114, \"sum\": 24153.741121292114, \"min\": 24153.741121292114}}, \"EndTime\": 1600544847.169026, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544823.015055}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:27 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.1146212385 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:27 INFO 140356611028800] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:27 INFO 140356611028800] #quality_metric: host=algo-1, epoch=161, train loss <loss>=-1.86929167234\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:29 INFO 140356611028800] Epoch[162] Batch[0] avg_epoch_loss=-1.877721\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:29 INFO 140356611028800] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=-1.8777210529\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:41 INFO 140356611028800] Epoch[162] Batch[5] avg_epoch_loss=-1.873166\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:41 INFO 140356611028800] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=-1.87316596202\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:41 INFO 140356611028800] Epoch[162] Batch [5]#011Speed: 86.03 samples/sec#011loss=-1.873166\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:51 INFO 140356611028800] processed a total of 2069 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24314.659118652344, \"sum\": 24314.659118652344, \"min\": 24314.659118652344}}, \"EndTime\": 1600544871.484101, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544847.169105}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:51 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.0923890245 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:51 INFO 140356611028800] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=162, train loss <loss>=-1.88164018484\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:54 INFO 140356611028800] Epoch[163] Batch[0] avg_epoch_loss=-1.873573\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:47:54 INFO 140356611028800] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=-1.87357330322\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:06 INFO 140356611028800] Epoch[163] Batch[5] avg_epoch_loss=-1.906088\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:06 INFO 140356611028800] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=-1.90608802209\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:06 INFO 140356611028800] Epoch[163] Batch [5]#011Speed: 88.10 samples/sec#011loss=-1.906088\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:17 INFO 140356611028800] Epoch[163] Batch[10] avg_epoch_loss=-1.913226\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=-1.92179219173\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:17 INFO 140356611028800] Epoch[163] Batch [10]#011Speed: 88.17 samples/sec#011loss=-1.921792\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:17 INFO 140356611028800] processed a total of 2087 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26348.838090896606, \"sum\": 26348.838090896606, \"min\": 26348.838090896606}}, \"EndTime\": 1600544897.833341, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544871.484159}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:17 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.206206884 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:17 INFO 140356611028800] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=163, train loss <loss>=-1.91322628101\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:20 INFO 140356611028800] Epoch[164] Batch[0] avg_epoch_loss=-1.913831\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:20 INFO 140356611028800] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=-1.91383053706\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:32 INFO 140356611028800] Epoch[164] Batch[5] avg_epoch_loss=-1.908736\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=-1.90873556871\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:32 INFO 140356611028800] Epoch[164] Batch [5]#011Speed: 88.01 samples/sec#011loss=-1.908736\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:44 INFO 140356611028800] Epoch[164] Batch[10] avg_epoch_loss=-1.908786\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=-1.90884622427\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:44 INFO 140356611028800] Epoch[164] Batch [10]#011Speed: 87.85 samples/sec#011loss=-1.908846\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:44 INFO 140356611028800] processed a total of 2141 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26393.90206336975, \"sum\": 26393.90206336975, \"min\": 26393.90206336975}}, \"EndTime\": 1600544924.22763, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544897.833419}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:44 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.1169174172 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:44 INFO 140356611028800] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=164, train loss <loss>=-1.90878586669\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:46 INFO 140356611028800] Epoch[165] Batch[0] avg_epoch_loss=-1.922459\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=-1.9224587954\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:58 INFO 140356611028800] Epoch[165] Batch[5] avg_epoch_loss=-1.922649\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=-1.92264916347\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:48:58 INFO 140356611028800] Epoch[165] Batch [5]#011Speed: 88.00 samples/sec#011loss=-1.922649\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:08 INFO 140356611028800] processed a total of 2080 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24057.979106903076, \"sum\": 24057.979106903076, \"min\": 24057.979106903076}}, \"EndTime\": 1600544948.286144, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544924.227695}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:08 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.4572127613 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:08 INFO 140356611028800] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:08 INFO 140356611028800] #quality_metric: host=algo-1, epoch=165, train loss <loss>=-1.92568795131\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:11 INFO 140356611028800] Epoch[166] Batch[0] avg_epoch_loss=-1.929463\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=-1.9294634599\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:22 INFO 140356611028800] Epoch[166] Batch[5] avg_epoch_loss=-1.924917\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=-1.92491702544\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:22 INFO 140356611028800] Epoch[166] Batch [5]#011Speed: 87.72 samples/sec#011loss=-1.924917\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:34 INFO 140356611028800] Epoch[166] Batch[10] avg_epoch_loss=-1.921631\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=-1.91768842844\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:34 INFO 140356611028800] Epoch[166] Batch [10]#011Speed: 87.79 samples/sec#011loss=-1.917688\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:34 INFO 140356611028800] processed a total of 2115 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26445.49608230591, \"sum\": 26445.49608230591, \"min\": 26445.49608230591}}, \"EndTime\": 1600544974.732089, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544948.286266}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:34 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.975554451 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:34 INFO 140356611028800] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=166, train loss <loss>=-1.92163129953\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:37 INFO 140356611028800] Epoch[167] Batch[0] avg_epoch_loss=-1.909572\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=-1.90957230788\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:49 INFO 140356611028800] Epoch[167] Batch[5] avg_epoch_loss=-1.912961\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:49 INFO 140356611028800] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=-1.91296134851\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:49:49 INFO 140356611028800] Epoch[167] Batch [5]#011Speed: 87.46 samples/sec#011loss=-1.912961\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:01 INFO 140356611028800] Epoch[167] Batch[10] avg_epoch_loss=-1.916791\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:01 INFO 140356611028800] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=-1.92138748169\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:01 INFO 140356611028800] Epoch[167] Batch [10]#011Speed: 87.85 samples/sec#011loss=-1.921387\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:01 INFO 140356611028800] processed a total of 2154 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26500.330924987793, \"sum\": 26500.330924987793, \"min\": 26500.330924987793}}, \"EndTime\": 1600545001.232789, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600544974.732145}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:01 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.281721567 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:01 INFO 140356611028800] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:01 INFO 140356611028800] #quality_metric: host=algo-1, epoch=167, train loss <loss>=-1.91679140905\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:04 INFO 140356611028800] Epoch[168] Batch[0] avg_epoch_loss=-1.846249\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=-1.84624892015\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:15 INFO 140356611028800] Epoch[168] Batch[5] avg_epoch_loss=-1.829185\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:15 INFO 140356611028800] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=-1.82918516795\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:15 INFO 140356611028800] Epoch[168] Batch [5]#011Speed: 87.82 samples/sec#011loss=-1.829185\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:27 INFO 140356611028800] Epoch[168] Batch[10] avg_epoch_loss=-1.810896\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:27 INFO 140356611028800] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=-1.78895008381\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:27 INFO 140356611028800] Epoch[168] Batch [10]#011Speed: 87.76 samples/sec#011loss=-1.788950\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:27 INFO 140356611028800] processed a total of 2105 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26478.26600074768, \"sum\": 26478.26600074768, \"min\": 26478.26600074768}}, \"EndTime\": 1600545027.711343, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545001.232853}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:27 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.4989080235 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:27 INFO 140356611028800] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:27 INFO 140356611028800] #quality_metric: host=algo-1, epoch=168, train loss <loss>=-1.81089649334\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:30 INFO 140356611028800] Epoch[169] Batch[0] avg_epoch_loss=-1.857067\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:30 INFO 140356611028800] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=-1.857066668\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:42 INFO 140356611028800] Epoch[169] Batch[5] avg_epoch_loss=-1.882120\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:42 INFO 140356611028800] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=-1.88211996127\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:42 INFO 140356611028800] Epoch[169] Batch [5]#011Speed: 87.99 samples/sec#011loss=-1.882120\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:54 INFO 140356611028800] Epoch[169] Batch[10] avg_epoch_loss=-1.891760\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:54 INFO 140356611028800] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=-1.90332723764\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:54 INFO 140356611028800] Epoch[169] Batch [10]#011Speed: 87.80 samples/sec#011loss=-1.903327\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:54 INFO 140356611028800] processed a total of 2125 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26457.92007446289, \"sum\": 26457.92007446289, \"min\": 26457.92007446289}}, \"EndTime\": 1600545054.169573, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545027.711401}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:54 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.315951664 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:54 INFO 140356611028800] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:54 INFO 140356611028800] #quality_metric: host=algo-1, epoch=169, train loss <loss>=-1.89175963235\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:56 INFO 140356611028800] Epoch[170] Batch[0] avg_epoch_loss=-1.818750\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:50:56 INFO 140356611028800] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=-1.81874950115\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:08 INFO 140356611028800] Epoch[170] Batch[5] avg_epoch_loss=-1.864228\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:08 INFO 140356611028800] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=-1.86422834641\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:08 INFO 140356611028800] Epoch[170] Batch [5]#011Speed: 86.82 samples/sec#011loss=-1.864228\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:20 INFO 140356611028800] Epoch[170] Batch[10] avg_epoch_loss=-1.885356\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:20 INFO 140356611028800] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=-1.91071026142\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:20 INFO 140356611028800] Epoch[170] Batch [10]#011Speed: 86.68 samples/sec#011loss=-1.910710\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:20 INFO 140356611028800] processed a total of 2112 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26731.693983078003, \"sum\": 26731.693983078003, \"min\": 26731.693983078003}}, \"EndTime\": 1600545080.901594, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545054.169633}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:20 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.0070723181 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:20 INFO 140356611028800] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:20 INFO 140356611028800] #quality_metric: host=algo-1, epoch=170, train loss <loss>=-1.88535648959\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:23 INFO 140356611028800] Epoch[171] Batch[0] avg_epoch_loss=-1.881097\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:23 INFO 140356611028800] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=-1.88109661983\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:35 INFO 140356611028800] Epoch[171] Batch[5] avg_epoch_loss=-1.898347\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:35 INFO 140356611028800] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=-1.89834707211\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:35 INFO 140356611028800] Epoch[171] Batch [5]#011Speed: 87.82 samples/sec#011loss=-1.898347\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:45 INFO 140356611028800] processed a total of 2045 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24113.243103027344, \"sum\": 24113.243103027344, \"min\": 24113.243103027344}}, \"EndTime\": 1600545105.015169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545080.901655}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:45 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.8078597378 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:45 INFO 140356611028800] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:45 INFO 140356611028800] #quality_metric: host=algo-1, epoch=171, train loss <loss>=-1.90253662696\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:47 INFO 140356611028800] Epoch[172] Batch[0] avg_epoch_loss=-1.881768\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:47 INFO 140356611028800] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=-1.88176756639\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:59 INFO 140356611028800] Epoch[172] Batch[5] avg_epoch_loss=-1.900398\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:59 INFO 140356611028800] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=-1.90039835221\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:51:59 INFO 140356611028800] Epoch[172] Batch [5]#011Speed: 87.62 samples/sec#011loss=-1.900398\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:11 INFO 140356611028800] Epoch[172] Batch[10] avg_epoch_loss=-1.908667\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=-1.9185901055\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:11 INFO 140356611028800] Epoch[172] Batch [10]#011Speed: 87.25 samples/sec#011loss=-1.918590\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:11 INFO 140356611028800] processed a total of 2199 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26523.839950561523, \"sum\": 26523.839950561523, \"min\": 26523.839950561523}}, \"EndTime\": 1600545131.539412, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545105.01523}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:11 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.9062726324 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:11 INFO 140356611028800] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=172, train loss <loss>=-1.90866733098\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:14 INFO 140356611028800] Epoch[173] Batch[0] avg_epoch_loss=-1.911617\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:14 INFO 140356611028800] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=-1.91161713233\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:26 INFO 140356611028800] Epoch[173] Batch[5] avg_epoch_loss=-1.924594\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:26 INFO 140356611028800] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=-1.92459417001\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:26 INFO 140356611028800] Epoch[173] Batch [5]#011Speed: 87.65 samples/sec#011loss=-1.924594\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:35 INFO 140356611028800] processed a total of 2061 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24124.58896636963, \"sum\": 24124.58896636963, \"min\": 24124.58896636963}}, \"EndTime\": 1600545155.664343, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545131.539471}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:35 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.4311316536 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:35 INFO 140356611028800] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:35 INFO 140356611028800] #quality_metric: host=algo-1, epoch=173, train loss <loss>=-1.92188943716\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:38 INFO 140356611028800] Epoch[174] Batch[0] avg_epoch_loss=-1.925769\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:38 INFO 140356611028800] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=-1.92576892559\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:50 INFO 140356611028800] Epoch[174] Batch[5] avg_epoch_loss=-1.927405\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:50 INFO 140356611028800] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=-1.92740523509\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:52:50 INFO 140356611028800] Epoch[174] Batch [5]#011Speed: 86.73 samples/sec#011loss=-1.927405\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:02 INFO 140356611028800] Epoch[174] Batch[10] avg_epoch_loss=-1.935413\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=-1.94502234826\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:02 INFO 140356611028800] Epoch[174] Batch [10]#011Speed: 88.04 samples/sec#011loss=-1.945022\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:02 INFO 140356611028800] processed a total of 2136 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26537.28985786438, \"sum\": 26537.28985786438, \"min\": 26537.28985786438}}, \"EndTime\": 1600545182.201989, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545155.664419}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:02 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.4902578221 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:02 INFO 140356611028800] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=174, train loss <loss>=-1.93541301381\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:04 INFO 140356611028800] Epoch[175] Batch[0] avg_epoch_loss=-1.928597\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=-1.9285966433\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:16 INFO 140356611028800] Epoch[175] Batch[5] avg_epoch_loss=-1.923326\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:16 INFO 140356611028800] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=-1.92332590543\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:16 INFO 140356611028800] Epoch[175] Batch [5]#011Speed: 87.87 samples/sec#011loss=-1.923326\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:28 INFO 140356611028800] Epoch[175] Batch[10] avg_epoch_loss=-1.921600\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=-1.91952840365\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:28 INFO 140356611028800] Epoch[175] Batch [10]#011Speed: 87.53 samples/sec#011loss=-1.919528\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:28 INFO 140356611028800] processed a total of 2163 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26450.769901275635, \"sum\": 26450.769901275635, \"min\": 26450.769901275635}}, \"EndTime\": 1600545208.653137, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545182.202043}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:28 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.7742824075 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:28 INFO 140356611028800] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=175, train loss <loss>=-1.92159976826\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:31 INFO 140356611028800] Epoch[176] Batch[0] avg_epoch_loss=-1.903146\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:31 INFO 140356611028800] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=-1.90314645034\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:43 INFO 140356611028800] Epoch[176] Batch[5] avg_epoch_loss=-1.927788\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=-1.92778792748\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:43 INFO 140356611028800] Epoch[176] Batch [5]#011Speed: 88.32 samples/sec#011loss=-1.927788\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:52 INFO 140356611028800] processed a total of 2039 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23969.087839126587, \"sum\": 23969.087839126587, \"min\": 23969.087839126587}}, \"EndTime\": 1600545232.622591, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545208.653195}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:52 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.0675738965 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:52 INFO 140356611028800] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:52 INFO 140356611028800] #quality_metric: host=algo-1, epoch=176, train loss <loss>=-1.93181200761\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:55 INFO 140356611028800] Epoch[177] Batch[0] avg_epoch_loss=-1.930706\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:53:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=-1.93070602417\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:07 INFO 140356611028800] Epoch[177] Batch[5] avg_epoch_loss=-1.930252\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:07 INFO 140356611028800] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=-1.93025241754\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:07 INFO 140356611028800] Epoch[177] Batch [5]#011Speed: 87.40 samples/sec#011loss=-1.930252\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:19 INFO 140356611028800] Epoch[177] Batch[10] avg_epoch_loss=-1.927241\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=-1.92362755996\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:19 INFO 140356611028800] Epoch[177] Batch [10]#011Speed: 87.60 samples/sec#011loss=-1.923628\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:19 INFO 140356611028800] processed a total of 2144 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26501.110076904297, \"sum\": 26501.110076904297, \"min\": 26501.110076904297}}, \"EndTime\": 1600545259.124072, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545232.622655}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:19 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.9019846374 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:19 INFO 140356611028800] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=177, train loss <loss>=-1.92724111864\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:21 INFO 140356611028800] Epoch[178] Batch[0] avg_epoch_loss=-1.939271\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:21 INFO 140356611028800] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=-1.93927075313\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:33 INFO 140356611028800] Epoch[178] Batch[5] avg_epoch_loss=-1.923118\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:33 INFO 140356611028800] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=-1.92311800443\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:33 INFO 140356611028800] Epoch[178] Batch [5]#011Speed: 87.93 samples/sec#011loss=-1.923118\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:43 INFO 140356611028800] processed a total of 2074 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24109.686136245728, \"sum\": 24109.686136245728, \"min\": 24109.686136245728}}, \"EndTime\": 1600545283.234048, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545259.124136}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:43 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.0227643545 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:43 INFO 140356611028800] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=178, train loss <loss>=-1.92494057875\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:46 INFO 140356611028800] Epoch[179] Batch[0] avg_epoch_loss=-1.930344\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=-1.93034436153\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:57 INFO 140356611028800] Epoch[179] Batch[5] avg_epoch_loss=-1.931325\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:57 INFO 140356611028800] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=-1.93132525224\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:54:57 INFO 140356611028800] Epoch[179] Batch [5]#011Speed: 87.99 samples/sec#011loss=-1.931325\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:09 INFO 140356611028800] Epoch[179] Batch[10] avg_epoch_loss=-1.933689\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:09 INFO 140356611028800] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=-1.93652478732\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:09 INFO 140356611028800] Epoch[179] Batch [10]#011Speed: 87.81 samples/sec#011loss=-1.936525\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:09 INFO 140356611028800] processed a total of 2100 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26493.863821029663, \"sum\": 26493.863821029663, \"min\": 26493.863821029663}}, \"EndTime\": 1600545309.728388, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545283.234228}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:09 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.2633914525 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:09 INFO 140356611028800] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:09 INFO 140356611028800] #quality_metric: host=algo-1, epoch=179, train loss <loss>=-1.93368867727\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:12 INFO 140356611028800] Epoch[180] Batch[0] avg_epoch_loss=-1.908578\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:12 INFO 140356611028800] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=-1.9085782858\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:24 INFO 140356611028800] Epoch[180] Batch[5] avg_epoch_loss=-1.910979\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:24 INFO 140356611028800] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=-1.91097929539\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:24 INFO 140356611028800] Epoch[180] Batch [5]#011Speed: 87.82 samples/sec#011loss=-1.910979\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:33 INFO 140356611028800] processed a total of 2060 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24099.27010536194, \"sum\": 24099.27010536194, \"min\": 24099.27010536194}}, \"EndTime\": 1600545333.827994, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545309.728439}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:33 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.4794560663 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:33 INFO 140356611028800] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:33 INFO 140356611028800] #quality_metric: host=algo-1, epoch=180, train loss <loss>=-1.91551969968\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:36 INFO 140356611028800] Epoch[181] Batch[0] avg_epoch_loss=-1.907334\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=-1.90733381418\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:48 INFO 140356611028800] Epoch[181] Batch[5] avg_epoch_loss=-1.922777\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:48 INFO 140356611028800] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=-1.92277685801\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:55:48 INFO 140356611028800] Epoch[181] Batch [5]#011Speed: 87.57 samples/sec#011loss=-1.922777\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:00 INFO 140356611028800] Epoch[181] Batch[10] avg_epoch_loss=-1.924319\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:00 INFO 140356611028800] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=-1.9261702024\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:00 INFO 140356611028800] Epoch[181] Batch [10]#011Speed: 87.71 samples/sec#011loss=-1.926170\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:00 INFO 140356611028800] processed a total of 2199 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26514.007806777954, \"sum\": 26514.007806777954, \"min\": 26514.007806777954}}, \"EndTime\": 1600545360.342492, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545333.828056}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:00 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.9370224867 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:00 INFO 140356611028800] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:00 INFO 140356611028800] #quality_metric: host=algo-1, epoch=181, train loss <loss>=-1.92431928728\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:03 INFO 140356611028800] Epoch[182] Batch[0] avg_epoch_loss=-1.934491\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=-1.93449108417\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:14 INFO 140356611028800] Epoch[182] Batch[5] avg_epoch_loss=-1.929279\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:14 INFO 140356611028800] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=-1.92927927849\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:14 INFO 140356611028800] Epoch[182] Batch [5]#011Speed: 87.52 samples/sec#011loss=-1.929279\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:24 INFO 140356611028800] processed a total of 1988 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24193.578958511353, \"sum\": 24193.578958511353, \"min\": 24193.578958511353}}, \"EndTime\": 1600545384.536421, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545360.342547}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:24 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.1702607951 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:24 INFO 140356611028800] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:24 INFO 140356611028800] #quality_metric: host=algo-1, epoch=182, train loss <loss>=-1.93096466064\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:27 INFO 140356611028800] Epoch[183] Batch[0] avg_epoch_loss=-1.913905\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:27 INFO 140356611028800] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=-1.9139052171\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:39 INFO 140356611028800] Epoch[183] Batch[5] avg_epoch_loss=-1.885188\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:39 INFO 140356611028800] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=-1.8851883228\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:39 INFO 140356611028800] Epoch[183] Batch [5]#011Speed: 87.86 samples/sec#011loss=-1.885188\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:48 INFO 140356611028800] processed a total of 2070 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24137.815952301025, \"sum\": 24137.815952301025, \"min\": 24137.815952301025}}, \"EndTime\": 1600545408.674705, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545384.536482}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:48 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.7570468774 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:48 INFO 140356611028800] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:48 INFO 140356611028800] #quality_metric: host=algo-1, epoch=183, train loss <loss>=-1.89589730776\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:51 INFO 140356611028800] Epoch[184] Batch[0] avg_epoch_loss=-1.916769\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:56:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=-1.91676932115\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:03 INFO 140356611028800] Epoch[184] Batch[5] avg_epoch_loss=-1.922114\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=-1.92211385874\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:03 INFO 140356611028800] Epoch[184] Batch [5]#011Speed: 87.55 samples/sec#011loss=-1.922114\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:15 INFO 140356611028800] Epoch[184] Batch[10] avg_epoch_loss=-1.919132\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:15 INFO 140356611028800] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=-1.91555401729\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:15 INFO 140356611028800] Epoch[184] Batch [10]#011Speed: 87.63 samples/sec#011loss=-1.915554\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:15 INFO 140356611028800] processed a total of 2156 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26505.390167236328, \"sum\": 26505.390167236328, \"min\": 26505.390167236328}}, \"EndTime\": 1600545435.180497, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545408.674813}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:15 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.3416702977 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:15 INFO 140356611028800] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:15 INFO 140356611028800] #quality_metric: host=algo-1, epoch=184, train loss <loss>=-1.91913211262\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:17 INFO 140356611028800] Epoch[185] Batch[0] avg_epoch_loss=-1.916087\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=-1.91608722393\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:29 INFO 140356611028800] Epoch[185] Batch[5] avg_epoch_loss=-1.916062\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:29 INFO 140356611028800] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=-1.9160620616\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:29 INFO 140356611028800] Epoch[185] Batch [5]#011Speed: 87.53 samples/sec#011loss=-1.916062\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:41 INFO 140356611028800] Epoch[185] Batch[10] avg_epoch_loss=-1.923012\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:41 INFO 140356611028800] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=-1.9313512362\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:41 INFO 140356611028800] Epoch[185] Batch [10]#011Speed: 87.66 samples/sec#011loss=-1.931351\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:41 INFO 140356611028800] processed a total of 2095 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26526.74388885498, \"sum\": 26526.74388885498, \"min\": 26526.74388885498}}, \"EndTime\": 1600545461.707535, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545435.18056}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:41 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.9766380937 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:41 INFO 140356611028800] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:41 INFO 140356611028800] #quality_metric: host=algo-1, epoch=185, train loss <loss>=-1.92301168642\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:44 INFO 140356611028800] Epoch[186] Batch[0] avg_epoch_loss=-1.908591\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=-1.90859061021\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:56 INFO 140356611028800] Epoch[186] Batch[5] avg_epoch_loss=-1.915948\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:56 INFO 140356611028800] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=-1.91594791412\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:57:56 INFO 140356611028800] Epoch[186] Batch [5]#011Speed: 87.80 samples/sec#011loss=-1.915948\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:05 INFO 140356611028800] processed a total of 2069 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24091.152906417847, \"sum\": 24091.152906417847, \"min\": 24091.152906417847}}, \"EndTime\": 1600545485.798995, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545461.707595}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:05 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.8816822239 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:05 INFO 140356611028800] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:05 INFO 140356611028800] #quality_metric: host=algo-1, epoch=186, train loss <loss>=-1.91767583994\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:08 INFO 140356611028800] Epoch[187] Batch[0] avg_epoch_loss=-1.920479\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:08 INFO 140356611028800] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=-1.92047940768\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:20 INFO 140356611028800] Epoch[187] Batch[5] avg_epoch_loss=-1.918864\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:20 INFO 140356611028800] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=-1.91886385893\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:20 INFO 140356611028800] Epoch[187] Batch [5]#011Speed: 88.01 samples/sec#011loss=-1.918864\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:32 INFO 140356611028800] Epoch[187] Batch[10] avg_epoch_loss=-1.924241\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=-1.93069337698\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:32 INFO 140356611028800] Epoch[187] Batch [10]#011Speed: 88.20 samples/sec#011loss=-1.930693\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:32 INFO 140356611028800] processed a total of 2129 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26348.99592399597, \"sum\": 26348.99592399597, \"min\": 26348.99592399597}}, \"EndTime\": 1600545512.148454, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545485.799075}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:32 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.799727019 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:32 INFO 140356611028800] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=187, train loss <loss>=-1.92424091259\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:34 INFO 140356611028800] Epoch[188] Batch[0] avg_epoch_loss=-1.923111\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=-1.92311052176\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:46 INFO 140356611028800] Epoch[188] Batch[5] avg_epoch_loss=-1.924778\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=-1.92477837587\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:46 INFO 140356611028800] Epoch[188] Batch [5]#011Speed: 87.97 samples/sec#011loss=-1.924778\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:58 INFO 140356611028800] Epoch[188] Batch[10] avg_epoch_loss=-1.924941\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=-1.92513662485\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:58 INFO 140356611028800] Epoch[188] Batch [10]#011Speed: 88.50 samples/sec#011loss=-1.925137\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:58 INFO 140356611028800] processed a total of 2097 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26315.397024154663, \"sum\": 26315.397024154663, \"min\": 26315.397024154663}}, \"EndTime\": 1600545538.464215, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545512.148517}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:58 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.6869277516 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:58 INFO 140356611028800] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:58:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=188, train loss <loss>=-1.92494121632\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:01 INFO 140356611028800] Epoch[189] Batch[0] avg_epoch_loss=-1.927673\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:01 INFO 140356611028800] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=-1.92767333984\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:13 INFO 140356611028800] Epoch[189] Batch[5] avg_epoch_loss=-1.923550\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:13 INFO 140356611028800] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=-1.92354952983\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:13 INFO 140356611028800] Epoch[189] Batch [5]#011Speed: 86.33 samples/sec#011loss=-1.923550\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:25 INFO 140356611028800] Epoch[189] Batch[10] avg_epoch_loss=-1.930822\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=-1.93954831637\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:25 INFO 140356611028800] Epoch[189] Batch [10]#011Speed: 87.81 samples/sec#011loss=-1.939548\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:25 INFO 140356611028800] processed a total of 2083 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26624.92799758911, \"sum\": 26624.92799758911, \"min\": 26624.92799758911}}, \"EndTime\": 1600545565.089478, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545538.464272}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:25 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.2344426428 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:25 INFO 140356611028800] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=189, train loss <loss>=-1.93082170553\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:27 INFO 140356611028800] Epoch[190] Batch[0] avg_epoch_loss=-1.822903\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:27 INFO 140356611028800] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=-1.82290341304\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:39 INFO 140356611028800] Epoch[190] Batch[5] avg_epoch_loss=-1.814869\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:39 INFO 140356611028800] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=-1.81486912263\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:39 INFO 140356611028800] Epoch[190] Batch [5]#011Speed: 87.51 samples/sec#011loss=-1.814869\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:51 INFO 140356611028800] Epoch[190] Batch[10] avg_epoch_loss=-1.787300\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=-1.75421708914\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:51 INFO 140356611028800] Epoch[190] Batch [10]#011Speed: 87.75 samples/sec#011loss=-1.754217\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:51 INFO 140356611028800] processed a total of 2082 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26467.267990112305, \"sum\": 26467.267990112305, \"min\": 26467.267990112305}}, \"EndTime\": 1600545591.557258, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545565.089618}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:51 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.6629387019 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:51 INFO 140356611028800] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=190, train loss <loss>=-1.7873000165\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:54 INFO 140356611028800] Epoch[191] Batch[0] avg_epoch_loss=-1.814509\u001b[0m\n",
      "\u001b[34m[09/19/2020 19:59:54 INFO 140356611028800] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=-1.81450858483\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:06 INFO 140356611028800] Epoch[191] Batch[5] avg_epoch_loss=-1.820937\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:06 INFO 140356611028800] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=-1.82093713222\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:06 INFO 140356611028800] Epoch[191] Batch [5]#011Speed: 87.93 samples/sec#011loss=-1.820937\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:18 INFO 140356611028800] Epoch[191] Batch[10] avg_epoch_loss=-1.842766\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:18 INFO 140356611028800] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=-1.86895995507\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:18 INFO 140356611028800] Epoch[191] Batch [10]#011Speed: 87.55 samples/sec#011loss=-1.868960\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:18 INFO 140356611028800] processed a total of 2109 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26476.577043533325, \"sum\": 26476.577043533325, \"min\": 26476.577043533325}}, \"EndTime\": 1600545618.034193, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545591.55732}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:18 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.6550413913 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:18 INFO 140356611028800] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:18 INFO 140356611028800] #quality_metric: host=algo-1, epoch=191, train loss <loss>=-1.84276568806\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:20 INFO 140356611028800] Epoch[192] Batch[0] avg_epoch_loss=-1.805726\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:20 INFO 140356611028800] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=-1.80572583125\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:32 INFO 140356611028800] Epoch[192] Batch[5] avg_epoch_loss=-1.868426\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=-1.86842573606\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:32 INFO 140356611028800] Epoch[192] Batch [5]#011Speed: 87.67 samples/sec#011loss=-1.868426\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:44 INFO 140356611028800] Epoch[192] Batch[10] avg_epoch_loss=-1.871568\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=-1.87533853971\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:44 INFO 140356611028800] Epoch[192] Batch [10]#011Speed: 87.56 samples/sec#011loss=-1.875339\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:44 INFO 140356611028800] processed a total of 2145 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26500.576972961426, \"sum\": 26500.576972961426, \"min\": 26500.576972961426}}, \"EndTime\": 1600545644.535051, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545618.034254}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:44 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.9412887493 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:44 INFO 140356611028800] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=192, train loss <loss>=-1.87156791954\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:47 INFO 140356611028800] Epoch[193] Batch[0] avg_epoch_loss=-1.815423\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:47 INFO 140356611028800] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=-1.8154227917\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:59 INFO 140356611028800] Epoch[193] Batch[5] avg_epoch_loss=-1.872140\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:59 INFO 140356611028800] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=-1.87214041979\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:00:59 INFO 140356611028800] Epoch[193] Batch [5]#011Speed: 86.61 samples/sec#011loss=-1.872140\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:11 INFO 140356611028800] Epoch[193] Batch[10] avg_epoch_loss=-1.884368\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=-1.89904166002\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:11 INFO 140356611028800] Epoch[193] Batch [10]#011Speed: 86.90 samples/sec#011loss=-1.899042\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:11 INFO 140356611028800] processed a total of 2115 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26749.505043029785, \"sum\": 26749.505043029785, \"min\": 26749.505043029785}}, \"EndTime\": 1600545671.284943, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545644.535139}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:11 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.0666171557 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:11 INFO 140356611028800] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=193, train loss <loss>=-1.88436825626\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:14 INFO 140356611028800] Epoch[194] Batch[0] avg_epoch_loss=-1.911625\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:14 INFO 140356611028800] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=-1.91162520189\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:25 INFO 140356611028800] Epoch[194] Batch[5] avg_epoch_loss=-1.917310\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=-1.91730966323\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:25 INFO 140356611028800] Epoch[194] Batch [5]#011Speed: 87.40 samples/sec#011loss=-1.917310\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:37 INFO 140356611028800] Epoch[194] Batch[10] avg_epoch_loss=-1.930969\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=-1.94735967196\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:37 INFO 140356611028800] Epoch[194] Batch [10]#011Speed: 87.96 samples/sec#011loss=-1.947360\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:37 INFO 140356611028800] processed a total of 2094 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26462.862968444824, \"sum\": 26462.862968444824, \"min\": 26462.862968444824}}, \"EndTime\": 1600545697.748154, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545671.285002}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:37 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.1294849784 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:37 INFO 140356611028800] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=194, train loss <loss>=-1.93096875811\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:40 INFO 140356611028800] Epoch[195] Batch[0] avg_epoch_loss=-1.895103\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:40 INFO 140356611028800] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=-1.89510286771\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:52 INFO 140356611028800] Epoch[195] Batch[5] avg_epoch_loss=-1.889567\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:52 INFO 140356611028800] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=-1.88956732628\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:01:52 INFO 140356611028800] Epoch[195] Batch [5]#011Speed: 87.03 samples/sec#011loss=-1.889567\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:01 INFO 140356611028800] processed a total of 2079 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24229.382038116455, \"sum\": 24229.382038116455, \"min\": 24229.382038116455}}, \"EndTime\": 1600545721.977835, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545697.748216}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:01 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.8045407627 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:01 INFO 140356611028800] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:01 INFO 140356611028800] #quality_metric: host=algo-1, epoch=195, train loss <loss>=-1.8982282932\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:04 INFO 140356611028800] Epoch[196] Batch[0] avg_epoch_loss=-1.924084\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=-1.92408444331\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:16 INFO 140356611028800] Epoch[196] Batch[5] avg_epoch_loss=-1.911274\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:16 INFO 140356611028800] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=-1.91127410302\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:16 INFO 140356611028800] Epoch[196] Batch [5]#011Speed: 87.45 samples/sec#011loss=-1.911274\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:28 INFO 140356611028800] Epoch[196] Batch[10] avg_epoch_loss=-1.925617\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=-1.94282769423\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:28 INFO 140356611028800] Epoch[196] Batch [10]#011Speed: 88.02 samples/sec#011loss=-1.942828\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:28 INFO 140356611028800] processed a total of 2082 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26485.591888427734, \"sum\": 26485.591888427734, \"min\": 26485.591888427734}}, \"EndTime\": 1600545748.463783, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545721.977911}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:28 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.6085163991 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:28 INFO 140356611028800] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=196, train loss <loss>=-1.92561664448\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:31 INFO 140356611028800] Epoch[197] Batch[0] avg_epoch_loss=-1.920902\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:31 INFO 140356611028800] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=-1.92090166532\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:43 INFO 140356611028800] Epoch[197] Batch[5] avg_epoch_loss=-1.926692\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=-1.92669232686\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:43 INFO 140356611028800] Epoch[197] Batch [5]#011Speed: 87.97 samples/sec#011loss=-1.926692\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:52 INFO 140356611028800] processed a total of 2029 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24396.32797241211, \"sum\": 24396.32797241211, \"min\": 24396.32797241211}}, \"EndTime\": 1600545772.860401, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545748.463843}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:52 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=83.167902007 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:52 INFO 140356611028800] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:52 INFO 140356611028800] #quality_metric: host=algo-1, epoch=197, train loss <loss>=-1.92591136052\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:55 INFO 140356611028800] Epoch[198] Batch[0] avg_epoch_loss=-1.925417\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:02:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=-1.92541738657\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:07 INFO 140356611028800] Epoch[198] Batch[5] avg_epoch_loss=-1.935068\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:07 INFO 140356611028800] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=-1.93506835057\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:07 INFO 140356611028800] Epoch[198] Batch [5]#011Speed: 88.07 samples/sec#011loss=-1.935068\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:19 INFO 140356611028800] Epoch[198] Batch[10] avg_epoch_loss=-1.923653\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=-1.90995412973\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:19 INFO 140356611028800] Epoch[198] Batch [10]#011Speed: 88.06 samples/sec#011loss=-1.909954\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:19 INFO 140356611028800] processed a total of 2112 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26421.164989471436, \"sum\": 26421.164989471436, \"min\": 26421.164989471436}}, \"EndTime\": 1600545799.281903, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545772.860474}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:19 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.9356214679 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:19 INFO 140356611028800] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=198, train loss <loss>=-1.92365279564\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:22 INFO 140356611028800] Epoch[199] Batch[0] avg_epoch_loss=-1.851521\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=-1.85152068505\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:33 INFO 140356611028800] Epoch[199] Batch[5] avg_epoch_loss=-1.881520\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:33 INFO 140356611028800] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=-1.88151997786\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:33 INFO 140356611028800] Epoch[199] Batch [5]#011Speed: 88.25 samples/sec#011loss=-1.881520\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:43 INFO 140356611028800] processed a total of 2045 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23993.69215965271, \"sum\": 23993.69215965271, \"min\": 23993.69215965271}}, \"EndTime\": 1600545823.275906, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545799.281973}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:43 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.2304225812 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:43 INFO 140356611028800] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=199, train loss <loss>=-1.87741153424\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:46 INFO 140356611028800] Epoch[200] Batch[0] avg_epoch_loss=-1.872587\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=-1.8725866171\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:57 INFO 140356611028800] Epoch[200] Batch[5] avg_epoch_loss=-1.891633\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:57 INFO 140356611028800] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=-1.89163276477\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:03:57 INFO 140356611028800] Epoch[200] Batch [5]#011Speed: 87.99 samples/sec#011loss=-1.891633\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:09 INFO 140356611028800] Epoch[200] Batch[10] avg_epoch_loss=-1.904091\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:09 INFO 140356611028800] #quality_metric: host=algo-1, epoch=200, batch=10 train loss <loss>=-1.91904158959\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:09 INFO 140356611028800] Epoch[200] Batch [10]#011Speed: 88.05 samples/sec#011loss=-1.919042\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:09 INFO 140356611028800] processed a total of 2152 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26368.242979049683, \"sum\": 26368.242979049683, \"min\": 26368.242979049683}}, \"EndTime\": 1600545849.644633, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545823.275965}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:09 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.6130378146 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:09 INFO 140356611028800] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:09 INFO 140356611028800] #quality_metric: host=algo-1, epoch=200, train loss <loss>=-1.90409132151\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:12 INFO 140356611028800] Epoch[201] Batch[0] avg_epoch_loss=-1.885339\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:12 INFO 140356611028800] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=-1.8853387099\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:24 INFO 140356611028800] Epoch[201] Batch[5] avg_epoch_loss=-1.880709\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:24 INFO 140356611028800] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=-1.88070857219\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:24 INFO 140356611028800] Epoch[201] Batch [5]#011Speed: 87.56 samples/sec#011loss=-1.880709\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:36 INFO 140356611028800] Epoch[201] Batch[10] avg_epoch_loss=-1.892827\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=201, batch=10 train loss <loss>=-1.90736923218\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:36 INFO 140356611028800] Epoch[201] Batch [10]#011Speed: 86.78 samples/sec#011loss=-1.907369\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:36 INFO 140356611028800] processed a total of 2112 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26662.96100616455, \"sum\": 26662.96100616455, \"min\": 26662.96100616455}}, \"EndTime\": 1600545876.307941, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545849.644693}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:36 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.2107190642 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:36 INFO 140356611028800] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=201, train loss <loss>=-1.892827054\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:39 INFO 140356611028800] Epoch[202] Batch[0] avg_epoch_loss=-1.917055\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:39 INFO 140356611028800] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=-1.91705513\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:50 INFO 140356611028800] Epoch[202] Batch[5] avg_epoch_loss=-1.877106\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:50 INFO 140356611028800] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=-1.87710615305\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:04:50 INFO 140356611028800] Epoch[202] Batch [5]#011Speed: 87.71 samples/sec#011loss=-1.877106\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:02 INFO 140356611028800] Epoch[202] Batch[10] avg_epoch_loss=-1.894670\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=-1.91574701162\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:02 INFO 140356611028800] Epoch[202] Batch [10]#011Speed: 87.56 samples/sec#011loss=-1.915747\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:02 INFO 140356611028800] processed a total of 2094 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26471.739053726196, \"sum\": 26471.739053726196, \"min\": 26471.739053726196}}, \"EndTime\": 1600545902.780055, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545876.308006}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:02 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.1029618837 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:02 INFO 140356611028800] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=202, train loss <loss>=-1.89467017967\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:05 INFO 140356611028800] Epoch[203] Batch[0] avg_epoch_loss=-1.720829\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:05 INFO 140356611028800] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=-1.72082901001\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:17 INFO 140356611028800] Epoch[203] Batch[5] avg_epoch_loss=-1.824393\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=-1.82439283224\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:17 INFO 140356611028800] Epoch[203] Batch [5]#011Speed: 87.48 samples/sec#011loss=-1.824393\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:29 INFO 140356611028800] Epoch[203] Batch[10] avg_epoch_loss=-1.850616\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:29 INFO 140356611028800] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=-1.8820837461\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:29 INFO 140356611028800] Epoch[203] Batch [10]#011Speed: 87.91 samples/sec#011loss=-1.882084\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:29 INFO 140356611028800] processed a total of 2131 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26460.154056549072, \"sum\": 26460.154056549072, \"min\": 26460.154056549072}}, \"EndTime\": 1600545929.240542, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545902.780115}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:29 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.5359311437 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:29 INFO 140356611028800] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:29 INFO 140356611028800] #quality_metric: host=algo-1, epoch=203, train loss <loss>=-1.85061597491\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:32 INFO 140356611028800] Epoch[204] Batch[0] avg_epoch_loss=-1.859669\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=-1.85966931857\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:43 INFO 140356611028800] Epoch[204] Batch[5] avg_epoch_loss=-1.889682\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=-1.88968174274\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:43 INFO 140356611028800] Epoch[204] Batch [5]#011Speed: 87.89 samples/sec#011loss=-1.889682\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:55 INFO 140356611028800] Epoch[204] Batch[10] avg_epoch_loss=-1.896818\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=204, batch=10 train loss <loss>=-1.90538068918\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:55 INFO 140356611028800] Epoch[204] Batch [10]#011Speed: 87.60 samples/sec#011loss=-1.905381\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:55 INFO 140356611028800] processed a total of 2170 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26486.737966537476, \"sum\": 26486.737966537476, \"min\": 26486.737966537476}}, \"EndTime\": 1600545955.72761, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545929.240596}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:55 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.927508891 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:55 INFO 140356611028800] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=204, train loss <loss>=-1.89681762749\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:58 INFO 140356611028800] Epoch[205] Batch[0] avg_epoch_loss=-1.921569\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:05:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=-1.92156923734\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:10 INFO 140356611028800] Epoch[205] Batch[5] avg_epoch_loss=-1.921839\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=-1.92183902936\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:10 INFO 140356611028800] Epoch[205] Batch [5]#011Speed: 86.03 samples/sec#011loss=-1.921839\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:22 INFO 140356611028800] Epoch[205] Batch[10] avg_epoch_loss=-1.924273\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=-1.92719295208\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:22 INFO 140356611028800] Epoch[205] Batch [10]#011Speed: 87.58 samples/sec#011loss=-1.927193\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:22 INFO 140356611028800] processed a total of 2097 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26744.4748878479, \"sum\": 26744.4748878479, \"min\": 26744.4748878479}}, \"EndTime\": 1600545982.472433, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545955.727669}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:22 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.4084311077 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:22 INFO 140356611028800] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=205, train loss <loss>=-1.9242726306\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:25 INFO 140356611028800] Epoch[206] Batch[0] avg_epoch_loss=-1.939633\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=-1.93963270921\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:37 INFO 140356611028800] Epoch[206] Batch[5] avg_epoch_loss=-1.925484\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=-1.92548365471\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:37 INFO 140356611028800] Epoch[206] Batch [5]#011Speed: 88.04 samples/sec#011loss=-1.925484\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:48 INFO 140356611028800] Epoch[206] Batch[10] avg_epoch_loss=-1.927350\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:48 INFO 140356611028800] #quality_metric: host=algo-1, epoch=206, batch=10 train loss <loss>=-1.92959010784\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:48 INFO 140356611028800] Epoch[206] Batch [10]#011Speed: 87.22 samples/sec#011loss=-1.929590\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:48 INFO 140356611028800] processed a total of 2101 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26476.727962493896, \"sum\": 26476.727962493896, \"min\": 26476.727962493896}}, \"EndTime\": 1600546008.949538, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600545982.472498}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:48 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.3524298095 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:48 INFO 140356611028800] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:48 INFO 140356611028800] #quality_metric: host=algo-1, epoch=206, train loss <loss>=-1.92735022431\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:51 INFO 140356611028800] Epoch[207] Batch[0] avg_epoch_loss=-1.935322\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:06:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=-1.93532224802\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:03 INFO 140356611028800] Epoch[207] Batch[5] avg_epoch_loss=-1.929877\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=-1.9298770122\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:03 INFO 140356611028800] Epoch[207] Batch [5]#011Speed: 87.48 samples/sec#011loss=-1.929877\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:13 INFO 140356611028800] processed a total of 2079 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24118.447065353394, \"sum\": 24118.447065353394, \"min\": 24118.447065353394}}, \"EndTime\": 1600546033.068284, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546008.949599}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:13 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.199230334 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:13 INFO 140356611028800] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:13 INFO 140356611028800] #quality_metric: host=algo-1, epoch=207, train loss <loss>=-1.92830181122\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:15 INFO 140356611028800] Epoch[208] Batch[0] avg_epoch_loss=-1.931636\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:15 INFO 140356611028800] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=-1.93163578327\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:27 INFO 140356611028800] Epoch[208] Batch[5] avg_epoch_loss=-1.931746\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:27 INFO 140356611028800] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=-1.93174606714\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:27 INFO 140356611028800] Epoch[208] Batch [5]#011Speed: 87.21 samples/sec#011loss=-1.931746\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:37 INFO 140356611028800] processed a total of 2024 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24146.75211906433, \"sum\": 24146.75211906433, \"min\": 24146.75211906433}}, \"EndTime\": 1600546057.215535, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546033.068349}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:37 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=83.8204879834 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:37 INFO 140356611028800] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=208, train loss <loss>=-1.93416193449\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:39 INFO 140356611028800] Epoch[209] Batch[0] avg_epoch_loss=-1.933136\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:39 INFO 140356611028800] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=-1.93313598633\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:51 INFO 140356611028800] Epoch[209] Batch[5] avg_epoch_loss=-1.932527\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=-1.9325274443\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:07:51 INFO 140356611028800] Epoch[209] Batch [5]#011Speed: 87.61 samples/sec#011loss=-1.932527\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:03 INFO 140356611028800] Epoch[209] Batch[10] avg_epoch_loss=-1.895608\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=209, batch=10 train loss <loss>=-1.85130459712\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:03 INFO 140356611028800] Epoch[209] Batch [10]#011Speed: 87.72 samples/sec#011loss=-1.851305\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:03 INFO 140356611028800] processed a total of 2117 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26484.062910079956, \"sum\": 26484.062910079956, \"min\": 26484.062910079956}}, \"EndTime\": 1600546083.699944, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546057.215596}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:03 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.9345961205 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:03 INFO 140356611028800] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=209, train loss <loss>=-1.89560796831\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:06 INFO 140356611028800] Epoch[210] Batch[0] avg_epoch_loss=-1.840089\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:06 INFO 140356611028800] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=-1.84008935782\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:18 INFO 140356611028800] Epoch[210] Batch[5] avg_epoch_loss=-1.860994\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:18 INFO 140356611028800] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=-1.86099360539\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:18 INFO 140356611028800] Epoch[210] Batch [5]#011Speed: 88.31 samples/sec#011loss=-1.860994\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:30 INFO 140356611028800] Epoch[210] Batch[10] avg_epoch_loss=-1.871703\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:30 INFO 140356611028800] #quality_metric: host=algo-1, epoch=210, batch=10 train loss <loss>=-1.88455522977\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:30 INFO 140356611028800] Epoch[210] Batch [10]#011Speed: 88.21 samples/sec#011loss=-1.884555\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:30 INFO 140356611028800] processed a total of 2117 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26309.467792510986, \"sum\": 26309.467792510986, \"min\": 26309.467792510986}}, \"EndTime\": 1600546110.009749, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546083.700005}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:30 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.4650511469 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:30 INFO 140356611028800] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:30 INFO 140356611028800] #quality_metric: host=algo-1, epoch=210, train loss <loss>=-1.87170343466\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:32 INFO 140356611028800] Epoch[211] Batch[0] avg_epoch_loss=-1.862936\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=-1.86293557974\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:44 INFO 140356611028800] Epoch[211] Batch[5] avg_epoch_loss=-1.897200\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=-1.89720021761\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:44 INFO 140356611028800] Epoch[211] Batch [5]#011Speed: 88.29 samples/sec#011loss=-1.897200\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:54 INFO 140356611028800] processed a total of 2080 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23992.66791343689, \"sum\": 23992.66791343689, \"min\": 23992.66791343689}}, \"EndTime\": 1600546134.002731, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546110.009811}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:54 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.6926529418 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:54 INFO 140356611028800] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:54 INFO 140356611028800] #quality_metric: host=algo-1, epoch=211, train loss <loss>=-1.90730540936\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:56 INFO 140356611028800] Epoch[212] Batch[0] avg_epoch_loss=-1.897397\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:08:56 INFO 140356611028800] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=-1.89739682124\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:08 INFO 140356611028800] Epoch[212] Batch[5] avg_epoch_loss=-1.917285\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:08 INFO 140356611028800] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=-1.91728543013\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:08 INFO 140356611028800] Epoch[212] Batch [5]#011Speed: 86.46 samples/sec#011loss=-1.917285\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:18 INFO 140356611028800] processed a total of 2072 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24247.02000617981, \"sum\": 24247.02000617981, \"min\": 24247.02000617981}}, \"EndTime\": 1600546158.250211, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546134.002827}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:18 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.4534790964 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:18 INFO 140356611028800] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:18 INFO 140356611028800] #quality_metric: host=algo-1, epoch=212, train loss <loss>=-1.91769616054\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:21 INFO 140356611028800] Epoch[213] Batch[0] avg_epoch_loss=-1.927485\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:21 INFO 140356611028800] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=-1.92748524592\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:32 INFO 140356611028800] Epoch[213] Batch[5] avg_epoch_loss=-1.925425\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=-1.92542535831\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:32 INFO 140356611028800] Epoch[213] Batch [5]#011Speed: 87.42 samples/sec#011loss=-1.925425\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:42 INFO 140356611028800] processed a total of 2044 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24140.90895652771, \"sum\": 24140.90895652771, \"min\": 24140.90895652771}}, \"EndTime\": 1600546182.391606, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546158.250275}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:42 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.6691829534 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:42 INFO 140356611028800] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:42 INFO 140356611028800] #quality_metric: host=algo-1, epoch=213, train loss <loss>=-1.92625233577\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:45 INFO 140356611028800] Epoch[214] Batch[0] avg_epoch_loss=-1.916328\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:45 INFO 140356611028800] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=-1.91632813674\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:56 INFO 140356611028800] Epoch[214] Batch[5] avg_epoch_loss=-1.929689\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:56 INFO 140356611028800] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=-1.92968916282\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:09:56 INFO 140356611028800] Epoch[214] Batch [5]#011Speed: 87.78 samples/sec#011loss=-1.929689\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:08 INFO 140356611028800] Epoch[214] Batch[10] avg_epoch_loss=-1.931545\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:08 INFO 140356611028800] #quality_metric: host=algo-1, epoch=214, batch=10 train loss <loss>=-1.9337721898\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:08 INFO 140356611028800] Epoch[214] Batch [10]#011Speed: 87.49 samples/sec#011loss=-1.933772\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:08 INFO 140356611028800] processed a total of 2141 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26493.20411682129, \"sum\": 26493.20411682129, \"min\": 26493.20411682129}}, \"EndTime\": 1600546208.885249, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546182.391677}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:08 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.8129154304 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:08 INFO 140356611028800] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:08 INFO 140356611028800] #quality_metric: host=algo-1, epoch=214, train loss <loss>=-1.93154508417\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:11 INFO 140356611028800] Epoch[215] Batch[0] avg_epoch_loss=-1.920942\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=-1.9209421598\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:23 INFO 140356611028800] Epoch[215] Batch[5] avg_epoch_loss=-1.921776\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:23 INFO 140356611028800] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=-1.92177584232\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:23 INFO 140356611028800] Epoch[215] Batch [5]#011Speed: 87.81 samples/sec#011loss=-1.921776\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:32 INFO 140356611028800] processed a total of 2036 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24096.635103225708, \"sum\": 24096.635103225708, \"min\": 24096.635103225708}}, \"EndTime\": 1600546232.982243, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546208.885305}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:32 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.492645063 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:32 INFO 140356611028800] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=215, train loss <loss>=-1.92205396799\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:35 INFO 140356611028800] Epoch[216] Batch[0] avg_epoch_loss=-1.937018\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:35 INFO 140356611028800] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=-1.93701832111\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:47 INFO 140356611028800] Epoch[216] Batch[5] avg_epoch_loss=-1.935818\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:47 INFO 140356611028800] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=-1.93581793858\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:47 INFO 140356611028800] Epoch[216] Batch [5]#011Speed: 87.80 samples/sec#011loss=-1.935818\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:59 INFO 140356611028800] Epoch[216] Batch[10] avg_epoch_loss=-1.932509\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:59 INFO 140356611028800] #quality_metric: host=algo-1, epoch=216, batch=10 train loss <loss>=-1.9285391294\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:59 INFO 140356611028800] Epoch[216] Batch [10]#011Speed: 86.44 samples/sec#011loss=-1.928539\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:59 INFO 140356611028800] processed a total of 2152 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26661.006927490234, \"sum\": 26661.006927490234, \"min\": 26661.006927490234}}, \"EndTime\": 1600546259.643661, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546232.982349}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:59 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.7168650707 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:59 INFO 140356611028800] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:10:59 INFO 140356611028800] #quality_metric: host=algo-1, epoch=216, train loss <loss>=-1.93250938896\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:02 INFO 140356611028800] Epoch[217] Batch[0] avg_epoch_loss=-1.934437\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=-1.93443738497\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:14 INFO 140356611028800] Epoch[217] Batch[5] avg_epoch_loss=-1.934288\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:14 INFO 140356611028800] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=-1.93428814717\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:14 INFO 140356611028800] Epoch[217] Batch [5]#011Speed: 87.92 samples/sec#011loss=-1.934288\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:26 INFO 140356611028800] Epoch[217] Batch[10] avg_epoch_loss=-1.939169\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:26 INFO 140356611028800] #quality_metric: host=algo-1, epoch=217, batch=10 train loss <loss>=-1.94502663246\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:26 INFO 140356611028800] Epoch[217] Batch [10]#011Speed: 86.30 samples/sec#011loss=-1.945027\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:26 INFO 140356611028800] processed a total of 2144 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26636.247873306274, \"sum\": 26636.247873306274, \"min\": 26636.247873306274}}, \"EndTime\": 1600546286.28023, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546259.64372}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:26 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.4915299301 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:26 INFO 140356611028800] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:26 INFO 140356611028800] #quality_metric: host=algo-1, epoch=217, train loss <loss>=-1.93916927684\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:29 INFO 140356611028800] Epoch[218] Batch[0] avg_epoch_loss=-1.941052\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:29 INFO 140356611028800] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=-1.94105207003\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:41 INFO 140356611028800] Epoch[218] Batch[5] avg_epoch_loss=-1.929496\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:41 INFO 140356611028800] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=-1.92949630053\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:41 INFO 140356611028800] Epoch[218] Batch [5]#011Speed: 86.53 samples/sec#011loss=-1.929496\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:52 INFO 140356611028800] Epoch[218] Batch[10] avg_epoch_loss=-1.935078\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:52 INFO 140356611028800] #quality_metric: host=algo-1, epoch=218, batch=10 train loss <loss>=-1.9417757181\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:52 INFO 140356611028800] Epoch[218] Batch [10]#011Speed: 87.76 samples/sec#011loss=-1.941776\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:52 INFO 140356611028800] processed a total of 2138 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26603.40189933777, \"sum\": 26603.40189933777, \"min\": 26603.40189933777}}, \"EndTime\": 1600546312.884017, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546286.280291}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:52 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.3653506688 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:52 INFO 140356611028800] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:52 INFO 140356611028800] #quality_metric: host=algo-1, epoch=218, train loss <loss>=-1.93507785397\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:55 INFO 140356611028800] Epoch[219] Batch[0] avg_epoch_loss=-1.934466\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:11:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=-1.93446628864\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:07 INFO 140356611028800] Epoch[219] Batch[5] avg_epoch_loss=-1.923744\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:07 INFO 140356611028800] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=-1.92374407939\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:07 INFO 140356611028800] Epoch[219] Batch [5]#011Speed: 87.04 samples/sec#011loss=-1.923744\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:19 INFO 140356611028800] Epoch[219] Batch[10] avg_epoch_loss=-1.925488\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=219, batch=10 train loss <loss>=-1.92758005582\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:19 INFO 140356611028800] Epoch[219] Batch [10]#011Speed: 87.67 samples/sec#011loss=-1.927580\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:19 INFO 140356611028800] processed a total of 2112 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26574.26619529724, \"sum\": 26574.26619529724, \"min\": 26574.26619529724}}, \"EndTime\": 1600546339.458679, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546312.88409}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:19 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.4747347516 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:19 INFO 140356611028800] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=219, train loss <loss>=-1.92548770504\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:22 INFO 140356611028800] Epoch[220] Batch[0] avg_epoch_loss=-1.940587\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=-1.94058682368\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:34 INFO 140356611028800] Epoch[220] Batch[5] avg_epoch_loss=-1.931016\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=-1.93101584606\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:34 INFO 140356611028800] Epoch[220] Batch [5]#011Speed: 88.05 samples/sec#011loss=-1.931016\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:43 INFO 140356611028800] processed a total of 2022 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24144.570112228394, \"sum\": 24144.570112228394, \"min\": 24144.570112228394}}, \"EndTime\": 1600546363.60402, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546339.45885}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:43 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=83.7447501728 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:43 INFO 140356611028800] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=220, train loss <loss>=-1.93252290579\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:46 INFO 140356611028800] Epoch[221] Batch[0] avg_epoch_loss=-1.937938\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=-1.93793810331\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:58 INFO 140356611028800] Epoch[221] Batch[5] avg_epoch_loss=-1.936210\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=-1.93620960529\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:12:58 INFO 140356611028800] Epoch[221] Batch [5]#011Speed: 87.92 samples/sec#011loss=-1.936210\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:07 INFO 140356611028800] processed a total of 2039 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24125.414848327637, \"sum\": 24125.414848327637, \"min\": 24125.414848327637}}, \"EndTime\": 1600546387.730003, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546363.604216}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:07 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.5162988492 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:07 INFO 140356611028800] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:07 INFO 140356611028800] #quality_metric: host=algo-1, epoch=221, train loss <loss>=-1.93078710116\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:10 INFO 140356611028800] Epoch[222] Batch[0] avg_epoch_loss=-1.936195\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=-1.93619522682\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:22 INFO 140356611028800] Epoch[222] Batch[5] avg_epoch_loss=-1.935671\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=-1.9356707304\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:22 INFO 140356611028800] Epoch[222] Batch [5]#011Speed: 87.96 samples/sec#011loss=-1.935671\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:34 INFO 140356611028800] Epoch[222] Batch[10] avg_epoch_loss=-1.928970\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=222, batch=10 train loss <loss>=-1.92092907245\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:34 INFO 140356611028800] Epoch[222] Batch [10]#011Speed: 88.20 samples/sec#011loss=-1.920929\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:34 INFO 140356611028800] processed a total of 2101 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26354.166984558105, \"sum\": 26354.166984558105, \"min\": 26354.166984558105}}, \"EndTime\": 1600546414.084561, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546387.73008}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:34 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.7214388638 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:34 INFO 140356611028800] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=222, train loss <loss>=-1.92896997679\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:36 INFO 140356611028800] Epoch[223] Batch[0] avg_epoch_loss=-1.911834\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=-1.91183442336\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:48 INFO 140356611028800] Epoch[223] Batch[5] avg_epoch_loss=-1.918296\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:48 INFO 140356611028800] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=-1.9182963249\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:48 INFO 140356611028800] Epoch[223] Batch [5]#011Speed: 88.38 samples/sec#011loss=-1.918296\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:58 INFO 140356611028800] processed a total of 2001 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24043.593883514404, \"sum\": 24043.593883514404, \"min\": 24043.593883514404}}, \"EndTime\": 1600546438.128598, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546414.084627}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:58 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=83.2234846439 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:58 INFO 140356611028800] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:13:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=223, train loss <loss>=-1.92066540351\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:00 INFO 140356611028800] Epoch[224] Batch[0] avg_epoch_loss=-1.889557\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:00 INFO 140356611028800] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=-1.88955732492\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:12 INFO 140356611028800] Epoch[224] Batch[5] avg_epoch_loss=-1.912800\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:12 INFO 140356611028800] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=-1.91279954177\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:12 INFO 140356611028800] Epoch[224] Batch [5]#011Speed: 87.93 samples/sec#011loss=-1.912800\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:24 INFO 140356611028800] Epoch[224] Batch[10] avg_epoch_loss=-1.900342\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:24 INFO 140356611028800] #quality_metric: host=algo-1, epoch=224, batch=10 train loss <loss>=-1.8853926732\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:24 INFO 140356611028800] Epoch[224] Batch [10]#011Speed: 87.28 samples/sec#011loss=-1.885393\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:24 INFO 140356611028800] processed a total of 2097 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26485.335111618042, \"sum\": 26485.335111618042, \"min\": 26485.335111618042}}, \"EndTime\": 1600546464.614285, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546438.128664}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:24 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.1756277794 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:24 INFO 140356611028800] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:24 INFO 140356611028800] #quality_metric: host=algo-1, epoch=224, train loss <loss>=-1.90034187424\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:27 INFO 140356611028800] Epoch[225] Batch[0] avg_epoch_loss=-1.910328\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:27 INFO 140356611028800] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=-1.91032761794\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:39 INFO 140356611028800] Epoch[225] Batch[5] avg_epoch_loss=-1.901838\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:39 INFO 140356611028800] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=-1.90183847378\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:39 INFO 140356611028800] Epoch[225] Batch [5]#011Speed: 87.93 samples/sec#011loss=-1.901838\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:51 INFO 140356611028800] Epoch[225] Batch[10] avg_epoch_loss=-1.921095\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=225, batch=10 train loss <loss>=-1.94420283391\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:51 INFO 140356611028800] Epoch[225] Batch [10]#011Speed: 87.84 samples/sec#011loss=-1.944203\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:51 INFO 140356611028800] processed a total of 2087 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26444.72312927246, \"sum\": 26444.72312927246, \"min\": 26444.72312927246}}, \"EndTime\": 1600546491.059333, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546464.614346}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:51 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.9190709812 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:51 INFO 140356611028800] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=225, train loss <loss>=-1.92109500111\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:53 INFO 140356611028800] Epoch[226] Batch[0] avg_epoch_loss=-1.902883\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:14:53 INFO 140356611028800] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=-1.90288338294\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:05 INFO 140356611028800] Epoch[226] Batch[5] avg_epoch_loss=-1.897272\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:05 INFO 140356611028800] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=-1.89727186545\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:05 INFO 140356611028800] Epoch[226] Batch [5]#011Speed: 87.98 samples/sec#011loss=-1.897272\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:17 INFO 140356611028800] Epoch[226] Batch[10] avg_epoch_loss=-1.908343\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=226, batch=10 train loss <loss>=-1.92162763155\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:17 INFO 140356611028800] Epoch[226] Batch [10]#011Speed: 85.89 samples/sec#011loss=-1.921628\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:17 INFO 140356611028800] processed a total of 2096 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26684.672117233276, \"sum\": 26684.672117233276, \"min\": 26684.672117233276}}, \"EndTime\": 1600546517.744355, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546491.059393}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:17 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.5466706949 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:17 INFO 140356611028800] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=226, train loss <loss>=-1.90834266823\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:20 INFO 140356611028800] Epoch[227] Batch[0] avg_epoch_loss=-1.920558\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:20 INFO 140356611028800] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=-1.92055804913\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:32 INFO 140356611028800] Epoch[227] Batch[5] avg_epoch_loss=-1.914243\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=-1.91424303788\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:32 INFO 140356611028800] Epoch[227] Batch [5]#011Speed: 87.44 samples/sec#011loss=-1.914243\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:44 INFO 140356611028800] Epoch[227] Batch[10] avg_epoch_loss=-1.921742\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=227, batch=10 train loss <loss>=-1.93074117807\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:44 INFO 140356611028800] Epoch[227] Batch [10]#011Speed: 88.07 samples/sec#011loss=-1.930741\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:44 INFO 140356611028800] processed a total of 2099 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26473.19507598877, \"sum\": 26473.19507598877, \"min\": 26473.19507598877}}, \"EndTime\": 1600546544.217897, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546517.744422}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:44 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.2874509095 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:44 INFO 140356611028800] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=227, train loss <loss>=-1.92174219252\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:46 INFO 140356611028800] Epoch[228] Batch[0] avg_epoch_loss=-1.810053\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=-1.81005301842\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:58 INFO 140356611028800] Epoch[228] Batch[5] avg_epoch_loss=-1.835180\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=-1.83518045377\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:15:58 INFO 140356611028800] Epoch[228] Batch [5]#011Speed: 87.31 samples/sec#011loss=-1.835180\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:10 INFO 140356611028800] Epoch[228] Batch[10] avg_epoch_loss=-1.836959\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=228, batch=10 train loss <loss>=-1.83909342839\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:10 INFO 140356611028800] Epoch[228] Batch [10]#011Speed: 87.82 samples/sec#011loss=-1.839093\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:10 INFO 140356611028800] processed a total of 2087 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26505.872011184692, \"sum\": 26505.872011184692, \"min\": 26505.872011184692}}, \"EndTime\": 1600546570.72407, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546544.217969}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:10 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.7370291577 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:10 INFO 140356611028800] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=228, train loss <loss>=-1.8369590786\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:13 INFO 140356611028800] Epoch[229] Batch[0] avg_epoch_loss=-1.877575\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:13 INFO 140356611028800] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=-1.87757536081\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:25 INFO 140356611028800] Epoch[229] Batch[5] avg_epoch_loss=-1.885690\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=-1.88568985768\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:25 INFO 140356611028800] Epoch[229] Batch [5]#011Speed: 87.51 samples/sec#011loss=-1.885690\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:34 INFO 140356611028800] processed a total of 1998 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24198.96697998047, \"sum\": 24198.96697998047, \"min\": 24198.96697998047}}, \"EndTime\": 1600546594.923396, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546570.724124}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:34 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.5652077569 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:34 INFO 140356611028800] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:34 INFO 140356611028800] #quality_metric: host=algo-1, epoch=229, train loss <loss>=-1.90014558939\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:37 INFO 140356611028800] Epoch[230] Batch[0] avg_epoch_loss=-1.909772\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=-1.90977228605\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:49 INFO 140356611028800] Epoch[230] Batch[5] avg_epoch_loss=-1.924746\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:49 INFO 140356611028800] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=-1.92474634219\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:16:49 INFO 140356611028800] Epoch[230] Batch [5]#011Speed: 87.88 samples/sec#011loss=-1.924746\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:01 INFO 140356611028800] Epoch[230] Batch[10] avg_epoch_loss=-1.916566\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:01 INFO 140356611028800] #quality_metric: host=algo-1, epoch=230, batch=10 train loss <loss>=-1.90675054697\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:01 INFO 140356611028800] Epoch[230] Batch [10]#011Speed: 87.26 samples/sec#011loss=-1.906751\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:01 INFO 140356611028800] processed a total of 2098 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26480.25608062744, \"sum\": 26480.25608062744, \"min\": 26480.25608062744}}, \"EndTime\": 1600546621.404053, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546594.923457}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:01 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.2285806799 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:01 INFO 140356611028800] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:01 INFO 140356611028800] #quality_metric: host=algo-1, epoch=230, train loss <loss>=-1.91656643527\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:04 INFO 140356611028800] Epoch[231] Batch[0] avg_epoch_loss=-1.903993\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=-1.90399301969\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:16 INFO 140356611028800] Epoch[231] Batch[5] avg_epoch_loss=-1.927521\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:16 INFO 140356611028800] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=-1.92752124102\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:16 INFO 140356611028800] Epoch[231] Batch [5]#011Speed: 87.75 samples/sec#011loss=-1.927521\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:25 INFO 140356611028800] processed a total of 2019 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24126.51300430298, \"sum\": 24126.51300430298, \"min\": 24126.51300430298}}, \"EndTime\": 1600546645.530868, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546621.404114}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:25 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=83.6835657708 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:25 INFO 140356611028800] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=231, train loss <loss>=-1.93084147527\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:28 INFO 140356611028800] Epoch[232] Batch[0] avg_epoch_loss=-1.934574\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=-1.93457442064\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:40 INFO 140356611028800] Epoch[232] Batch[5] avg_epoch_loss=-1.933832\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:40 INFO 140356611028800] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=-1.93383182623\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:40 INFO 140356611028800] Epoch[232] Batch [5]#011Speed: 87.79 samples/sec#011loss=-1.933832\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:49 INFO 140356611028800] processed a total of 2073 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24088.49811553955, \"sum\": 24088.49811553955, \"min\": 24088.49811553955}}, \"EndTime\": 1600546669.619764, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546645.530929}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:49 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.0572909202 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:49 INFO 140356611028800] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:49 INFO 140356611028800] #quality_metric: host=algo-1, epoch=232, train loss <loss>=-1.93447204003\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:52 INFO 140356611028800] Epoch[233] Batch[0] avg_epoch_loss=-1.926386\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:17:52 INFO 140356611028800] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=-1.92638631967\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:04 INFO 140356611028800] Epoch[233] Batch[5] avg_epoch_loss=-1.933861\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=-1.93386104779\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:04 INFO 140356611028800] Epoch[233] Batch [5]#011Speed: 87.34 samples/sec#011loss=-1.933861\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:13 INFO 140356611028800] processed a total of 2065 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24184.237003326416, \"sum\": 24184.237003326416, \"min\": 24184.237003326416}}, \"EndTime\": 1600546693.804497, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546669.619835}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:13 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.3855713722 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:13 INFO 140356611028800] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:13 INFO 140356611028800] #quality_metric: host=algo-1, epoch=233, train loss <loss>=-1.9332177529\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:16 INFO 140356611028800] Epoch[234] Batch[0] avg_epoch_loss=-1.941613\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:16 INFO 140356611028800] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=-1.94161283053\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:28 INFO 140356611028800] Epoch[234] Batch[5] avg_epoch_loss=-1.937701\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=-1.93770088294\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:28 INFO 140356611028800] Epoch[234] Batch [5]#011Speed: 87.96 samples/sec#011loss=-1.937701\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:40 INFO 140356611028800] Epoch[234] Batch[10] avg_epoch_loss=-1.905837\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:40 INFO 140356611028800] #quality_metric: host=algo-1, epoch=234, batch=10 train loss <loss>=-1.86759954599\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:40 INFO 140356611028800] Epoch[234] Batch [10]#011Speed: 88.23 samples/sec#011loss=-1.867600\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:40 INFO 140356611028800] processed a total of 2107 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26367.28596687317, \"sum\": 26367.28596687317, \"min\": 26367.28596687317}}, \"EndTime\": 1600546720.172267, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546693.804636}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:40 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.9093522133 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:40 INFO 140356611028800] #progress_metric: host=algo-1, completed 89 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:40 INFO 140356611028800] #quality_metric: host=algo-1, epoch=234, train loss <loss>=-1.90583663887\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:42 INFO 140356611028800] Epoch[235] Batch[0] avg_epoch_loss=-1.887471\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:42 INFO 140356611028800] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=-1.8874712724\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:54 INFO 140356611028800] Epoch[235] Batch[5] avg_epoch_loss=-1.900235\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:54 INFO 140356611028800] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=-1.90023458921\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:18:54 INFO 140356611028800] Epoch[235] Batch [5]#011Speed: 88.20 samples/sec#011loss=-1.900235\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:06 INFO 140356611028800] Epoch[235] Batch[10] avg_epoch_loss=-1.906150\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:06 INFO 140356611028800] #quality_metric: host=algo-1, epoch=235, batch=10 train loss <loss>=-1.91324958801\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:06 INFO 140356611028800] Epoch[235] Batch [10]#011Speed: 87.87 samples/sec#011loss=-1.913250\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:06 INFO 140356611028800] processed a total of 2133 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26369.580030441284, \"sum\": 26369.580030441284, \"min\": 26369.580030441284}}, \"EndTime\": 1600546746.542168, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546720.172331}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:06 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.8883933079 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:06 INFO 140356611028800] #progress_metric: host=algo-1, completed 89 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:06 INFO 140356611028800] #quality_metric: host=algo-1, epoch=235, train loss <loss>=-1.90615049776\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:09 INFO 140356611028800] Epoch[236] Batch[0] avg_epoch_loss=-1.942958\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:09 INFO 140356611028800] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=-1.94295809819\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:21 INFO 140356611028800] Epoch[236] Batch[5] avg_epoch_loss=-1.929708\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:21 INFO 140356611028800] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=-1.92970808958\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:21 INFO 140356611028800] Epoch[236] Batch [5]#011Speed: 88.07 samples/sec#011loss=-1.929708\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:32 INFO 140356611028800] Epoch[236] Batch[10] avg_epoch_loss=-1.935512\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=236, batch=10 train loss <loss>=-1.94247759306\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:32 INFO 140356611028800] Epoch[236] Batch [10]#011Speed: 88.00 samples/sec#011loss=-1.942478\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:32 INFO 140356611028800] processed a total of 2097 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26357.326984405518, \"sum\": 26357.326984405518, \"min\": 26357.326984405518}}, \"EndTime\": 1600546772.899843, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546746.542224}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:32 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.5601506548 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:32 INFO 140356611028800] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=236, train loss <loss>=-1.93551240934\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:35 INFO 140356611028800] Epoch[237] Batch[0] avg_epoch_loss=-1.925855\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:35 INFO 140356611028800] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=-1.92585460956\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:47 INFO 140356611028800] Epoch[237] Batch[5] avg_epoch_loss=-1.928057\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:47 INFO 140356611028800] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=-1.928056937\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:47 INFO 140356611028800] Epoch[237] Batch [5]#011Speed: 87.86 samples/sec#011loss=-1.928057\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:59 INFO 140356611028800] Epoch[237] Batch[10] avg_epoch_loss=-1.936704\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:59 INFO 140356611028800] #quality_metric: host=algo-1, epoch=237, batch=10 train loss <loss>=-1.94707958515\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:59 INFO 140356611028800] Epoch[237] Batch [10]#011Speed: 87.54 samples/sec#011loss=-1.947080\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:59 INFO 140356611028800] processed a total of 2111 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26502.65383720398, \"sum\": 26502.65383720398, \"min\": 26502.65383720398}}, \"EndTime\": 1600546799.402788, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546772.899904}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:59 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.652132594 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:59 INFO 140356611028800] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:19:59 INFO 140356611028800] #quality_metric: host=algo-1, epoch=237, train loss <loss>=-1.93670359525\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:02 INFO 140356611028800] Epoch[238] Batch[0] avg_epoch_loss=-1.898659\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=-1.89865860572\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:14 INFO 140356611028800] Epoch[238] Batch[5] avg_epoch_loss=-1.887858\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:14 INFO 140356611028800] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=-1.88785780393\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:14 INFO 140356611028800] Epoch[238] Batch [5]#011Speed: 87.51 samples/sec#011loss=-1.887858\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:26 INFO 140356611028800] Epoch[238] Batch[10] avg_epoch_loss=-1.894123\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:26 INFO 140356611028800] #quality_metric: host=algo-1, epoch=238, batch=10 train loss <loss>=-1.90164087736\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:26 INFO 140356611028800] Epoch[238] Batch [10]#011Speed: 87.00 samples/sec#011loss=-1.901641\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:26 INFO 140356611028800] processed a total of 2159 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26647.740840911865, \"sum\": 26647.740840911865, \"min\": 26647.740840911865}}, \"EndTime\": 1600546826.050829, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546799.402849}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:26 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.0197244842 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:26 INFO 140356611028800] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:26 INFO 140356611028800] #quality_metric: host=algo-1, epoch=238, train loss <loss>=-1.89412283731\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:28 INFO 140356611028800] Epoch[239] Batch[0] avg_epoch_loss=-1.866255\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=-1.86625524668\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:40 INFO 140356611028800] Epoch[239] Batch[5] avg_epoch_loss=-1.897417\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:40 INFO 140356611028800] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=-1.89741711739\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:40 INFO 140356611028800] Epoch[239] Batch [5]#011Speed: 87.08 samples/sec#011loss=-1.897417\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:50 INFO 140356611028800] processed a total of 2068 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24189.175844192505, \"sum\": 24189.175844192505, \"min\": 24189.175844192505}}, \"EndTime\": 1600546850.240361, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546826.05089}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:50 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.4924736583 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:50 INFO 140356611028800] #progress_metric: host=algo-1, completed 91 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:50 INFO 140356611028800] #quality_metric: host=algo-1, epoch=239, train loss <loss>=-1.90519029177\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:53 INFO 140356611028800] Epoch[240] Batch[0] avg_epoch_loss=-1.920712\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:20:53 INFO 140356611028800] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=-1.92071166405\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:04 INFO 140356611028800] Epoch[240] Batch[5] avg_epoch_loss=-1.927482\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=-1.92748184693\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:04 INFO 140356611028800] Epoch[240] Batch [5]#011Speed: 87.73 samples/sec#011loss=-1.927482\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:14 INFO 140356611028800] processed a total of 2065 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24207.085132598877, \"sum\": 24207.085132598877, \"min\": 24207.085132598877}}, \"EndTime\": 1600546874.448059, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546850.24042}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:14 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.3052436455 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:14 INFO 140356611028800] #progress_metric: host=algo-1, completed 91 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:14 INFO 140356611028800] #quality_metric: host=algo-1, epoch=240, train loss <loss>=-1.93065715203\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:17 INFO 140356611028800] Epoch[241] Batch[0] avg_epoch_loss=-1.943078\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=-1.94307826116\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:29 INFO 140356611028800] Epoch[241] Batch[5] avg_epoch_loss=-1.932055\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:29 INFO 140356611028800] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=-1.93205520434\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:29 INFO 140356611028800] Epoch[241] Batch [5]#011Speed: 87.36 samples/sec#011loss=-1.932055\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:41 INFO 140356611028800] Epoch[241] Batch[10] avg_epoch_loss=-1.943542\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:41 INFO 140356611028800] #quality_metric: host=algo-1, epoch=241, batch=10 train loss <loss>=-1.95732597938\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:41 INFO 140356611028800] Epoch[241] Batch [10]#011Speed: 87.26 samples/sec#011loss=-1.957326\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:41 INFO 140356611028800] processed a total of 2112 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26571.338891983032, \"sum\": 26571.338891983032, \"min\": 26571.338891983032}}, \"EndTime\": 1600546901.019831, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546874.448126}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:41 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.4838753488 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:41 INFO 140356611028800] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:41 INFO 140356611028800] #quality_metric: host=algo-1, epoch=241, train loss <loss>=-1.94354192027\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:43 INFO 140356611028800] Epoch[242] Batch[0] avg_epoch_loss=-1.895853\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=-1.89585333604\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:55 INFO 140356611028800] Epoch[242] Batch[5] avg_epoch_loss=-1.904950\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=-1.90494960394\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:21:55 INFO 140356611028800] Epoch[242] Batch [5]#011Speed: 87.74 samples/sec#011loss=-1.904950\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:05 INFO 140356611028800] processed a total of 2057 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24069.905996322632, \"sum\": 24069.905996322632, \"min\": 24069.905996322632}}, \"EndTime\": 1600546925.090166, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546901.019887}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:05 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.4590990894 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:05 INFO 140356611028800] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:05 INFO 140356611028800] #quality_metric: host=algo-1, epoch=242, train loss <loss>=-1.91331214905\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:07 INFO 140356611028800] Epoch[243] Batch[0] avg_epoch_loss=-1.915057\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:07 INFO 140356611028800] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=-1.91505740239\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:19 INFO 140356611028800] Epoch[243] Batch[5] avg_epoch_loss=-1.924537\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:19 INFO 140356611028800] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=-1.92453736525\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:19 INFO 140356611028800] Epoch[243] Batch [5]#011Speed: 87.96 samples/sec#011loss=-1.924537\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:29 INFO 140356611028800] processed a total of 2053 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24076.46107673645, \"sum\": 24076.46107673645, \"min\": 24076.46107673645}}, \"EndTime\": 1600546949.167017, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546925.090225}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:29 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.26964288 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:29 INFO 140356611028800] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:29 INFO 140356611028800] #quality_metric: host=algo-1, epoch=243, train loss <loss>=-1.92546740312\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:31 INFO 140356611028800] Epoch[244] Batch[0] avg_epoch_loss=-1.907299\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:31 INFO 140356611028800] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=-1.90729904175\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:43 INFO 140356611028800] Epoch[244] Batch[5] avg_epoch_loss=-1.916102\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:43 INFO 140356611028800] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=-1.91610211592\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:43 INFO 140356611028800] Epoch[244] Batch [5]#011Speed: 87.51 samples/sec#011loss=-1.916102\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:55 INFO 140356611028800] Epoch[244] Batch[10] avg_epoch_loss=-1.918361\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=244, batch=10 train loss <loss>=-1.92107089116\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:55 INFO 140356611028800] Epoch[244] Batch [10]#011Speed: 87.08 samples/sec#011loss=-1.921071\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:55 INFO 140356611028800] processed a total of 2104 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26623.055934906006, \"sum\": 26623.055934906006, \"min\": 26623.055934906006}}, \"EndTime\": 1600546975.790501, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546949.167086}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:55 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.0289891284 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:55 INFO 140356611028800] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:55 INFO 140356611028800] #quality_metric: host=algo-1, epoch=244, train loss <loss>=-1.91836065012\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:58 INFO 140356611028800] Epoch[245] Batch[0] avg_epoch_loss=-1.909432\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:22:58 INFO 140356611028800] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=-1.9094320444\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:10 INFO 140356611028800] Epoch[245] Batch[5] avg_epoch_loss=-1.873822\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=-1.87382177206\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:10 INFO 140356611028800] Epoch[245] Batch [5]#011Speed: 87.44 samples/sec#011loss=-1.873822\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:22 INFO 140356611028800] Epoch[245] Batch[10] avg_epoch_loss=-1.886139\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=245, batch=10 train loss <loss>=-1.90092069186\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:22 INFO 140356611028800] Epoch[245] Batch [10]#011Speed: 88.22 samples/sec#011loss=-1.900921\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:22 INFO 140356611028800] processed a total of 2167 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26447.622060775757, \"sum\": 26447.622060775757, \"min\": 26447.622060775757}}, \"EndTime\": 1600547002.238424, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600546975.790559}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:22 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.9352667117 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:22 INFO 140356611028800] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:22 INFO 140356611028800] #quality_metric: host=algo-1, epoch=245, train loss <loss>=-1.88613946288\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:25 INFO 140356611028800] Epoch[246] Batch[0] avg_epoch_loss=-1.874825\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:25 INFO 140356611028800] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=-1.87482452393\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:36 INFO 140356611028800] Epoch[246] Batch[5] avg_epoch_loss=-1.896070\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=-1.89606986902\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:36 INFO 140356611028800] Epoch[246] Batch [5]#011Speed: 88.32 samples/sec#011loss=-1.896070\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:46 INFO 140356611028800] processed a total of 2048 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23961.838960647583, \"sum\": 23961.838960647583, \"min\": 23961.838960647583}}, \"EndTime\": 1600547026.200547, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547002.238483}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:46 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.468858085 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:46 INFO 140356611028800] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:46 INFO 140356611028800] #quality_metric: host=algo-1, epoch=246, train loss <loss>=-1.90869049659\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:48 INFO 140356611028800] Epoch[247] Batch[0] avg_epoch_loss=-1.916254\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:23:48 INFO 140356611028800] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=-1.91625389686\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:00 INFO 140356611028800] Epoch[247] Batch[5] avg_epoch_loss=-1.909527\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:00 INFO 140356611028800] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=-1.90952692276\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:00 INFO 140356611028800] Epoch[247] Batch [5]#011Speed: 88.00 samples/sec#011loss=-1.909527\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:10 INFO 140356611028800] processed a total of 2054 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24040.701150894165, \"sum\": 24040.701150894165, \"min\": 24040.701150894165}}, \"EndTime\": 1600547050.241594, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547026.200623}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:10 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.4381128185 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:10 INFO 140356611028800] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:10 INFO 140356611028800] #quality_metric: host=algo-1, epoch=247, train loss <loss>=-1.91603415563\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:13 INFO 140356611028800] Epoch[248] Batch[0] avg_epoch_loss=-1.913489\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:13 INFO 140356611028800] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=-1.91348897494\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:24 INFO 140356611028800] Epoch[248] Batch[5] avg_epoch_loss=-1.923877\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:24 INFO 140356611028800] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=-1.92387749599\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:24 INFO 140356611028800] Epoch[248] Batch [5]#011Speed: 87.49 samples/sec#011loss=-1.923877\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:36 INFO 140356611028800] Epoch[248] Batch[10] avg_epoch_loss=-1.927310\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=248, batch=10 train loss <loss>=-1.93142870389\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:36 INFO 140356611028800] Epoch[248] Batch [10]#011Speed: 87.79 samples/sec#011loss=-1.931429\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:36 INFO 140356611028800] processed a total of 2126 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26519.34003829956, \"sum\": 26519.34003829956, \"min\": 26519.34003829956}}, \"EndTime\": 1600547076.761259, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547050.241657}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:36 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.1676444632 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:36 INFO 140356611028800] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=248, train loss <loss>=-1.92730986322\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:39 INFO 140356611028800] Epoch[249] Batch[0] avg_epoch_loss=-1.934201\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:39 INFO 140356611028800] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=-1.93420116718\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:51 INFO 140356611028800] Epoch[249] Batch[5] avg_epoch_loss=-1.933542\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:51 INFO 140356611028800] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=-1.9335416158\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:24:51 INFO 140356611028800] Epoch[249] Batch [5]#011Speed: 88.01 samples/sec#011loss=-1.933542\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:03 INFO 140356611028800] Epoch[249] Batch[10] avg_epoch_loss=-1.939935\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=249, batch=10 train loss <loss>=-1.94760748056\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:03 INFO 140356611028800] Epoch[249] Batch [10]#011Speed: 87.43 samples/sec#011loss=-1.947607\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:03 INFO 140356611028800] processed a total of 2085 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26467.978954315186, \"sum\": 26467.978954315186, \"min\": 26467.978954315186}}, \"EndTime\": 1600547103.22961, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547076.761317}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:03 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.7741663019 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:03 INFO 140356611028800] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:03 INFO 140356611028800] #quality_metric: host=algo-1, epoch=249, train loss <loss>=-1.93993519069\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:05 INFO 140356611028800] Epoch[250] Batch[0] avg_epoch_loss=-1.931265\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:05 INFO 140356611028800] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=-1.93126531748\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:17 INFO 140356611028800] Epoch[250] Batch[5] avg_epoch_loss=-1.932043\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:17 INFO 140356611028800] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=-1.93204283103\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:17 INFO 140356611028800] Epoch[250] Batch [5]#011Speed: 87.35 samples/sec#011loss=-1.932043\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:29 INFO 140356611028800] Epoch[250] Batch[10] avg_epoch_loss=-1.938149\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:29 INFO 140356611028800] #quality_metric: host=algo-1, epoch=250, batch=10 train loss <loss>=-1.9454757397\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:29 INFO 140356611028800] Epoch[250] Batch [10]#011Speed: 87.78 samples/sec#011loss=-1.945476\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:29 INFO 140356611028800] processed a total of 2138 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26511.791944503784, \"sum\": 26511.791944503784, \"min\": 26511.791944503784}}, \"EndTime\": 1600547129.741696, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547103.229671}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:29 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.6430684155 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:29 INFO 140356611028800] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:29 INFO 140356611028800] #quality_metric: host=algo-1, epoch=250, train loss <loss>=-1.93814869861\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:32 INFO 140356611028800] Epoch[251] Batch[0] avg_epoch_loss=-1.926168\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:32 INFO 140356611028800] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=-1.92616770818\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:44 INFO 140356611028800] Epoch[251] Batch[5] avg_epoch_loss=-1.930919\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:44 INFO 140356611028800] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=-1.93091888917\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:44 INFO 140356611028800] Epoch[251] Batch [5]#011Speed: 86.87 samples/sec#011loss=-1.930919\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:56 INFO 140356611028800] Epoch[251] Batch[10] avg_epoch_loss=-1.928758\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:56 INFO 140356611028800] #quality_metric: host=algo-1, epoch=251, batch=10 train loss <loss>=-1.9261657128\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:56 INFO 140356611028800] Epoch[251] Batch [10]#011Speed: 86.81 samples/sec#011loss=-1.926166\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:56 INFO 140356611028800] processed a total of 2092 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26682.186126708984, \"sum\": 26682.186126708984, \"min\": 26682.186126708984}}, \"EndTime\": 1600547156.424276, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547129.741759}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:56 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=78.4040998204 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:56 INFO 140356611028800] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:56 INFO 140356611028800] #quality_metric: host=algo-1, epoch=251, train loss <loss>=-1.92875835445\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:59 INFO 140356611028800] Epoch[252] Batch[0] avg_epoch_loss=-1.912786\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:25:59 INFO 140356611028800] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=-1.91278648376\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:11 INFO 140356611028800] Epoch[252] Batch[5] avg_epoch_loss=-1.908116\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=-1.90811643845\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:11 INFO 140356611028800] Epoch[252] Batch [5]#011Speed: 87.99 samples/sec#011loss=-1.908116\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:20 INFO 140356611028800] processed a total of 2078 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24094.534873962402, \"sum\": 24094.534873962402, \"min\": 24094.534873962402}}, \"EndTime\": 1600547180.519153, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547156.424339}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:20 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=86.2432695896 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:20 INFO 140356611028800] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:20 INFO 140356611028800] #quality_metric: host=algo-1, epoch=252, train loss <loss>=-1.91203958071\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:23 INFO 140356611028800] Epoch[253] Batch[0] avg_epoch_loss=-1.936552\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:23 INFO 140356611028800] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=-1.93655219445\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:35 INFO 140356611028800] Epoch[253] Batch[5] avg_epoch_loss=-1.928890\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:35 INFO 140356611028800] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=-1.92889027718\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:35 INFO 140356611028800] Epoch[253] Batch [5]#011Speed: 86.40 samples/sec#011loss=-1.928890\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:47 INFO 140356611028800] Epoch[253] Batch[10] avg_epoch_loss=-1.924418\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:47 INFO 140356611028800] #quality_metric: host=algo-1, epoch=253, batch=10 train loss <loss>=-1.91905235877\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:47 INFO 140356611028800] Epoch[253] Batch [10]#011Speed: 87.72 samples/sec#011loss=-1.919052\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:47 INFO 140356611028800] processed a total of 2139 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26636.26790046692, \"sum\": 26636.26790046692, \"min\": 26636.26790046692}}, \"EndTime\": 1600547207.155833, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547180.519219}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:47 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=80.3037747844 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:47 INFO 140356611028800] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:47 INFO 140356611028800] #quality_metric: host=algo-1, epoch=253, train loss <loss>=-1.92441849609\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:49 INFO 140356611028800] Epoch[254] Batch[0] avg_epoch_loss=-1.912596\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:26:49 INFO 140356611028800] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=-1.91259604234\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:01 INFO 140356611028800] Epoch[254] Batch[5] avg_epoch_loss=-1.904646\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:01 INFO 140356611028800] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=-1.90464587089\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:01 INFO 140356611028800] Epoch[254] Batch [5]#011Speed: 87.20 samples/sec#011loss=-1.904646\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:11 INFO 140356611028800] processed a total of 2055 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24178.09820175171, \"sum\": 24178.09820175171, \"min\": 24178.09820175171}}, \"EndTime\": 1600547231.33423, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547207.155893}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:11 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=84.993838823 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:11 INFO 140356611028800] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=254, train loss <loss>=-1.90959578294\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:14 INFO 140356611028800] Epoch[255] Batch[0] avg_epoch_loss=-1.929281\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:14 INFO 140356611028800] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=-1.92928079458\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:26 INFO 140356611028800] Epoch[255] Batch[5] avg_epoch_loss=-1.928282\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:26 INFO 140356611028800] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=-1.92828227312\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:26 INFO 140356611028800] Epoch[255] Batch [5]#011Speed: 86.85 samples/sec#011loss=-1.928282\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:37 INFO 140356611028800] Epoch[255] Batch[10] avg_epoch_loss=-1.932884\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=255, batch=10 train loss <loss>=-1.93840508094\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:37 INFO 140356611028800] Epoch[255] Batch [10]#011Speed: 88.21 samples/sec#011loss=-1.938405\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:37 INFO 140356611028800] processed a total of 2098 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26536.28396987915, \"sum\": 26536.28396987915, \"min\": 26536.28396987915}}, \"EndTime\": 1600547257.870889, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547231.334327}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:37 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.061296902 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:37 INFO 140356611028800] #progress_metric: host=algo-1, completed 97 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:37 INFO 140356611028800] #quality_metric: host=algo-1, epoch=255, train loss <loss>=-1.9328835494\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:40 INFO 140356611028800] Epoch[256] Batch[0] avg_epoch_loss=-1.790232\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:40 INFO 140356611028800] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=-1.79023185143\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:52 INFO 140356611028800] Epoch[256] Batch[5] avg_epoch_loss=-1.831255\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:52 INFO 140356611028800] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=-1.83125471457\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:27:52 INFO 140356611028800] Epoch[256] Batch [5]#011Speed: 87.96 samples/sec#011loss=-1.831255\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:02 INFO 140356611028800] processed a total of 2005 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24141.903162002563, \"sum\": 24141.903162002563, \"min\": 24141.903162002563}}, \"EndTime\": 1600547282.013126, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547257.870949}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:02 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=83.0503130126 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:02 INFO 140356611028800] #progress_metric: host=algo-1, completed 97 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:02 INFO 140356611028800] #quality_metric: host=algo-1, epoch=256, train loss <loss>=-1.8406028014\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:04 INFO 140356611028800] Epoch[257] Batch[0] avg_epoch_loss=-1.842755\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:04 INFO 140356611028800] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=-1.84275451073\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:16 INFO 140356611028800] Epoch[257] Batch[5] avg_epoch_loss=-1.876213\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:16 INFO 140356611028800] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=-1.87621260912\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:16 INFO 140356611028800] Epoch[257] Batch [5]#011Speed: 87.45 samples/sec#011loss=-1.876213\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:28 INFO 140356611028800] Epoch[257] Batch[10] avg_epoch_loss=-1.870615\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=257, batch=10 train loss <loss>=-1.86389829195\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:28 INFO 140356611028800] Epoch[257] Batch [10]#011Speed: 88.09 samples/sec#011loss=-1.863898\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:28 INFO 140356611028800] processed a total of 2175 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26468.18709373474, \"sum\": 26468.18709373474, \"min\": 26468.18709373474}}, \"EndTime\": 1600547308.481869, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547282.013186}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:28 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.1738134809 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:28 INFO 140356611028800] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:28 INFO 140356611028800] #quality_metric: host=algo-1, epoch=257, train loss <loss>=-1.87061519223\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:31 INFO 140356611028800] Epoch[258] Batch[0] avg_epoch_loss=-1.901268\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:31 INFO 140356611028800] #quality_metric: host=algo-1, epoch=258, batch=0 train loss <loss>=-1.90126771193\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:42 INFO 140356611028800] Epoch[258] Batch[5] avg_epoch_loss=-1.916627\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:42 INFO 140356611028800] #quality_metric: host=algo-1, epoch=258, batch=5 train loss <loss>=-1.91662707696\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:42 INFO 140356611028800] Epoch[258] Batch [5]#011Speed: 88.47 samples/sec#011loss=-1.916627\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:54 INFO 140356611028800] Epoch[258] Batch[10] avg_epoch_loss=-1.916768\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:54 INFO 140356611028800] #quality_metric: host=algo-1, epoch=258, batch=10 train loss <loss>=-1.91693617014\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:54 INFO 140356611028800] Epoch[258] Batch [10]#011Speed: 88.30 samples/sec#011loss=-1.916936\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:54 INFO 140356611028800] processed a total of 2136 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26277.49991416931, \"sum\": 26277.49991416931, \"min\": 26277.49991416931}}, \"EndTime\": 1600547334.759735, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547308.481935}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:54 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=81.2859716214 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:54 INFO 140356611028800] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:54 INFO 140356611028800] #quality_metric: host=algo-1, epoch=258, train loss <loss>=-1.91676757386\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:57 INFO 140356611028800] Epoch[259] Batch[0] avg_epoch_loss=-1.911631\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:28:57 INFO 140356611028800] #quality_metric: host=algo-1, epoch=259, batch=0 train loss <loss>=-1.91163136409\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:09 INFO 140356611028800] Epoch[259] Batch[5] avg_epoch_loss=-1.915483\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:09 INFO 140356611028800] #quality_metric: host=algo-1, epoch=259, batch=5 train loss <loss>=-1.91548276559\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:09 INFO 140356611028800] Epoch[259] Batch [5]#011Speed: 88.17 samples/sec#011loss=-1.915483\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:21 INFO 140356611028800] Epoch[259] Batch[10] avg_epoch_loss=-1.920919\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:21 INFO 140356611028800] #quality_metric: host=algo-1, epoch=259, batch=10 train loss <loss>=-1.92744252132\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:21 INFO 140356611028800] Epoch[259] Batch [10]#011Speed: 88.05 samples/sec#011loss=-1.927443\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:21 INFO 140356611028800] processed a total of 2178 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26354.207038879395, \"sum\": 26354.207038879395, \"min\": 26354.207038879395}}, \"EndTime\": 1600547361.114482, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547334.759801}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:21 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=82.6430570858 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:21 INFO 140356611028800] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:21 INFO 140356611028800] #quality_metric: host=algo-1, epoch=259, train loss <loss>=-1.92091901819\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:23 INFO 140356611028800] Epoch[260] Batch[0] avg_epoch_loss=-1.904022\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:23 INFO 140356611028800] #quality_metric: host=algo-1, epoch=260, batch=0 train loss <loss>=-1.90402207008\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:35 INFO 140356611028800] Epoch[260] Batch[5] avg_epoch_loss=-1.923481\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:35 INFO 140356611028800] #quality_metric: host=algo-1, epoch=260, batch=5 train loss <loss>=-1.92348091419\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:35 INFO 140356611028800] Epoch[260] Batch [5]#011Speed: 87.11 samples/sec#011loss=-1.923481\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:45 INFO 140356611028800] processed a total of 2065 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24290.696144104004, \"sum\": 24290.696144104004, \"min\": 24290.696144104004}}, \"EndTime\": 1600547385.405525, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547361.114544}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:45 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.0116507227 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:45 INFO 140356611028800] #progress_metric: host=algo-1, completed 99 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:45 INFO 140356611028800] #quality_metric: host=algo-1, epoch=260, train loss <loss>=-1.92935645764\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:48 INFO 140356611028800] Epoch[261] Batch[0] avg_epoch_loss=-1.934674\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:29:48 INFO 140356611028800] #quality_metric: host=algo-1, epoch=261, batch=0 train loss <loss>=-1.93467404292\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:00 INFO 140356611028800] Epoch[261] Batch[5] avg_epoch_loss=-1.937592\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:00 INFO 140356611028800] #quality_metric: host=algo-1, epoch=261, batch=5 train loss <loss>=-1.93759206625\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:00 INFO 140356611028800] Epoch[261] Batch [5]#011Speed: 87.56 samples/sec#011loss=-1.937592\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:11 INFO 140356611028800] Epoch[261] Batch[10] avg_epoch_loss=-1.930710\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=261, batch=10 train loss <loss>=-1.9224504911\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:11 INFO 140356611028800] Epoch[261] Batch [10]#011Speed: 87.32 samples/sec#011loss=-1.922450\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:11 INFO 140356611028800] processed a total of 2106 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26526.69620513916, \"sum\": 26526.69620513916, \"min\": 26526.69620513916}}, \"EndTime\": 1600547411.932645, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547385.405584}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:11 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=79.3914524229 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:11 INFO 140356611028800] #progress_metric: host=algo-1, completed 99 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:11 INFO 140356611028800] #quality_metric: host=algo-1, epoch=261, train loss <loss>=-1.93070953209\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:14 INFO 140356611028800] Epoch[262] Batch[0] avg_epoch_loss=-1.901634\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:14 INFO 140356611028800] #quality_metric: host=algo-1, epoch=262, batch=0 train loss <loss>=-1.90163392287\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:26 INFO 140356611028800] Epoch[262] Batch[5] avg_epoch_loss=-1.916190\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:26 INFO 140356611028800] #quality_metric: host=algo-1, epoch=262, batch=5 train loss <loss>=-1.91619012295\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:26 INFO 140356611028800] Epoch[262] Batch [5]#011Speed: 86.71 samples/sec#011loss=-1.916190\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:36 INFO 140356611028800] processed a total of 2079 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24277.064085006714, \"sum\": 24277.064085006714, \"min\": 24277.064085006714}}, \"EndTime\": 1600547436.21008, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547411.932705}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:36 INFO 140356611028800] #throughput_metric: host=algo-1, train throughput=85.6360180462 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:36 INFO 140356611028800] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:36 INFO 140356611028800] #quality_metric: host=algo-1, epoch=262, train loss <loss>=-1.92219079825\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:36 INFO 140356611028800] Final loss: -1.92219079825 (occurred at epoch 262)\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:36 INFO 140356611028800] #quality_metric: host=algo-1, train final_loss <loss>=-1.92219079825\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:36 INFO 140356611028800] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:36 WARNING 140356611028800] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:36 INFO 140356611028800] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 451.98607444763184, \"sum\": 451.98607444763184, \"min\": 451.98607444763184}}, \"EndTime\": 1600547436.662825, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547436.210149}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:36 INFO 140356611028800] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 695.2760219573975, \"sum\": 695.2760219573975, \"min\": 695.2760219573975}}, \"EndTime\": 1600547436.90608, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547436.662883}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:36 INFO 140356611028800] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:36 INFO 140356611028800] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 48.770904541015625, \"sum\": 48.770904541015625, \"min\": 48.770904541015625}}, \"EndTime\": 1600547436.954953, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547436.906139}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:36 INFO 140356611028800] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:30:36 INFO 140356611028800] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.03504753112792969, \"sum\": 0.03504753112792969, \"min\": 0.03504753112792969}}, \"EndTime\": 1600547436.955665, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547436.955}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 111561.1641407013, \"sum\": 111561.1641407013, \"min\": 111561.1641407013}}, \"EndTime\": 1600547548.51679, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547436.955707}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:32:28 INFO 140356611028800] #test_score (algo-1, RMSE): 0.0872618432425\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:32:28 INFO 140356611028800] #test_score (algo-1, mean_absolute_QuantileLoss): 661.433787045545\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:32:28 INFO 140356611028800] #test_score (algo-1, mean_wQuantileLoss): 0.09573522582343956\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:32:28 INFO 140356611028800] #test_score (algo-1, wQuantileLoss[0.1]): 0.073448073987746\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:32:28 INFO 140356611028800] #test_score (algo-1, wQuantileLoss[0.2]): 0.10128258474857449\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:32:28 INFO 140356611028800] #test_score (algo-1, wQuantileLoss[0.3]): 0.1158508695031694\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:32:28 INFO 140356611028800] #test_score (algo-1, wQuantileLoss[0.4]): 0.12154462547717265\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:32:28 INFO 140356611028800] #test_score (algo-1, wQuantileLoss[0.5]): 0.11990017505663185\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:32:28 INFO 140356611028800] #test_score (algo-1, wQuantileLoss[0.6]): 0.11161520983969724\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:32:28 INFO 140356611028800] #test_score (algo-1, wQuantileLoss[0.7]): 0.0969071904612062\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:32:28 INFO 140356611028800] #test_score (algo-1, wQuantileLoss[0.8]): 0.07535637061067224\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:32:28 INFO 140356611028800] #test_score (algo-1, wQuantileLoss[0.9]): 0.045711932726086014\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:32:28 INFO 140356611028800] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.0957352258234\u001b[0m\n",
      "\u001b[34m[09/19/2020 20:32:28 INFO 140356611028800] #quality_metric: host=algo-1, test RMSE <loss>=0.0872618432425\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 6850403.307199478, \"sum\": 6850403.307199478, \"min\": 6850403.307199478}, \"setuptime\": {\"count\": 1, \"max\": 7.053136825561523, \"sum\": 7.053136825561523, \"min\": 7.053136825561523}}, \"EndTime\": 1600547548.587118, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600547548.516848}\n",
      "\u001b[0m\n",
      "Training seconds: 6898\n",
      "Billable seconds: 6898\n",
      "CPU times: user 488 ms, sys: 121 ms, total: 609 ms\n",
      "Wall time: 1.86 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.estimator.Estimator at 0x7f854527d9b0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# train and test channels\n",
    "data_channels = {\n",
    "    \"train\": train_path,\n",
    "    \"test\": test_path\n",
    "}\n",
    "\n",
    "# fit the estimator\n",
    "estimator.attach('forecasting-deepar-2020-09-19-18-36-00-609')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attaching saved training job to estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-16 03:43:08 Starting - Preparing the instances for training\n",
      "2020-09-16 03:43:08 Downloading - Downloading input data\n",
      "2020-09-16 03:43:08 Training - Training image download completed. Training in progress.\n",
      "2020-09-16 03:43:08 Uploading - Uploading generated training model\n",
      "2020-09-16 03:43:08 Completed - Training job completed\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'208', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'test:RMSE', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.01', u'num_cells': u'177', u'num_layers': u'2', u'prediction_length': u'166', u'epochs': u'263', u'embedding_dimension': u'10', u'time_freq': u'D', u'context_length': u'4', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t'}\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'num_eval_samples': u'100', u'epochs': u'263', u'num_layers': u'2', u'_num_kv_servers': u'auto', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'prediction_length': u'166', u'time_freq': u'D', u'context_length': u'4', u'early_stopping_patience': u'', u'_tuning_objective_metric': u'test:RMSE', u'learning_rate': u'0.01', u'embedding_dimension': u'10', u'num_cells': u'177', u'mini_batch_size': u'208', u'likelihood': u'student-t', u'_num_gpus': u'auto', u'_kvstore': u'auto'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] Training set statistics:\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] Real time series\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] number of time series: 70\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] number of observations: 23468\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] mean target length: 335\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] min/mean/max target: 0.00699300691485/0.586140650347/1.0\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] mean abs(target): 0.586140650347\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] contains missing values: no\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] Small number of time series. Doing 30 passes over dataset with prob 0.990476190476 per epoch.\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] Test set statistics:\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] Real time series\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] number of time series: 70\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] number of observations: 25568\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] mean target length: 365\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] min/mean/max target: 0.0/0.572861865405/1.0\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] mean abs(target): 0.572861865405\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] contains missing values: no\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] nvidia-smi took: 0.0251338481903 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:50 INFO 140162782930752] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 262.4349594116211, \"sum\": 262.4349594116211, \"min\": 262.4349594116211}}, \"EndTime\": 1600220931.016795, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600220930.753576}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:51 INFO 140162782930752] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 873.6200332641602, \"sum\": 873.6200332641602, \"min\": 873.6200332641602}}, \"EndTime\": 1600220931.627291, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600220931.016872}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:55 INFO 140162782930752] Epoch[0] Batch[0] avg_epoch_loss=0.870445\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:48:55 INFO 140162782930752] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=0.870444737948\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:07 INFO 140162782930752] Epoch[0] Batch[5] avg_epoch_loss=2.465848\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=2.4658477612\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:07 INFO 140162782930752] Epoch[0] Batch [5]#011Speed: 83.88 samples/sec#011loss=2.465848\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:16 INFO 140162782930752] processed a total of 1993 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 263, \"sum\": 263.0, \"min\": 263}, \"update.time\": {\"count\": 1, \"max\": 25371.806859970093, \"sum\": 25371.806859970093, \"min\": 25371.806859970093}}, \"EndTime\": 1600220956.999356, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600220931.627462}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:16 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.5512916878 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:16 INFO 140162782930752] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=0, train loss <loss>=2.23510899911\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:19 INFO 140162782930752] Epoch[1] Batch[0] avg_epoch_loss=1.718317\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:19 INFO 140162782930752] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=1.71831688514\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:31 INFO 140162782930752] Epoch[1] Batch[5] avg_epoch_loss=1.211206\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:31 INFO 140162782930752] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=1.21120587985\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:31 INFO 140162782930752] Epoch[1] Batch [5]#011Speed: 87.52 samples/sec#011loss=1.211206\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:43 INFO 140162782930752] Epoch[1] Batch[10] avg_epoch_loss=0.527665\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:43 INFO 140162782930752] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=-0.29258447427\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:43 INFO 140162782930752] Epoch[1] Batch [10]#011Speed: 87.80 samples/sec#011loss=-0.292584\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:43 INFO 140162782930752] processed a total of 2152 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26482.208013534546, \"sum\": 26482.208013534546, \"min\": 26482.208013534546}}, \"EndTime\": 1600220983.482008, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600220956.999472}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:43 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.2618362401 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:43 INFO 140162782930752] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:43 INFO 140162782930752] #quality_metric: host=algo-1, epoch=1, train loss <loss>=0.527664809794\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:46 INFO 140162782930752] Epoch[2] Batch[0] avg_epoch_loss=1.114795\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:46 INFO 140162782930752] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=1.11479524466\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:58 INFO 140162782930752] Epoch[2] Batch[5] avg_epoch_loss=0.120373\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:58 INFO 140162782930752] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=0.120372903653\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:49:58 INFO 140162782930752] Epoch[2] Batch [5]#011Speed: 87.51 samples/sec#011loss=0.120373\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:07 INFO 140162782930752] processed a total of 2074 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24121.450901031494, \"sum\": 24121.450901031494, \"min\": 24121.450901031494}}, \"EndTime\": 1600221007.603742, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600220983.482067}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:07 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.9812362735 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:07 INFO 140162782930752] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=2, train loss <loss>=0.0846263332436\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:10 INFO 140162782930752] Epoch[3] Batch[0] avg_epoch_loss=-0.034089\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:10 INFO 140162782930752] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=-0.0340891801394\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:22 INFO 140162782930752] Epoch[3] Batch[5] avg_epoch_loss=-0.193119\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:22 INFO 140162782930752] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=-0.193119455607\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:22 INFO 140162782930752] Epoch[3] Batch [5]#011Speed: 88.11 samples/sec#011loss=-0.193119\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:34 INFO 140162782930752] Epoch[3] Batch[10] avg_epoch_loss=-0.347283\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=-0.532278765165\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:34 INFO 140162782930752] Epoch[3] Batch [10]#011Speed: 87.87 samples/sec#011loss=-0.532279\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:34 INFO 140162782930752] processed a total of 2097 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26407.697916030884, \"sum\": 26407.697916030884, \"min\": 26407.697916030884}}, \"EndTime\": 1600221034.011767, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221007.603806}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:34 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.4083804032 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:34 INFO 140162782930752] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=3, train loss <loss>=-0.347282778133\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:36 INFO 140162782930752] Epoch[4] Batch[0] avg_epoch_loss=0.246429\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=0.246428636404\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:48 INFO 140162782930752] Epoch[4] Batch[5] avg_epoch_loss=-0.053627\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:48 INFO 140162782930752] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=-0.0536273351082\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:48 INFO 140162782930752] Epoch[4] Batch [5]#011Speed: 88.20 samples/sec#011loss=-0.053627\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:58 INFO 140162782930752] processed a total of 2027 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24064.464807510376, \"sum\": 24064.464807510376, \"min\": 24064.464807510376}}, \"EndTime\": 1600221058.076594, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221034.011831}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:58 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.2315673882 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:58 INFO 140162782930752] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:50:58 INFO 140162782930752] #quality_metric: host=algo-1, epoch=4, train loss <loss>=-0.225477466216\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:00 INFO 140162782930752] Epoch[5] Batch[0] avg_epoch_loss=-0.231969\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=-0.231968989739\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:12 INFO 140162782930752] Epoch[5] Batch[5] avg_epoch_loss=-0.442168\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:12 INFO 140162782930752] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=-0.442167599996\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:12 INFO 140162782930752] Epoch[5] Batch [5]#011Speed: 87.82 samples/sec#011loss=-0.442168\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:22 INFO 140162782930752] processed a total of 2041 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24027.84013748169, \"sum\": 24027.84013748169, \"min\": 24027.84013748169}}, \"EndTime\": 1600221082.104835, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221058.076709}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:22 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.9427621344 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:22 INFO 140162782930752] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:22 INFO 140162782930752] #quality_metric: host=algo-1, epoch=5, train loss <loss>=-0.556179259374\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:24 INFO 140162782930752] Epoch[6] Batch[0] avg_epoch_loss=-0.958537\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:24 INFO 140162782930752] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=-0.958537321824\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:36 INFO 140162782930752] Epoch[6] Batch[5] avg_epoch_loss=-0.931874\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=-0.931873712784\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:36 INFO 140162782930752] Epoch[6] Batch [5]#011Speed: 87.52 samples/sec#011loss=-0.931874\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:48 INFO 140162782930752] Epoch[6] Batch[10] avg_epoch_loss=-0.923457\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:48 INFO 140162782930752] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=-0.913356516911\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:48 INFO 140162782930752] Epoch[6] Batch [10]#011Speed: 87.60 samples/sec#011loss=-0.913357\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:48 INFO 140162782930752] processed a total of 2092 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26511.751174926758, \"sum\": 26511.751174926758, \"min\": 26511.751174926758}}, \"EndTime\": 1600221108.617039, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221082.104906}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:48 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.9081289982 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:48 INFO 140162782930752] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:48 INFO 140162782930752] #quality_metric: host=algo-1, epoch=6, train loss <loss>=-0.923456805569\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:51 INFO 140162782930752] Epoch[7] Batch[0] avg_epoch_loss=-0.686842\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:51:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=-0.6868421848\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:03 INFO 140162782930752] Epoch[7] Batch[5] avg_epoch_loss=-0.911875\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:03 INFO 140162782930752] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=-0.911874832251\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:03 INFO 140162782930752] Epoch[7] Batch [5]#011Speed: 87.42 samples/sec#011loss=-0.911875\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:12 INFO 140162782930752] processed a total of 2051 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24095.499992370605, \"sum\": 24095.499992370605, \"min\": 24095.499992370605}}, \"EndTime\": 1600221132.712861, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221108.617106}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:12 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.1193241271 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:12 INFO 140162782930752] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:12 INFO 140162782930752] #quality_metric: host=algo-1, epoch=7, train loss <loss>=-0.984557093107\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:15 INFO 140162782930752] Epoch[8] Batch[0] avg_epoch_loss=-1.311280\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:15 INFO 140162782930752] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=-1.31128032391\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:27 INFO 140162782930752] Epoch[8] Batch[5] avg_epoch_loss=-1.273443\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=-1.27344261072\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:27 INFO 140162782930752] Epoch[8] Batch [5]#011Speed: 87.66 samples/sec#011loss=-1.273443\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:36 INFO 140162782930752] processed a total of 2044 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24104.427814483643, \"sum\": 24104.427814483643, \"min\": 24104.427814483643}}, \"EndTime\": 1600221156.81765, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221132.71292}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:36 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.7973813609 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:36 INFO 140162782930752] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=8, train loss <loss>=-1.28291664857\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:39 INFO 140162782930752] Epoch[9] Batch[0] avg_epoch_loss=-1.438523\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:39 INFO 140162782930752] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=-1.43852263231\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:51 INFO 140162782930752] Epoch[9] Batch[5] avg_epoch_loss=-1.386856\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=-1.38685590793\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:52:51 INFO 140162782930752] Epoch[9] Batch [5]#011Speed: 87.99 samples/sec#011loss=-1.386856\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:00 INFO 140162782930752] processed a total of 2041 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24025.23684501648, \"sum\": 24025.23684501648, \"min\": 24025.23684501648}}, \"EndTime\": 1600221180.843338, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221156.817708}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:00 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.9520285858 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:00 INFO 140162782930752] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=9, train loss <loss>=-1.39895832355\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:03 INFO 140162782930752] Epoch[10] Batch[0] avg_epoch_loss=-1.493316\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:03 INFO 140162782930752] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=-1.49331562336\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:15 INFO 140162782930752] Epoch[10] Batch[5] avg_epoch_loss=-1.462008\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:15 INFO 140162782930752] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=-1.46200842735\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:15 INFO 140162782930752] Epoch[10] Batch [5]#011Speed: 88.34 samples/sec#011loss=-1.462008\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:27 INFO 140162782930752] Epoch[10] Batch[10] avg_epoch_loss=-1.472412\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=-1.4848972614\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:27 INFO 140162782930752] Epoch[10] Batch [10]#011Speed: 88.01 samples/sec#011loss=-1.484897\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:27 INFO 140162782930752] processed a total of 2098 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26350.01301765442, \"sum\": 26350.01301765442, \"min\": 26350.01301765442}}, \"EndTime\": 1600221207.193721, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221180.843397}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:27 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.6201910725 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:27 INFO 140162782930752] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=10, train loss <loss>=-1.47241244283\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:29 INFO 140162782930752] Epoch[11] Batch[0] avg_epoch_loss=-1.564279\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:29 INFO 140162782930752] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=-1.5642789694\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:41 INFO 140162782930752] Epoch[11] Batch[5] avg_epoch_loss=-1.502442\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:41 INFO 140162782930752] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=-1.50244228656\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:41 INFO 140162782930752] Epoch[11] Batch [5]#011Speed: 88.11 samples/sec#011loss=-1.502442\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:53 INFO 140162782930752] Epoch[11] Batch[10] avg_epoch_loss=-1.532264\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=-1.56805091271\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:53 INFO 140162782930752] Epoch[11] Batch [10]#011Speed: 88.02 samples/sec#011loss=-1.568051\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:53 INFO 140162782930752] processed a total of 2091 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26352.207899093628, \"sum\": 26352.207899093628, \"min\": 26352.207899093628}}, \"EndTime\": 1600221233.546255, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221207.193779}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:53 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.3479394826 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:53 INFO 140162782930752] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=11, train loss <loss>=-1.53226438936\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:56 INFO 140162782930752] Epoch[12] Batch[0] avg_epoch_loss=-1.588914\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:53:56 INFO 140162782930752] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=-1.58891369746\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:08 INFO 140162782930752] Epoch[12] Batch[5] avg_epoch_loss=-1.289618\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:08 INFO 140162782930752] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=-1.28961845545\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:08 INFO 140162782930752] Epoch[12] Batch [5]#011Speed: 87.50 samples/sec#011loss=-1.289618\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:20 INFO 140162782930752] Epoch[12] Batch[10] avg_epoch_loss=-1.313397\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:20 INFO 140162782930752] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=-1.34193204733\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:20 INFO 140162782930752] Epoch[12] Batch [10]#011Speed: 87.95 samples/sec#011loss=-1.341932\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:20 INFO 140162782930752] processed a total of 2095 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26473.32715988159, \"sum\": 26473.32715988159, \"min\": 26473.32715988159}}, \"EndTime\": 1600221260.019936, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221233.546307}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:20 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.1359611208 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:20 INFO 140162782930752] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:20 INFO 140162782930752] #quality_metric: host=algo-1, epoch=12, train loss <loss>=-1.31339736085\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:22 INFO 140162782930752] Epoch[13] Batch[0] avg_epoch_loss=-1.378635\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:22 INFO 140162782930752] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=-1.37863452618\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:34 INFO 140162782930752] Epoch[13] Batch[5] avg_epoch_loss=-1.430686\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=-1.43068636381\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:34 INFO 140162782930752] Epoch[13] Batch [5]#011Speed: 87.81 samples/sec#011loss=-1.430686\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:46 INFO 140162782930752] Epoch[13] Batch[10] avg_epoch_loss=-1.452019\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:46 INFO 140162782930752] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=-1.47761837886\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:46 INFO 140162782930752] Epoch[13] Batch [10]#011Speed: 86.99 samples/sec#011loss=-1.477618\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:46 INFO 140162782930752] processed a total of 2100 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26539.07799720764, \"sum\": 26539.07799720764, \"min\": 26539.07799720764}}, \"EndTime\": 1600221286.559437, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221260.020003}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:46 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.1283137903 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:46 INFO 140162782930752] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:46 INFO 140162782930752] #quality_metric: host=algo-1, epoch=13, train loss <loss>=-1.45201909792\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:49 INFO 140162782930752] Epoch[14] Batch[0] avg_epoch_loss=-1.598443\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:54:49 INFO 140162782930752] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=-1.59844251779\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:01 INFO 140162782930752] Epoch[14] Batch[5] avg_epoch_loss=-1.524216\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:01 INFO 140162782930752] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=-1.52421586941\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:01 INFO 140162782930752] Epoch[14] Batch [5]#011Speed: 87.71 samples/sec#011loss=-1.524216\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:13 INFO 140162782930752] Epoch[14] Batch[10] avg_epoch_loss=-1.563629\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=-1.61092517559\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:13 INFO 140162782930752] Epoch[14] Batch [10]#011Speed: 87.90 samples/sec#011loss=-1.610925\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:13 INFO 140162782930752] processed a total of 2141 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26461.795806884766, \"sum\": 26461.795806884766, \"min\": 26461.795806884766}}, \"EndTime\": 1600221313.021606, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221286.559501}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:13 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.9088307805 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:13 INFO 140162782930752] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=14, train loss <loss>=-1.5636291904\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:15 INFO 140162782930752] Epoch[15] Batch[0] avg_epoch_loss=-1.469526\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:15 INFO 140162782930752] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=-1.4695255573\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:27 INFO 140162782930752] Epoch[15] Batch[5] avg_epoch_loss=-1.552960\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=-1.55296042027\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:27 INFO 140162782930752] Epoch[15] Batch [5]#011Speed: 87.68 samples/sec#011loss=-1.552960\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:37 INFO 140162782930752] processed a total of 2011 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24085.394144058228, \"sum\": 24085.394144058228, \"min\": 24085.394144058228}}, \"EndTime\": 1600221337.107318, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221313.021664}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:37 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.4942738819 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:37 INFO 140162782930752] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:37 INFO 140162782930752] #quality_metric: host=algo-1, epoch=15, train loss <loss>=-1.58977373563\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:39 INFO 140162782930752] Epoch[16] Batch[0] avg_epoch_loss=-1.605295\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:39 INFO 140162782930752] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=-1.60529532799\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:51 INFO 140162782930752] Epoch[16] Batch[5] avg_epoch_loss=-1.630332\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=-1.63033155295\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:55:51 INFO 140162782930752] Epoch[16] Batch [5]#011Speed: 87.86 samples/sec#011loss=-1.630332\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:03 INFO 140162782930752] Epoch[16] Batch[10] avg_epoch_loss=-1.660017\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:03 INFO 140162782930752] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=-1.69563927284\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:03 INFO 140162782930752] Epoch[16] Batch [10]#011Speed: 87.40 samples/sec#011loss=-1.695639\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:03 INFO 140162782930752] processed a total of 2147 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26496.91605567932, \"sum\": 26496.91605567932, \"min\": 26496.91605567932}}, \"EndTime\": 1600221363.604657, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221337.107376}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:03 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.0280344127 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:03 INFO 140162782930752] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:03 INFO 140162782930752] #quality_metric: host=algo-1, epoch=16, train loss <loss>=-1.66001688017\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:06 INFO 140162782930752] Epoch[17] Batch[0] avg_epoch_loss=-1.504477\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:06 INFO 140162782930752] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=-1.50447742756\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:18 INFO 140162782930752] Epoch[17] Batch[5] avg_epoch_loss=-1.379190\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=-1.37918977248\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:18 INFO 140162782930752] Epoch[17] Batch [5]#011Speed: 87.84 samples/sec#011loss=-1.379190\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:27 INFO 140162782930752] processed a total of 2027 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24115.35882949829, \"sum\": 24115.35882949829, \"min\": 24115.35882949829}}, \"EndTime\": 1600221387.720369, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221363.604718}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:27 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.0540230065 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:27 INFO 140162782930752] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=17, train loss <loss>=-1.42579211455\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:30 INFO 140162782930752] Epoch[18] Batch[0] avg_epoch_loss=-1.526632\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:30 INFO 140162782930752] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=-1.52663172208\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:42 INFO 140162782930752] Epoch[18] Batch[5] avg_epoch_loss=-1.483396\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:42 INFO 140162782930752] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=-1.48339552757\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:42 INFO 140162782930752] Epoch[18] Batch [5]#011Speed: 87.96 samples/sec#011loss=-1.483396\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:51 INFO 140162782930752] processed a total of 2004 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24074.395179748535, \"sum\": 24074.395179748535, \"min\": 24074.395179748535}}, \"EndTime\": 1600221411.795133, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221387.720427}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:51 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.2414728219 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:51 INFO 140162782930752] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=18, train loss <loss>=-1.51778865227\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:54 INFO 140162782930752] Epoch[19] Batch[0] avg_epoch_loss=-1.473184\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:56:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=-1.47318355854\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:06 INFO 140162782930752] Epoch[19] Batch[5] avg_epoch_loss=-1.585581\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:06 INFO 140162782930752] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=-1.58558133932\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:06 INFO 140162782930752] Epoch[19] Batch [5]#011Speed: 86.99 samples/sec#011loss=-1.585581\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:15 INFO 140162782930752] processed a total of 2068 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24195.508003234863, \"sum\": 24195.508003234863, \"min\": 24195.508003234863}}, \"EndTime\": 1600221435.991071, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221411.795196}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:15 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.4700188201 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:15 INFO 140162782930752] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:15 INFO 140162782930752] #quality_metric: host=algo-1, epoch=19, train loss <loss>=-1.58533153534\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:18 INFO 140162782930752] Epoch[20] Batch[0] avg_epoch_loss=-1.638666\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=-1.63866644639\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:30 INFO 140162782930752] Epoch[20] Batch[5] avg_epoch_loss=-1.653889\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:30 INFO 140162782930752] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=-1.65388914255\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:30 INFO 140162782930752] Epoch[20] Batch [5]#011Speed: 87.71 samples/sec#011loss=-1.653889\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:42 INFO 140162782930752] Epoch[20] Batch[10] avg_epoch_loss=-1.672490\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:42 INFO 140162782930752] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=-1.69481171828\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:42 INFO 140162782930752] Epoch[20] Batch [10]#011Speed: 85.98 samples/sec#011loss=-1.694812\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:42 INFO 140162782930752] processed a total of 2178 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26720.80397605896, \"sum\": 26720.80397605896, \"min\": 26720.80397605896}}, \"EndTime\": 1600221462.712426, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221435.991136}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:42 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.5092522412 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:42 INFO 140162782930752] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:42 INFO 140162782930752] #quality_metric: host=algo-1, epoch=20, train loss <loss>=-1.67249031334\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:45 INFO 140162782930752] Epoch[21] Batch[0] avg_epoch_loss=-1.686291\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:45 INFO 140162782930752] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=-1.68629118112\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:57 INFO 140162782930752] Epoch[21] Batch[5] avg_epoch_loss=-1.629487\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:57 INFO 140162782930752] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=-1.62948693985\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:57:57 INFO 140162782930752] Epoch[21] Batch [5]#011Speed: 87.77 samples/sec#011loss=-1.629487\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:09 INFO 140162782930752] Epoch[21] Batch[10] avg_epoch_loss=-1.560305\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=-1.47728749789\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:09 INFO 140162782930752] Epoch[21] Batch [10]#011Speed: 87.94 samples/sec#011loss=-1.477287\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:09 INFO 140162782930752] processed a total of 2177 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26432.751178741455, \"sum\": 26432.751178741455, \"min\": 26432.751178741455}}, \"EndTime\": 1600221489.145515, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221462.712486}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:09 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=82.3596838056 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:09 INFO 140162782930752] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=21, train loss <loss>=-1.56030537532\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:11 INFO 140162782930752] Epoch[22] Batch[0] avg_epoch_loss=-1.471334\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=-1.47133387052\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:23 INFO 140162782930752] Epoch[22] Batch[5] avg_epoch_loss=-1.580048\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:23 INFO 140162782930752] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=-1.58004802313\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:23 INFO 140162782930752] Epoch[22] Batch [5]#011Speed: 88.31 samples/sec#011loss=-1.580048\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:35 INFO 140162782930752] Epoch[22] Batch[10] avg_epoch_loss=-1.541057\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:35 INFO 140162782930752] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=-1.49426868145\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:35 INFO 140162782930752] Epoch[22] Batch [10]#011Speed: 87.95 samples/sec#011loss=-1.494269\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:35 INFO 140162782930752] processed a total of 2081 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26333.01305770874, \"sum\": 26333.01305770874, \"min\": 26333.01305770874}}, \"EndTime\": 1600221515.478907, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221489.145569}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:35 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.0260228842 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:35 INFO 140162782930752] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:35 INFO 140162782930752] #quality_metric: host=algo-1, epoch=22, train loss <loss>=-1.54105741327\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:38 INFO 140162782930752] Epoch[23] Batch[0] avg_epoch_loss=-1.652016\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:38 INFO 140162782930752] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=-1.65201583275\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:50 INFO 140162782930752] Epoch[23] Batch[5] avg_epoch_loss=-1.644191\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:50 INFO 140162782930752] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=-1.64419098389\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:58:50 INFO 140162782930752] Epoch[23] Batch [5]#011Speed: 88.32 samples/sec#011loss=-1.644191\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:01 INFO 140162782930752] Epoch[23] Batch[10] avg_epoch_loss=-1.658408\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:01 INFO 140162782930752] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=-1.67546947186\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:01 INFO 140162782930752] Epoch[23] Batch [10]#011Speed: 87.20 samples/sec#011loss=-1.675469\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:01 INFO 140162782930752] processed a total of 2082 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26454.37002182007, \"sum\": 26454.37002182007, \"min\": 26454.37002182007}}, \"EndTime\": 1600221541.933569, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221515.478965}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:01 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.7012946534 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:01 INFO 140162782930752] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:01 INFO 140162782930752] #quality_metric: host=algo-1, epoch=23, train loss <loss>=-1.65840847842\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:04 INFO 140162782930752] Epoch[24] Batch[0] avg_epoch_loss=-1.722330\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:04 INFO 140162782930752] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=-1.72233038682\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:16 INFO 140162782930752] Epoch[24] Batch[5] avg_epoch_loss=-1.689562\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=-1.68956223512\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:16 INFO 140162782930752] Epoch[24] Batch [5]#011Speed: 87.82 samples/sec#011loss=-1.689562\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:26 INFO 140162782930752] processed a total of 1998 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24108.362913131714, \"sum\": 24108.362913131714, \"min\": 24108.362913131714}}, \"EndTime\": 1600221566.042235, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221541.933627}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:26 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=82.8754925931 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:26 INFO 140162782930752] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=24, train loss <loss>=-1.69266190162\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:28 INFO 140162782930752] Epoch[25] Batch[0] avg_epoch_loss=-1.740449\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:28 INFO 140162782930752] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=-1.74044887836\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:40 INFO 140162782930752] Epoch[25] Batch[5] avg_epoch_loss=-1.682127\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:40 INFO 140162782930752] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=-1.68212729234\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:40 INFO 140162782930752] Epoch[25] Batch [5]#011Speed: 87.89 samples/sec#011loss=-1.682127\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:52 INFO 140162782930752] Epoch[25] Batch[10] avg_epoch_loss=-1.536655\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:52 INFO 140162782930752] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=-1.3620884822\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:52 INFO 140162782930752] Epoch[25] Batch [10]#011Speed: 87.86 samples/sec#011loss=-1.362088\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:52 INFO 140162782930752] processed a total of 2090 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26447.394132614136, \"sum\": 26447.394132614136, \"min\": 26447.394132614136}}, \"EndTime\": 1600221592.490011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221566.042296}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:52 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.0245537327 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:52 INFO 140162782930752] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:52 INFO 140162782930752] #quality_metric: host=algo-1, epoch=25, train loss <loss>=-1.53665510591\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:55 INFO 140162782930752] Epoch[26] Batch[0] avg_epoch_loss=-1.428932\u001b[0m\n",
      "\u001b[34m[09/16/2020 01:59:55 INFO 140162782930752] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=-1.42893204322\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:07 INFO 140162782930752] Epoch[26] Batch[5] avg_epoch_loss=-1.489875\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=-1.48987520658\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:07 INFO 140162782930752] Epoch[26] Batch [5]#011Speed: 87.03 samples/sec#011loss=-1.489875\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:16 INFO 140162782930752] processed a total of 2064 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24176.70512199402, \"sum\": 24176.70512199402, \"min\": 24176.70512199402}}, \"EndTime\": 1600221616.667074, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221592.490066}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:16 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.371078475 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:16 INFO 140162782930752] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=26, train loss <loss>=-1.53160869892\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:19 INFO 140162782930752] Epoch[27] Batch[0] avg_epoch_loss=-1.629937\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:19 INFO 140162782930752] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=-1.62993680514\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:31 INFO 140162782930752] Epoch[27] Batch[5] avg_epoch_loss=-1.640062\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:31 INFO 140162782930752] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=-1.64006220989\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:31 INFO 140162782930752] Epoch[27] Batch [5]#011Speed: 87.71 samples/sec#011loss=-1.640062\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:43 INFO 140162782930752] Epoch[27] Batch[10] avg_epoch_loss=-1.648066\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:43 INFO 140162782930752] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=-1.65767012376\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:43 INFO 140162782930752] Epoch[27] Batch [10]#011Speed: 87.76 samples/sec#011loss=-1.657670\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:43 INFO 140162782930752] processed a total of 2131 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26451.797008514404, \"sum\": 26451.797008514404, \"min\": 26451.797008514404}}, \"EndTime\": 1600221643.119304, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221616.66714}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:43 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.5613693708 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:43 INFO 140162782930752] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:43 INFO 140162782930752] #quality_metric: host=algo-1, epoch=27, train loss <loss>=-1.6480658071\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:45 INFO 140162782930752] Epoch[28] Batch[0] avg_epoch_loss=-1.545907\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:45 INFO 140162782930752] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=-1.54590680049\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:57 INFO 140162782930752] Epoch[28] Batch[5] avg_epoch_loss=-1.676058\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:57 INFO 140162782930752] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=-1.67605830462\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:00:57 INFO 140162782930752] Epoch[28] Batch [5]#011Speed: 87.24 samples/sec#011loss=-1.676058\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:09 INFO 140162782930752] Epoch[28] Batch[10] avg_epoch_loss=-1.694092\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=-1.71573143005\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:09 INFO 140162782930752] Epoch[28] Batch [10]#011Speed: 86.83 samples/sec#011loss=-1.715731\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:09 INFO 140162782930752] processed a total of 2101 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26642.165899276733, \"sum\": 26642.165899276733, \"min\": 26642.165899276733}}, \"EndTime\": 1600221669.761774, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221643.119361}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:09 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.8595963532 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:09 INFO 140162782930752] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=28, train loss <loss>=-1.69409154345\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:12 INFO 140162782930752] Epoch[29] Batch[0] avg_epoch_loss=-1.614000\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:12 INFO 140162782930752] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=-1.61400046715\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:24 INFO 140162782930752] Epoch[29] Batch[5] avg_epoch_loss=-1.673336\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:24 INFO 140162782930752] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=-1.67333612687\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:24 INFO 140162782930752] Epoch[29] Batch [5]#011Speed: 87.84 samples/sec#011loss=-1.673336\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:33 INFO 140162782930752] processed a total of 2048 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24164.139986038208, \"sum\": 24164.139986038208, \"min\": 24164.139986038208}}, \"EndTime\": 1600221693.926263, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221669.761866}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:33 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.7532121293 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:33 INFO 140162782930752] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=29, train loss <loss>=-1.67901263604\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:36 INFO 140162782930752] Epoch[30] Batch[0] avg_epoch_loss=-1.730783\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=-1.73078258221\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:48 INFO 140162782930752] Epoch[30] Batch[5] avg_epoch_loss=-1.728283\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:48 INFO 140162782930752] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=-1.72828314855\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:48 INFO 140162782930752] Epoch[30] Batch [5]#011Speed: 87.99 samples/sec#011loss=-1.728283\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:58 INFO 140162782930752] processed a total of 2059 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24095.50404548645, \"sum\": 24095.50404548645, \"min\": 24095.50404548645}}, \"EndTime\": 1600221718.022184, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221693.92637}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:58 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.4511153093 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:58 INFO 140162782930752] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:01:58 INFO 140162782930752] #quality_metric: host=algo-1, epoch=30, train loss <loss>=-1.73551876362\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:00 INFO 140162782930752] Epoch[31] Batch[0] avg_epoch_loss=-1.681924\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=-1.68192364619\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:12 INFO 140162782930752] Epoch[31] Batch[5] avg_epoch_loss=-1.719467\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:12 INFO 140162782930752] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=-1.71946718754\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:12 INFO 140162782930752] Epoch[31] Batch [5]#011Speed: 87.45 samples/sec#011loss=-1.719467\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:24 INFO 140162782930752] Epoch[31] Batch[10] avg_epoch_loss=-1.684566\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:24 INFO 140162782930752] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=-1.64268473112\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:24 INFO 140162782930752] Epoch[31] Batch [10]#011Speed: 87.75 samples/sec#011loss=-1.642685\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:24 INFO 140162782930752] processed a total of 2158 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26495.645999908447, \"sum\": 26495.645999908447, \"min\": 26495.645999908447}}, \"EndTime\": 1600221744.518231, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221718.022295}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:24 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.4470921012 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:24 INFO 140162782930752] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:24 INFO 140162782930752] #quality_metric: host=algo-1, epoch=31, train loss <loss>=-1.68456607098\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:27 INFO 140162782930752] Epoch[32] Batch[0] avg_epoch_loss=-1.505014\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=-1.50501353924\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:39 INFO 140162782930752] Epoch[32] Batch[5] avg_epoch_loss=-1.678492\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:39 INFO 140162782930752] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=-1.67849181249\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:39 INFO 140162782930752] Epoch[32] Batch [5]#011Speed: 87.73 samples/sec#011loss=-1.678492\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:51 INFO 140162782930752] Epoch[32] Batch[10] avg_epoch_loss=-1.684949\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=-1.69269778912\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:51 INFO 140162782930752] Epoch[32] Batch [10]#011Speed: 87.81 samples/sec#011loss=-1.692698\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:51 INFO 140162782930752] processed a total of 2106 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26482.582092285156, \"sum\": 26482.582092285156, \"min\": 26482.582092285156}}, \"EndTime\": 1600221771.001149, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221744.518286}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:51 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.5237127152 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:51 INFO 140162782930752] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=32, train loss <loss>=-1.68494907459\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:53 INFO 140162782930752] Epoch[33] Batch[0] avg_epoch_loss=-1.673736\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:02:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=-1.67373554523\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:05 INFO 140162782930752] Epoch[33] Batch[5] avg_epoch_loss=-1.741750\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:05 INFO 140162782930752] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=-1.74174964122\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:05 INFO 140162782930752] Epoch[33] Batch [5]#011Speed: 87.61 samples/sec#011loss=-1.741750\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:17 INFO 140162782930752] Epoch[33] Batch[10] avg_epoch_loss=-1.737719\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:17 INFO 140162782930752] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=-1.73288269043\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:17 INFO 140162782930752] Epoch[33] Batch [10]#011Speed: 88.08 samples/sec#011loss=-1.732883\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:17 INFO 140162782930752] processed a total of 2123 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26480.763912200928, \"sum\": 26480.763912200928, \"min\": 26480.763912200928}}, \"EndTime\": 1600221797.48223, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221771.001208}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:17 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.171151261 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:17 INFO 140162782930752] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:17 INFO 140162782930752] #quality_metric: host=algo-1, epoch=33, train loss <loss>=-1.73771920904\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:20 INFO 140162782930752] Epoch[34] Batch[0] avg_epoch_loss=-1.706141\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:20 INFO 140162782930752] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=-1.70614066491\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:32 INFO 140162782930752] Epoch[34] Batch[5] avg_epoch_loss=-1.773639\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:32 INFO 140162782930752] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=-1.77363943442\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:32 INFO 140162782930752] Epoch[34] Batch [5]#011Speed: 87.99 samples/sec#011loss=-1.773639\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:41 INFO 140162782930752] processed a total of 2039 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24012.14098930359, \"sum\": 24012.14098930359, \"min\": 24012.14098930359}}, \"EndTime\": 1600221821.494688, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221797.482286}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:41 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.9150800235 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:41 INFO 140162782930752] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:41 INFO 140162782930752] #quality_metric: host=algo-1, epoch=34, train loss <loss>=-1.77853034093\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:44 INFO 140162782930752] Epoch[35] Batch[0] avg_epoch_loss=-1.765223\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:44 INFO 140162782930752] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=-1.76522342975\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:56 INFO 140162782930752] Epoch[35] Batch[5] avg_epoch_loss=-1.789844\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:56 INFO 140162782930752] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=-1.78984370598\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:03:56 INFO 140162782930752] Epoch[35] Batch [5]#011Speed: 88.15 samples/sec#011loss=-1.789844\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:07 INFO 140162782930752] Epoch[35] Batch[10] avg_epoch_loss=-1.805941\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=-1.82525837238\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:07 INFO 140162782930752] Epoch[35] Batch [10]#011Speed: 87.50 samples/sec#011loss=-1.825258\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:07 INFO 140162782930752] processed a total of 2125 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26434.44299697876, \"sum\": 26434.44299697876, \"min\": 26434.44299697876}}, \"EndTime\": 1600221847.929507, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221821.494747}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:07 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.3872537212 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:07 INFO 140162782930752] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=35, train loss <loss>=-1.80594128162\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:10 INFO 140162782930752] Epoch[36] Batch[0] avg_epoch_loss=-1.841596\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:10 INFO 140162782930752] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=-1.8415958698\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:22 INFO 140162782930752] Epoch[36] Batch[5] avg_epoch_loss=-1.612077\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:22 INFO 140162782930752] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=-1.61207749293\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:22 INFO 140162782930752] Epoch[36] Batch [5]#011Speed: 87.82 samples/sec#011loss=-1.612077\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:34 INFO 140162782930752] Epoch[36] Batch[10] avg_epoch_loss=-1.627874\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=-1.64682895954\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:34 INFO 140162782930752] Epoch[36] Batch [10]#011Speed: 86.51 samples/sec#011loss=-1.646829\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:34 INFO 140162782930752] processed a total of 2123 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26640.61212539673, \"sum\": 26640.61212539673, \"min\": 26640.61212539673}}, \"EndTime\": 1600221874.570419, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221847.929575}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:34 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.6901257425 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:34 INFO 140162782930752] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=36, train loss <loss>=-1.62787361412\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:37 INFO 140162782930752] Epoch[37] Batch[0] avg_epoch_loss=-1.724376\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:37 INFO 140162782930752] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=-1.72437565143\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:49 INFO 140162782930752] Epoch[37] Batch[5] avg_epoch_loss=-1.650226\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:49 INFO 140162782930752] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=-1.65022615286\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:49 INFO 140162782930752] Epoch[37] Batch [5]#011Speed: 87.69 samples/sec#011loss=-1.650226\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:58 INFO 140162782930752] processed a total of 2018 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24118.309020996094, \"sum\": 24118.309020996094, \"min\": 24118.309020996094}}, \"EndTime\": 1600221898.689042, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221874.57047}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:58 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.6705201944 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:58 INFO 140162782930752] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:04:58 INFO 140162782930752] #quality_metric: host=algo-1, epoch=37, train loss <loss>=-1.69677740244\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:01 INFO 140162782930752] Epoch[38] Batch[0] avg_epoch_loss=-1.744426\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:01 INFO 140162782930752] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=-1.74442570026\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:13 INFO 140162782930752] Epoch[38] Batch[5] avg_epoch_loss=-1.767669\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=-1.76766872406\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:13 INFO 140162782930752] Epoch[38] Batch [5]#011Speed: 87.79 samples/sec#011loss=-1.767669\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:25 INFO 140162782930752] Epoch[38] Batch[10] avg_epoch_loss=-1.783160\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:25 INFO 140162782930752] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=-1.80174959623\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:25 INFO 140162782930752] Epoch[38] Batch [10]#011Speed: 87.61 samples/sec#011loss=-1.801750\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:25 INFO 140162782930752] processed a total of 2090 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26479.77304458618, \"sum\": 26479.77304458618, \"min\": 26479.77304458618}}, \"EndTime\": 1600221925.169268, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221898.68911}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:25 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.9279187773 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:25 INFO 140162782930752] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:25 INFO 140162782930752] #quality_metric: host=algo-1, epoch=38, train loss <loss>=-1.78316002959\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:27 INFO 140162782930752] Epoch[39] Batch[0] avg_epoch_loss=-1.802974\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=-1.80297352717\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:39 INFO 140162782930752] Epoch[39] Batch[5] avg_epoch_loss=-1.788366\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:39 INFO 140162782930752] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=-1.7883659265\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:39 INFO 140162782930752] Epoch[39] Batch [5]#011Speed: 87.15 samples/sec#011loss=-1.788366\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:51 INFO 140162782930752] Epoch[39] Batch[10] avg_epoch_loss=-1.801005\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=-1.81617167546\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:51 INFO 140162782930752] Epoch[39] Batch [10]#011Speed: 87.83 samples/sec#011loss=-1.816172\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:51 INFO 140162782930752] processed a total of 2093 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26529.968976974487, \"sum\": 26529.968976974487, \"min\": 26529.968976974487}}, \"EndTime\": 1600221951.699517, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221925.169324}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:51 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.8916363308 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:51 INFO 140162782930752] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=39, train loss <loss>=-1.8010049033\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:54 INFO 140162782930752] Epoch[40] Batch[0] avg_epoch_loss=-1.633088\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:05:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=-1.63308833196\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:06 INFO 140162782930752] Epoch[40] Batch[5] avg_epoch_loss=-1.731387\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:06 INFO 140162782930752] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=-1.73138706501\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:06 INFO 140162782930752] Epoch[40] Batch [5]#011Speed: 87.12 samples/sec#011loss=-1.731387\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:18 INFO 140162782930752] Epoch[40] Batch[10] avg_epoch_loss=-1.763055\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=-1.80105749277\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:18 INFO 140162782930752] Epoch[40] Batch [10]#011Speed: 87.78 samples/sec#011loss=-1.801057\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:18 INFO 140162782930752] processed a total of 2163 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26552.079916000366, \"sum\": 26552.079916000366, \"min\": 26552.079916000366}}, \"EndTime\": 1600221978.251967, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221951.699579}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:18 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.4622529542 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:18 INFO 140162782930752] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=40, train loss <loss>=-1.76305544126\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:21 INFO 140162782930752] Epoch[41] Batch[0] avg_epoch_loss=-1.852345\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:21 INFO 140162782930752] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=-1.85234451294\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:32 INFO 140162782930752] Epoch[41] Batch[5] avg_epoch_loss=-1.848136\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:32 INFO 140162782930752] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=-1.84813553248\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:32 INFO 140162782930752] Epoch[41] Batch [5]#011Speed: 87.57 samples/sec#011loss=-1.848136\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:44 INFO 140162782930752] Epoch[41] Batch[10] avg_epoch_loss=-1.841181\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:44 INFO 140162782930752] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=-1.83283638587\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:44 INFO 140162782930752] Epoch[41] Batch [10]#011Speed: 87.78 samples/sec#011loss=-1.832836\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:44 INFO 140162782930752] processed a total of 2081 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26476.714849472046, \"sum\": 26476.714849472046, \"min\": 26476.714849472046}}, \"EndTime\": 1600222004.729097, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600221978.252031}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:44 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.5970881818 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:44 INFO 140162782930752] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:44 INFO 140162782930752] #quality_metric: host=algo-1, epoch=41, train loss <loss>=-1.84118137493\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:47 INFO 140162782930752] Epoch[42] Batch[0] avg_epoch_loss=-1.871244\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=-1.87124355023\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:59 INFO 140162782930752] Epoch[42] Batch[5] avg_epoch_loss=-1.763591\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:59 INFO 140162782930752] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=-1.76359093495\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:06:59 INFO 140162782930752] Epoch[42] Batch [5]#011Speed: 87.25 samples/sec#011loss=-1.763591\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:08 INFO 140162782930752] processed a total of 2072 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24188.939094543457, \"sum\": 24188.939094543457, \"min\": 24188.939094543457}}, \"EndTime\": 1600222028.91844, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222004.72916}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:08 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.6586814054 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:08 INFO 140162782930752] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:08 INFO 140162782930752] #quality_metric: host=algo-1, epoch=42, train loss <loss>=-1.76078872681\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:11 INFO 140162782930752] Epoch[43] Batch[0] avg_epoch_loss=-1.840094\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=-1.84009419955\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:23 INFO 140162782930752] Epoch[43] Batch[5] avg_epoch_loss=-1.786568\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:23 INFO 140162782930752] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=-1.78656832377\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:23 INFO 140162782930752] Epoch[43] Batch [5]#011Speed: 87.72 samples/sec#011loss=-1.786568\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:35 INFO 140162782930752] Epoch[43] Batch[10] avg_epoch_loss=-1.807275\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:35 INFO 140162782930752] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=-1.83212353633\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:35 INFO 140162782930752] Epoch[43] Batch [10]#011Speed: 87.50 samples/sec#011loss=-1.832124\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:35 INFO 140162782930752] processed a total of 2082 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26494.0288066864, \"sum\": 26494.0288066864, \"min\": 26494.0288066864}}, \"EndTime\": 1600222055.412858, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222028.9185}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:35 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.5834945199 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:35 INFO 140162782930752] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:35 INFO 140162782930752] #quality_metric: host=algo-1, epoch=43, train loss <loss>=-1.80727523857\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:38 INFO 140162782930752] Epoch[44] Batch[0] avg_epoch_loss=-1.868545\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:38 INFO 140162782930752] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=-1.86854479863\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:50 INFO 140162782930752] Epoch[44] Batch[5] avg_epoch_loss=-1.809825\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:50 INFO 140162782930752] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=-1.80982521253\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:50 INFO 140162782930752] Epoch[44] Batch [5]#011Speed: 87.54 samples/sec#011loss=-1.809825\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:59 INFO 140162782930752] processed a total of 2066 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24224.063873291016, \"sum\": 24224.063873291016, \"min\": 24224.063873291016}}, \"EndTime\": 1600222079.637242, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222055.412914}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:59 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.2867123865 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:59 INFO 140162782930752] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:07:59 INFO 140162782930752] #quality_metric: host=algo-1, epoch=44, train loss <loss>=-1.8200670389\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:02 INFO 140162782930752] Epoch[45] Batch[0] avg_epoch_loss=-1.868850\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:02 INFO 140162782930752] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=-1.86884968097\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:14 INFO 140162782930752] Epoch[45] Batch[5] avg_epoch_loss=-1.730479\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:14 INFO 140162782930752] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=-1.73047897143\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:14 INFO 140162782930752] Epoch[45] Batch [5]#011Speed: 88.14 samples/sec#011loss=-1.730479\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:23 INFO 140162782930752] processed a total of 2051 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24000.998973846436, \"sum\": 24000.998973846436, \"min\": 24000.998973846436}}, \"EndTime\": 1600222103.638695, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222079.637313}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:23 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.4544351224 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:23 INFO 140162782930752] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:23 INFO 140162782930752] #quality_metric: host=algo-1, epoch=45, train loss <loss>=-1.71582577045\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:26 INFO 140162782930752] Epoch[46] Batch[0] avg_epoch_loss=-1.685746\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=-1.68574626629\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:38 INFO 140162782930752] Epoch[46] Batch[5] avg_epoch_loss=-1.708765\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:38 INFO 140162782930752] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=-1.70876517663\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:38 INFO 140162782930752] Epoch[46] Batch [5]#011Speed: 87.65 samples/sec#011loss=-1.708765\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:47 INFO 140162782930752] processed a total of 2044 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24055.309057235718, \"sum\": 24055.309057235718, \"min\": 24055.309057235718}}, \"EndTime\": 1600222127.694348, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222103.638759}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:47 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.9705191607 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:47 INFO 140162782930752] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=46, train loss <loss>=-1.69730312641\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:50 INFO 140162782930752] Epoch[47] Batch[0] avg_epoch_loss=-1.725321\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:08:50 INFO 140162782930752] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=-1.7253212562\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:02 INFO 140162782930752] Epoch[47] Batch[5] avg_epoch_loss=-1.760693\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:02 INFO 140162782930752] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=-1.76069306105\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:02 INFO 140162782930752] Epoch[47] Batch [5]#011Speed: 87.57 samples/sec#011loss=-1.760693\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:14 INFO 140162782930752] Epoch[47] Batch[10] avg_epoch_loss=-1.770680\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:14 INFO 140162782930752] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=-1.78266331599\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:14 INFO 140162782930752] Epoch[47] Batch [10]#011Speed: 87.70 samples/sec#011loss=-1.782663\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:14 INFO 140162782930752] processed a total of 2099 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26480.12685775757, \"sum\": 26480.12685775757, \"min\": 26480.12685775757}}, \"EndTime\": 1600222154.17493, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222127.694411}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:14 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.2667484877 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:14 INFO 140162782930752] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:14 INFO 140162782930752] #quality_metric: host=algo-1, epoch=47, train loss <loss>=-1.77067954057\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:16 INFO 140162782930752] Epoch[48] Batch[0] avg_epoch_loss=-1.809768\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=-1.80976808988\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:28 INFO 140162782930752] Epoch[48] Batch[5] avg_epoch_loss=-1.827858\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:28 INFO 140162782930752] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=-1.82785750658\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:28 INFO 140162782930752] Epoch[48] Batch [5]#011Speed: 87.68 samples/sec#011loss=-1.827858\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:40 INFO 140162782930752] Epoch[48] Batch[10] avg_epoch_loss=-1.836468\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:40 INFO 140162782930752] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=-1.84679973309\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:40 INFO 140162782930752] Epoch[48] Batch [10]#011Speed: 87.56 samples/sec#011loss=-1.846800\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:40 INFO 140162782930752] processed a total of 2081 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26526.002883911133, \"sum\": 26526.002883911133, \"min\": 26526.002883911133}}, \"EndTime\": 1600222180.701204, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222154.174983}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:40 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.4510733308 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:40 INFO 140162782930752] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:40 INFO 140162782930752] #quality_metric: host=algo-1, epoch=48, train loss <loss>=-1.83646760954\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:43 INFO 140162782930752] Epoch[49] Batch[0] avg_epoch_loss=-1.789301\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:43 INFO 140162782930752] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=-1.7893010653\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:55 INFO 140162782930752] Epoch[49] Batch[5] avg_epoch_loss=-1.851174\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:55 INFO 140162782930752] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=-1.85117379213\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:09:55 INFO 140162782930752] Epoch[49] Batch [5]#011Speed: 86.72 samples/sec#011loss=-1.851174\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:07 INFO 140162782930752] Epoch[49] Batch[10] avg_epoch_loss=-1.855469\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=-1.86062311026\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:07 INFO 140162782930752] Epoch[49] Batch [10]#011Speed: 86.58 samples/sec#011loss=-1.860623\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:07 INFO 140162782930752] processed a total of 2094 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26776.96394920349, \"sum\": 26776.96394920349, \"min\": 26776.96394920349}}, \"EndTime\": 1600222207.478442, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222180.701262}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:07 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.2013309698 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:07 INFO 140162782930752] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=49, train loss <loss>=-1.85546893673\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:10 INFO 140162782930752] Epoch[50] Batch[0] avg_epoch_loss=-1.778721\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:10 INFO 140162782930752] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=-1.77872129587\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:22 INFO 140162782930752] Epoch[50] Batch[5] avg_epoch_loss=-1.786251\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:22 INFO 140162782930752] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=-1.78625111702\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:22 INFO 140162782930752] Epoch[50] Batch [5]#011Speed: 87.60 samples/sec#011loss=-1.786251\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:33 INFO 140162782930752] Epoch[50] Batch[10] avg_epoch_loss=-1.802890\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=-1.82285693242\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:33 INFO 140162782930752] Epoch[50] Batch [10]#011Speed: 87.61 samples/sec#011loss=-1.822857\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:33 INFO 140162782930752] processed a total of 2123 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26488.733053207397, \"sum\": 26488.733053207397, \"min\": 26488.733053207397}}, \"EndTime\": 1600222233.967459, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222207.478491}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:33 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.1470296646 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:33 INFO 140162782930752] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=50, train loss <loss>=-1.80289012402\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:36 INFO 140162782930752] Epoch[51] Batch[0] avg_epoch_loss=-1.794520\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=-1.7945198646\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:48 INFO 140162782930752] Epoch[51] Batch[5] avg_epoch_loss=-1.786361\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:48 INFO 140162782930752] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=-1.78636135199\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:10:48 INFO 140162782930752] Epoch[51] Batch [5]#011Speed: 87.60 samples/sec#011loss=-1.786361\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:00 INFO 140162782930752] Epoch[51] Batch[10] avg_epoch_loss=-1.809282\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=-1.8367867103\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:00 INFO 140162782930752] Epoch[51] Batch [10]#011Speed: 87.50 samples/sec#011loss=-1.836787\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:00 INFO 140162782930752] processed a total of 2175 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26511.642932891846, \"sum\": 26511.642932891846, \"min\": 26511.642932891846}}, \"EndTime\": 1600222260.479418, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222233.967517}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:00 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=82.0391608498 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:00 INFO 140162782930752] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=51, train loss <loss>=-1.8092819694\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:03 INFO 140162782930752] Epoch[52] Batch[0] avg_epoch_loss=-1.784988\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:03 INFO 140162782930752] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=-1.78498752301\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:15 INFO 140162782930752] Epoch[52] Batch[5] avg_epoch_loss=-1.835524\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:15 INFO 140162782930752] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=-1.83552433894\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:15 INFO 140162782930752] Epoch[52] Batch [5]#011Speed: 87.74 samples/sec#011loss=-1.835524\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:26 INFO 140162782930752] Epoch[52] Batch[10] avg_epoch_loss=-1.849512\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=-1.8662979126\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:26 INFO 140162782930752] Epoch[52] Batch [10]#011Speed: 87.68 samples/sec#011loss=-1.866298\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:26 INFO 140162782930752] processed a total of 2180 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26515.179872512817, \"sum\": 26515.179872512817, \"min\": 26515.179872512817}}, \"EndTime\": 1600222286.994885, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222260.479475}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:26 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=82.2167725248 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:26 INFO 140162782930752] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=52, train loss <loss>=-1.84951232697\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:29 INFO 140162782930752] Epoch[53] Batch[0] avg_epoch_loss=-1.842214\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:29 INFO 140162782930752] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=-1.84221414419\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:41 INFO 140162782930752] Epoch[53] Batch[5] avg_epoch_loss=-1.864219\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:41 INFO 140162782930752] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=-1.86421932318\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:41 INFO 140162782930752] Epoch[53] Batch [5]#011Speed: 87.61 samples/sec#011loss=-1.864219\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:53 INFO 140162782930752] Epoch[53] Batch[10] avg_epoch_loss=-1.869456\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=-1.87573996324\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:53 INFO 140162782930752] Epoch[53] Batch [10]#011Speed: 87.50 samples/sec#011loss=-1.875740\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:53 INFO 140162782930752] processed a total of 2161 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26529.217004776, \"sum\": 26529.217004776, \"min\": 26529.217004776}}, \"EndTime\": 1600222313.524468, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222286.994948}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:53 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.4570628042 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:53 INFO 140162782930752] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=53, train loss <loss>=-1.86945597775\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:56 INFO 140162782930752] Epoch[54] Batch[0] avg_epoch_loss=-1.840800\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:11:56 INFO 140162782930752] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=-1.8407996251\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:08 INFO 140162782930752] Epoch[54] Batch[5] avg_epoch_loss=-1.871334\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:08 INFO 140162782930752] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=-1.87133370913\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:08 INFO 140162782930752] Epoch[54] Batch [5]#011Speed: 86.55 samples/sec#011loss=-1.871334\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:20 INFO 140162782930752] Epoch[54] Batch[10] avg_epoch_loss=-1.876000\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:20 INFO 140162782930752] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=-1.88160001315\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:20 INFO 140162782930752] Epoch[54] Batch [10]#011Speed: 87.73 samples/sec#011loss=-1.881600\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:20 INFO 140162782930752] processed a total of 2125 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26624.526023864746, \"sum\": 26624.526023864746, \"min\": 26624.526023864746}}, \"EndTime\": 1600222340.149391, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222313.524534}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:20 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.8133429515 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:20 INFO 140162782930752] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:20 INFO 140162782930752] #quality_metric: host=algo-1, epoch=54, train loss <loss>=-1.87600021096\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:22 INFO 140162782930752] Epoch[55] Batch[0] avg_epoch_loss=-1.857081\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:22 INFO 140162782930752] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=-1.85708148663\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:34 INFO 140162782930752] Epoch[55] Batch[5] avg_epoch_loss=-1.772825\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=-1.77282482538\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:34 INFO 140162782930752] Epoch[55] Batch [5]#011Speed: 87.47 samples/sec#011loss=-1.772825\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:46 INFO 140162782930752] Epoch[55] Batch[10] avg_epoch_loss=-1.778072\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:46 INFO 140162782930752] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=-1.7843695127\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:46 INFO 140162782930752] Epoch[55] Batch [10]#011Speed: 87.79 samples/sec#011loss=-1.784370\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:46 INFO 140162782930752] processed a total of 2108 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26474.66802597046, \"sum\": 26474.66802597046, \"min\": 26474.66802597046}}, \"EndTime\": 1600222366.624424, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222340.149452}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:46 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.623013256 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:46 INFO 140162782930752] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:46 INFO 140162782930752] #quality_metric: host=algo-1, epoch=55, train loss <loss>=-1.77807241053\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:49 INFO 140162782930752] Epoch[56] Batch[0] avg_epoch_loss=-1.199639\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:12:49 INFO 140162782930752] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=-1.19963924701\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:01 INFO 140162782930752] Epoch[56] Batch[5] avg_epoch_loss=-1.566818\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:01 INFO 140162782930752] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=-1.56681750371\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:01 INFO 140162782930752] Epoch[56] Batch [5]#011Speed: 87.38 samples/sec#011loss=-1.566818\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:10 INFO 140162782930752] processed a total of 2046 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24176.553964614868, \"sum\": 24176.553964614868, \"min\": 24176.553964614868}}, \"EndTime\": 1600222390.801336, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222366.624482}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:10 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.6271407623 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:10 INFO 140162782930752] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:10 INFO 140162782930752] #quality_metric: host=algo-1, epoch=56, train loss <loss>=-1.63046803108\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:13 INFO 140162782930752] Epoch[57] Batch[0] avg_epoch_loss=-1.799141\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=-1.79914122361\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:25 INFO 140162782930752] Epoch[57] Batch[5] avg_epoch_loss=-1.660392\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:25 INFO 140162782930752] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=-1.66039239443\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:25 INFO 140162782930752] Epoch[57] Batch [5]#011Speed: 88.11 samples/sec#011loss=-1.660392\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:37 INFO 140162782930752] Epoch[57] Batch[10] avg_epoch_loss=-1.676015\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:37 INFO 140162782930752] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=-1.6947619805\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:37 INFO 140162782930752] Epoch[57] Batch [10]#011Speed: 87.84 samples/sec#011loss=-1.694762\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:37 INFO 140162782930752] processed a total of 2102 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26379.15015220642, \"sum\": 26379.15015220642, \"min\": 26379.15015220642}}, \"EndTime\": 1600222417.180975, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222390.801397}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:37 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.6837788874 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:37 INFO 140162782930752] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:37 INFO 140162782930752] #quality_metric: host=algo-1, epoch=57, train loss <loss>=-1.67601493355\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:39 INFO 140162782930752] Epoch[58] Batch[0] avg_epoch_loss=-1.808294\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:39 INFO 140162782930752] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=-1.80829429626\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:51 INFO 140162782930752] Epoch[58] Batch[5] avg_epoch_loss=-1.769198\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=-1.76919802641\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:13:51 INFO 140162782930752] Epoch[58] Batch [5]#011Speed: 88.13 samples/sec#011loss=-1.769198\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:03 INFO 140162782930752] Epoch[58] Batch[10] avg_epoch_loss=-1.800237\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:03 INFO 140162782930752] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=-1.83748347943\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:03 INFO 140162782930752] Epoch[58] Batch [10]#011Speed: 87.80 samples/sec#011loss=-1.837483\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:03 INFO 140162782930752] processed a total of 2113 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26380.079984664917, \"sum\": 26380.079984664917, \"min\": 26380.079984664917}}, \"EndTime\": 1600222443.561792, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222417.181061}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:03 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.0979916188 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:03 INFO 140162782930752] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:03 INFO 140162782930752] #quality_metric: host=algo-1, epoch=58, train loss <loss>=-1.80023686869\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:06 INFO 140162782930752] Epoch[59] Batch[0] avg_epoch_loss=-1.845538\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:06 INFO 140162782930752] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=-1.84553791926\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:18 INFO 140162782930752] Epoch[59] Batch[5] avg_epoch_loss=-1.813063\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=-1.81306315691\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:18 INFO 140162782930752] Epoch[59] Batch [5]#011Speed: 87.84 samples/sec#011loss=-1.813063\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:30 INFO 140162782930752] Epoch[59] Batch[10] avg_epoch_loss=-1.809183\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:30 INFO 140162782930752] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=-1.80452596224\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:30 INFO 140162782930752] Epoch[59] Batch [10]#011Speed: 87.46 samples/sec#011loss=-1.804526\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:30 INFO 140162782930752] processed a total of 2094 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26491.00685119629, \"sum\": 26491.00685119629, \"min\": 26491.00685119629}}, \"EndTime\": 1600222470.053184, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222443.561868}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:30 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.0454420687 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:30 INFO 140162782930752] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:30 INFO 140162782930752] #quality_metric: host=algo-1, epoch=59, train loss <loss>=-1.80918261388\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:32 INFO 140162782930752] Epoch[60] Batch[0] avg_epoch_loss=-1.848876\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:32 INFO 140162782930752] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=-1.84887621953\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:44 INFO 140162782930752] Epoch[60] Batch[5] avg_epoch_loss=-1.851034\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:44 INFO 140162782930752] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=-1.85103418888\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:44 INFO 140162782930752] Epoch[60] Batch [5]#011Speed: 87.52 samples/sec#011loss=-1.851034\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:54 INFO 140162782930752] processed a total of 2016 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24145.971059799194, \"sum\": 24145.971059799194, \"min\": 24145.971059799194}}, \"EndTime\": 1600222494.19944, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222470.053243}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:54 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.4918922471 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:54 INFO 140162782930752] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=60, train loss <loss>=-1.85989219959\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:56 INFO 140162782930752] Epoch[61] Batch[0] avg_epoch_loss=-1.874723\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:14:56 INFO 140162782930752] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=-1.87472299429\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:08 INFO 140162782930752] Epoch[61] Batch[5] avg_epoch_loss=-1.864843\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:08 INFO 140162782930752] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=-1.86484344189\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:08 INFO 140162782930752] Epoch[61] Batch [5]#011Speed: 87.33 samples/sec#011loss=-1.864843\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:20 INFO 140162782930752] Epoch[61] Batch[10] avg_epoch_loss=-1.871852\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:20 INFO 140162782930752] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=-1.88026187603\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:20 INFO 140162782930752] Epoch[61] Batch [10]#011Speed: 87.32 samples/sec#011loss=-1.880262\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:20 INFO 140162782930752] processed a total of 2123 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26606.246948242188, \"sum\": 26606.246948242188, \"min\": 26606.246948242188}}, \"EndTime\": 1600222520.806096, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222494.199495}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:20 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.7930391172 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:20 INFO 140162782930752] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:20 INFO 140162782930752] #quality_metric: host=algo-1, epoch=61, train loss <loss>=-1.87185182105\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:23 INFO 140162782930752] Epoch[62] Batch[0] avg_epoch_loss=-1.822876\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:23 INFO 140162782930752] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=-1.82287553641\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:35 INFO 140162782930752] Epoch[62] Batch[5] avg_epoch_loss=-1.846951\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:35 INFO 140162782930752] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=-1.84695138687\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:35 INFO 140162782930752] Epoch[62] Batch [5]#011Speed: 87.44 samples/sec#011loss=-1.846951\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:44 INFO 140162782930752] processed a total of 2063 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24112.807989120483, \"sum\": 24112.807989120483, \"min\": 24112.807989120483}}, \"EndTime\": 1600222544.919205, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222520.806153}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:44 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.5556442778 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:44 INFO 140162782930752] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:44 INFO 140162782930752] #quality_metric: host=algo-1, epoch=62, train loss <loss>=-1.85586561056\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:47 INFO 140162782930752] Epoch[63] Batch[0] avg_epoch_loss=-1.898325\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=-1.89832452627\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:59 INFO 140162782930752] Epoch[63] Batch[5] avg_epoch_loss=-1.891492\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:59 INFO 140162782930752] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=-1.89149245238\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:15:59 INFO 140162782930752] Epoch[63] Batch [5]#011Speed: 87.76 samples/sec#011loss=-1.891492\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:09 INFO 140162782930752] processed a total of 2041 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24183.391094207764, \"sum\": 24183.391094207764, \"min\": 24183.391094207764}}, \"EndTime\": 1600222569.102986, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222544.919315}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:09 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.396466494 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:09 INFO 140162782930752] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=63, train loss <loss>=-1.8856877547\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:11 INFO 140162782930752] Epoch[64] Batch[0] avg_epoch_loss=-1.853717\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=-1.8537166302\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:23 INFO 140162782930752] Epoch[64] Batch[5] avg_epoch_loss=-1.877878\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:23 INFO 140162782930752] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=-1.87787794456\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:23 INFO 140162782930752] Epoch[64] Batch [5]#011Speed: 87.83 samples/sec#011loss=-1.877878\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:33 INFO 140162782930752] processed a total of 2057 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24113.46983909607, \"sum\": 24113.46983909607, \"min\": 24113.46983909607}}, \"EndTime\": 1600222593.216955, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222569.103046}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:33 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.3046722317 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:33 INFO 140162782930752] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=64, train loss <loss>=-1.88215223459\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:35 INFO 140162782930752] Epoch[65] Batch[0] avg_epoch_loss=-1.894328\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:35 INFO 140162782930752] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=-1.89432789729\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:47 INFO 140162782930752] Epoch[65] Batch[5] avg_epoch_loss=-1.878427\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=-1.87842689416\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:47 INFO 140162782930752] Epoch[65] Batch [5]#011Speed: 87.77 samples/sec#011loss=-1.878427\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:59 INFO 140162782930752] Epoch[65] Batch[10] avg_epoch_loss=-1.880227\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:59 INFO 140162782930752] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=-1.88238633963\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:59 INFO 140162782930752] Epoch[65] Batch [10]#011Speed: 87.76 samples/sec#011loss=-1.882386\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:59 INFO 140162782930752] processed a total of 2141 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26473.504066467285, \"sum\": 26473.504066467285, \"min\": 26473.504066467285}}, \"EndTime\": 1600222619.690801, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222593.217019}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:59 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.8730631857 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:59 INFO 140162782930752] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:16:59 INFO 140162782930752] #quality_metric: host=algo-1, epoch=65, train loss <loss>=-1.8802266421\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:02 INFO 140162782930752] Epoch[66] Batch[0] avg_epoch_loss=-1.771212\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:02 INFO 140162782930752] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=-1.77121235774\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:14 INFO 140162782930752] Epoch[66] Batch[5] avg_epoch_loss=-1.828299\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:14 INFO 140162782930752] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=-1.82829920451\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:14 INFO 140162782930752] Epoch[66] Batch [5]#011Speed: 87.42 samples/sec#011loss=-1.828299\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:26 INFO 140162782930752] Epoch[66] Batch[10] avg_epoch_loss=-1.836775\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=-1.84694492634\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:26 INFO 140162782930752] Epoch[66] Batch [10]#011Speed: 87.25 samples/sec#011loss=-1.846945\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:26 INFO 140162782930752] processed a total of 2081 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26631.415128707886, \"sum\": 26631.415128707886, \"min\": 26631.415128707886}}, \"EndTime\": 1600222646.322491, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222619.690858}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:26 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.1405541267 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:26 INFO 140162782930752] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=66, train loss <loss>=-1.83677453261\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:29 INFO 140162782930752] Epoch[67] Batch[0] avg_epoch_loss=-1.897721\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:29 INFO 140162782930752] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=-1.89772063035\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:40 INFO 140162782930752] Epoch[67] Batch[5] avg_epoch_loss=-1.881536\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:40 INFO 140162782930752] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=-1.88153550564\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:40 INFO 140162782930752] Epoch[67] Batch [5]#011Speed: 87.28 samples/sec#011loss=-1.881536\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:52 INFO 140162782930752] Epoch[67] Batch[10] avg_epoch_loss=-1.879332\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:52 INFO 140162782930752] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=-1.87668861976\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:52 INFO 140162782930752] Epoch[67] Batch [10]#011Speed: 87.43 samples/sec#011loss=-1.876689\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:52 INFO 140162782930752] processed a total of 2112 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26563.901901245117, \"sum\": 26563.901901245117, \"min\": 26563.901901245117}}, \"EndTime\": 1600222672.88669, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222646.32255}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:52 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.5061259209 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:52 INFO 140162782930752] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:52 INFO 140162782930752] #quality_metric: host=algo-1, epoch=67, train loss <loss>=-1.87933237569\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:55 INFO 140162782930752] Epoch[68] Batch[0] avg_epoch_loss=-1.898288\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:17:55 INFO 140162782930752] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=-1.89828843337\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:07 INFO 140162782930752] Epoch[68] Batch[5] avg_epoch_loss=-1.891299\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=-1.89129910102\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:07 INFO 140162782930752] Epoch[68] Batch [5]#011Speed: 87.16 samples/sec#011loss=-1.891299\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:19 INFO 140162782930752] Epoch[68] Batch[10] avg_epoch_loss=-1.888024\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:19 INFO 140162782930752] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=-1.88409371009\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:19 INFO 140162782930752] Epoch[68] Batch [10]#011Speed: 88.08 samples/sec#011loss=-1.884094\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:19 INFO 140162782930752] processed a total of 2137 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26490.066051483154, \"sum\": 26490.066051483154, \"min\": 26490.066051483154}}, \"EndTime\": 1600222699.377085, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222672.886753}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:19 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.6714949531 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:19 INFO 140162782930752] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:19 INFO 140162782930752] #quality_metric: host=algo-1, epoch=68, train loss <loss>=-1.88802392333\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:22 INFO 140162782930752] Epoch[69] Batch[0] avg_epoch_loss=-1.889228\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:22 INFO 140162782930752] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=-1.88922779377\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:33 INFO 140162782930752] Epoch[69] Batch[5] avg_epoch_loss=-1.882156\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=-1.88215607863\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:33 INFO 140162782930752] Epoch[69] Batch [5]#011Speed: 87.87 samples/sec#011loss=-1.882156\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:43 INFO 140162782930752] processed a total of 1966 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24057.345867156982, \"sum\": 24057.345867156982, \"min\": 24057.345867156982}}, \"EndTime\": 1600222723.434719, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222699.377143}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:43 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.7200789166 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:43 INFO 140162782930752] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:43 INFO 140162782930752] #quality_metric: host=algo-1, epoch=69, train loss <loss>=-1.88697952857\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:46 INFO 140162782930752] Epoch[70] Batch[0] avg_epoch_loss=-1.875446\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:46 INFO 140162782930752] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=-1.8754464663\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:58 INFO 140162782930752] Epoch[70] Batch[5] avg_epoch_loss=-1.877436\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:58 INFO 140162782930752] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=-1.87743590428\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:18:58 INFO 140162782930752] Epoch[70] Batch [5]#011Speed: 87.80 samples/sec#011loss=-1.877436\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:07 INFO 140162782930752] processed a total of 2078 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24131.942987442017, \"sum\": 24131.942987442017, \"min\": 24131.942987442017}}, \"EndTime\": 1600222747.567517, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222723.435074}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:07 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=86.1095691379 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:07 INFO 140162782930752] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=70, train loss <loss>=-1.88185917781\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:10 INFO 140162782930752] Epoch[71] Batch[0] avg_epoch_loss=-1.896561\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:10 INFO 140162782930752] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=-1.8965611091\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:22 INFO 140162782930752] Epoch[71] Batch[5] avg_epoch_loss=-1.881193\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:22 INFO 140162782930752] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=-1.88119262304\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:22 INFO 140162782930752] Epoch[71] Batch [5]#011Speed: 86.76 samples/sec#011loss=-1.881193\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:34 INFO 140162782930752] Epoch[71] Batch[10] avg_epoch_loss=-1.867310\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=-1.85065146226\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:34 INFO 140162782930752] Epoch[71] Batch [10]#011Speed: 87.49 samples/sec#011loss=-1.850651\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:34 INFO 140162782930752] processed a total of 2127 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26620.47791481018, \"sum\": 26620.47791481018, \"min\": 26620.47791481018}}, \"EndTime\": 1600222774.188423, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222747.567586}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:34 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.9006298228 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:34 INFO 140162782930752] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=71, train loss <loss>=-1.86731027723\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:36 INFO 140162782930752] Epoch[72] Batch[0] avg_epoch_loss=-1.570770\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=-1.57077041039\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:49 INFO 140162782930752] Epoch[72] Batch[5] avg_epoch_loss=-1.720143\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:49 INFO 140162782930752] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=-1.72014341599\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:19:49 INFO 140162782930752] Epoch[72] Batch [5]#011Speed: 86.04 samples/sec#011loss=-1.720143\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:00 INFO 140162782930752] Epoch[72] Batch[10] avg_epoch_loss=-1.731374\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=-1.74484998263\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:00 INFO 140162782930752] Epoch[72] Batch [10]#011Speed: 87.64 samples/sec#011loss=-1.744850\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:00 INFO 140162782930752] processed a total of 2133 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26702.961921691895, \"sum\": 26702.961921691895, \"min\": 26702.961921691895}}, \"EndTime\": 1600222800.891679, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222774.188482}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:00 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.8783841136 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:00 INFO 140162782930752] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=72, train loss <loss>=-1.73137367355\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:03 INFO 140162782930752] Epoch[73] Batch[0] avg_epoch_loss=-1.694207\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:03 INFO 140162782930752] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=-1.69420653123\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:15 INFO 140162782930752] Epoch[73] Batch[5] avg_epoch_loss=-1.775344\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:15 INFO 140162782930752] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=-1.77534372379\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:15 INFO 140162782930752] Epoch[73] Batch [5]#011Speed: 87.55 samples/sec#011loss=-1.775344\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:27 INFO 140162782930752] Epoch[73] Batch[10] avg_epoch_loss=-1.804087\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=-1.8385796767\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:27 INFO 140162782930752] Epoch[73] Batch [10]#011Speed: 87.72 samples/sec#011loss=-1.838580\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:27 INFO 140162782930752] processed a total of 2117 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26565.176963806152, \"sum\": 26565.176963806152, \"min\": 26565.176963806152}}, \"EndTime\": 1600222827.457211, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222800.891768}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:27 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.6905369759 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:27 INFO 140162782930752] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=73, train loss <loss>=-1.80408733875\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:30 INFO 140162782930752] Epoch[74] Batch[0] avg_epoch_loss=-1.796293\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:30 INFO 140162782930752] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=-1.79629311195\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:42 INFO 140162782930752] Epoch[74] Batch[5] avg_epoch_loss=-1.849839\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:42 INFO 140162782930752] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=-1.84983899043\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:42 INFO 140162782930752] Epoch[74] Batch [5]#011Speed: 87.22 samples/sec#011loss=-1.849839\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:54 INFO 140162782930752] Epoch[74] Batch[10] avg_epoch_loss=-1.844471\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=-1.83803033095\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:54 INFO 140162782930752] Epoch[74] Batch [10]#011Speed: 87.22 samples/sec#011loss=-1.838030\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:54 INFO 140162782930752] processed a total of 2137 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26614.617109298706, \"sum\": 26614.617109298706, \"min\": 26614.617109298706}}, \"EndTime\": 1600222854.072101, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222827.457268}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:54 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.2939819921 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:54 INFO 140162782930752] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=74, train loss <loss>=-1.84447141794\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:56 INFO 140162782930752] Epoch[75] Batch[0] avg_epoch_loss=-1.736754\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:20:56 INFO 140162782930752] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=-1.73675419734\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:08 INFO 140162782930752] Epoch[75] Batch[5] avg_epoch_loss=-1.821753\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:08 INFO 140162782930752] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=-1.82175340408\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:08 INFO 140162782930752] Epoch[75] Batch [5]#011Speed: 87.15 samples/sec#011loss=-1.821753\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:18 INFO 140162782930752] processed a total of 2055 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24196.106910705566, \"sum\": 24196.106910705566, \"min\": 24196.106910705566}}, \"EndTime\": 1600222878.268481, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222854.072156}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:18 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.9306810891 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:18 INFO 140162782930752] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=75, train loss <loss>=-1.83021681859\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:21 INFO 140162782930752] Epoch[76] Batch[0] avg_epoch_loss=-1.857443\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:21 INFO 140162782930752] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=-1.85744300255\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:32 INFO 140162782930752] Epoch[76] Batch[5] avg_epoch_loss=-1.856936\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:32 INFO 140162782930752] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=-1.8569355011\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:32 INFO 140162782930752] Epoch[76] Batch [5]#011Speed: 87.49 samples/sec#011loss=-1.856936\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:44 INFO 140162782930752] Epoch[76] Batch[10] avg_epoch_loss=-1.865854\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:44 INFO 140162782930752] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=-1.87655713008\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:44 INFO 140162782930752] Epoch[76] Batch [10]#011Speed: 87.14 samples/sec#011loss=-1.876557\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:44 INFO 140162782930752] processed a total of 2112 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26567.721128463745, \"sum\": 26567.721128463745, \"min\": 26567.721128463745}}, \"EndTime\": 1600222904.836631, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222878.268546}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:44 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.4946723475 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:44 INFO 140162782930752] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:44 INFO 140162782930752] #quality_metric: host=algo-1, epoch=76, train loss <loss>=-1.86585442336\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:47 INFO 140162782930752] Epoch[77] Batch[0] avg_epoch_loss=-1.858148\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=-1.85814769451\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:59 INFO 140162782930752] Epoch[77] Batch[5] avg_epoch_loss=-1.864711\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:59 INFO 140162782930752] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=-1.86471073444\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:21:59 INFO 140162782930752] Epoch[77] Batch [5]#011Speed: 87.45 samples/sec#011loss=-1.864711\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:09 INFO 140162782930752] processed a total of 2022 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24164.69407081604, \"sum\": 24164.69407081604, \"min\": 24164.69407081604}}, \"EndTime\": 1600222929.001713, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222904.836699}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:09 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.6750789288 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:09 INFO 140162782930752] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=77, train loss <loss>=-1.87267608643\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:11 INFO 140162782930752] Epoch[78] Batch[0] avg_epoch_loss=-1.894001\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=-1.89400086036\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:23 INFO 140162782930752] Epoch[78] Batch[5] avg_epoch_loss=-1.890238\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:23 INFO 140162782930752] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=-1.89023829729\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:23 INFO 140162782930752] Epoch[78] Batch [5]#011Speed: 87.91 samples/sec#011loss=-1.890238\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:35 INFO 140162782930752] Epoch[78] Batch[10] avg_epoch_loss=-1.886893\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:35 INFO 140162782930752] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=-1.88287890508\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:35 INFO 140162782930752] Epoch[78] Batch [10]#011Speed: 87.45 samples/sec#011loss=-1.882879\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:35 INFO 140162782930752] processed a total of 2121 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26479.36487197876, \"sum\": 26479.36487197876, \"min\": 26479.36487197876}}, \"EndTime\": 1600222955.48157, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222929.001889}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:35 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.0998481698 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:35 INFO 140162782930752] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:35 INFO 140162782930752] #quality_metric: host=algo-1, epoch=78, train loss <loss>=-1.88689311901\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:38 INFO 140162782930752] Epoch[79] Batch[0] avg_epoch_loss=-1.904905\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:38 INFO 140162782930752] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=-1.90490517249\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:50 INFO 140162782930752] Epoch[79] Batch[5] avg_epoch_loss=-1.904929\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:50 INFO 140162782930752] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=-1.90492891654\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:22:50 INFO 140162782930752] Epoch[79] Batch [5]#011Speed: 86.81 samples/sec#011loss=-1.904929\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:02 INFO 140162782930752] Epoch[79] Batch[10] avg_epoch_loss=-1.901354\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:02 INFO 140162782930752] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=-1.89706391555\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:02 INFO 140162782930752] Epoch[79] Batch [10]#011Speed: 87.60 samples/sec#011loss=-1.897064\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:02 INFO 140162782930752] processed a total of 2117 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26602.901935577393, \"sum\": 26602.901935577393, \"min\": 26602.901935577393}}, \"EndTime\": 1600222982.084825, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222955.481627}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:02 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.5775535297 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:02 INFO 140162782930752] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:02 INFO 140162782930752] #quality_metric: host=algo-1, epoch=79, train loss <loss>=-1.90135391609\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:04 INFO 140162782930752] Epoch[80] Batch[0] avg_epoch_loss=-1.905660\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:04 INFO 140162782930752] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=-1.90565974896\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:16 INFO 140162782930752] Epoch[80] Batch[5] avg_epoch_loss=-1.889717\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=-1.88971680861\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:16 INFO 140162782930752] Epoch[80] Batch [5]#011Speed: 88.06 samples/sec#011loss=-1.889717\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:26 INFO 140162782930752] processed a total of 2067 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24086.08889579773, \"sum\": 24086.08889579773, \"min\": 24086.08889579773}}, \"EndTime\": 1600223006.171201, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600222982.084875}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:26 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.81681383 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:26 INFO 140162782930752] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=80, train loss <loss>=-1.88941179422\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:28 INFO 140162782930752] Epoch[81] Batch[0] avg_epoch_loss=-1.900991\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:28 INFO 140162782930752] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=-1.90099085294\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:40 INFO 140162782930752] Epoch[81] Batch[5] avg_epoch_loss=-1.896254\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:40 INFO 140162782930752] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=-1.89625378144\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:40 INFO 140162782930752] Epoch[81] Batch [5]#011Speed: 87.97 samples/sec#011loss=-1.896254\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:52 INFO 140162782930752] Epoch[81] Batch[10] avg_epoch_loss=-1.892849\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:52 INFO 140162782930752] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=-1.88876413199\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:52 INFO 140162782930752] Epoch[81] Batch [10]#011Speed: 88.18 samples/sec#011loss=-1.888764\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:52 INFO 140162782930752] processed a total of 2105 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26365.8390045166, \"sum\": 26365.8390045166, \"min\": 26365.8390045166}}, \"EndTime\": 1600223032.537383, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223006.171272}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:52 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.8379059932 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:52 INFO 140162782930752] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:52 INFO 140162782930752] #quality_metric: host=algo-1, epoch=81, train loss <loss>=-1.89284939533\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:55 INFO 140162782930752] Epoch[82] Batch[0] avg_epoch_loss=-1.906709\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:23:55 INFO 140162782930752] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=-1.90670937758\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:07 INFO 140162782930752] Epoch[82] Batch[5] avg_epoch_loss=-1.905084\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=-1.90508372967\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:07 INFO 140162782930752] Epoch[82] Batch [5]#011Speed: 87.44 samples/sec#011loss=-1.905084\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:16 INFO 140162782930752] processed a total of 2020 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24163.88988494873, \"sum\": 24163.88988494873, \"min\": 24163.88988494873}}, \"EndTime\": 1600223056.701557, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223032.53744}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:16 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.5953618173 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:16 INFO 140162782930752] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=82, train loss <loss>=-1.90242757064\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:19 INFO 140162782930752] Epoch[83] Batch[0] avg_epoch_loss=-1.919221\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:19 INFO 140162782930752] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=-1.91922114446\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:31 INFO 140162782930752] Epoch[83] Batch[5] avg_epoch_loss=-1.881729\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:31 INFO 140162782930752] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=-1.88172863691\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:31 INFO 140162782930752] Epoch[83] Batch [5]#011Speed: 87.79 samples/sec#011loss=-1.881729\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:43 INFO 140162782930752] Epoch[83] Batch[10] avg_epoch_loss=-1.873233\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:43 INFO 140162782930752] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=-1.86303716806\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:43 INFO 140162782930752] Epoch[83] Batch [10]#011Speed: 87.11 samples/sec#011loss=-1.863037\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:43 INFO 140162782930752] processed a total of 2105 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26528.762102127075, \"sum\": 26528.762102127075, \"min\": 26528.762102127075}}, \"EndTime\": 1600223083.230807, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223056.701617}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:43 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.3475900904 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:43 INFO 140162782930752] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:43 INFO 140162782930752] #quality_metric: host=algo-1, epoch=83, train loss <loss>=-1.87323251471\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:45 INFO 140162782930752] Epoch[84] Batch[0] avg_epoch_loss=-1.852008\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:45 INFO 140162782930752] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=-1.85200764583\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:57 INFO 140162782930752] Epoch[84] Batch[5] avg_epoch_loss=-1.863489\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:57 INFO 140162782930752] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=-1.86348875975\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:24:57 INFO 140162782930752] Epoch[84] Batch [5]#011Speed: 87.42 samples/sec#011loss=-1.863489\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:09 INFO 140162782930752] Epoch[84] Batch[10] avg_epoch_loss=-1.864480\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=-1.86567001343\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:09 INFO 140162782930752] Epoch[84] Batch [10]#011Speed: 87.31 samples/sec#011loss=-1.865670\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:09 INFO 140162782930752] processed a total of 2121 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26576.452016830444, \"sum\": 26576.452016830444, \"min\": 26576.452016830444}}, \"EndTime\": 1600223109.807571, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223083.230862}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:09 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.8072342282 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:09 INFO 140162782930752] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=84, train loss <loss>=-1.86448023869\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:12 INFO 140162782930752] Epoch[85] Batch[0] avg_epoch_loss=-1.886814\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:12 INFO 140162782930752] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=-1.88681411743\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:24 INFO 140162782930752] Epoch[85] Batch[5] avg_epoch_loss=-1.892796\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:24 INFO 140162782930752] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=-1.89279634525\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:24 INFO 140162782930752] Epoch[85] Batch [5]#011Speed: 87.74 samples/sec#011loss=-1.892796\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:33 INFO 140162782930752] processed a total of 2061 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24118.75295639038, \"sum\": 24118.75295639038, \"min\": 24118.75295639038}}, \"EndTime\": 1600223133.92671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223109.80763}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:33 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.4514029292 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:33 INFO 140162782930752] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=85, train loss <loss>=-1.8978180812\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:36 INFO 140162782930752] Epoch[86] Batch[0] avg_epoch_loss=-1.915674\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=-1.91567406288\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:48 INFO 140162782930752] Epoch[86] Batch[5] avg_epoch_loss=-1.904527\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:48 INFO 140162782930752] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=-1.90452658824\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:25:48 INFO 140162782930752] Epoch[86] Batch [5]#011Speed: 87.54 samples/sec#011loss=-1.904527\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:00 INFO 140162782930752] Epoch[86] Batch[10] avg_epoch_loss=-1.918073\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=-1.93432978117\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:00 INFO 140162782930752] Epoch[86] Batch [10]#011Speed: 87.58 samples/sec#011loss=-1.934330\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:00 INFO 140162782930752] processed a total of 2097 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26547.742128372192, \"sum\": 26547.742128372192, \"min\": 26547.742128372192}}, \"EndTime\": 1600223160.474957, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223133.926898}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:00 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.9895065517 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:00 INFO 140162782930752] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=86, train loss <loss>=-1.91807349412\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:03 INFO 140162782930752] Epoch[87] Batch[0] avg_epoch_loss=-1.884390\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:03 INFO 140162782930752] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=-1.8843904642\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:15 INFO 140162782930752] Epoch[87] Batch[5] avg_epoch_loss=-1.795967\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:15 INFO 140162782930752] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=-1.79596685752\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:15 INFO 140162782930752] Epoch[87] Batch [5]#011Speed: 87.49 samples/sec#011loss=-1.795967\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:24 INFO 140162782930752] processed a total of 2012 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24217.381954193115, \"sum\": 24217.381954193115, \"min\": 24217.381954193115}}, \"EndTime\": 1600223184.69268, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223160.475015}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:24 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.0805202097 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:24 INFO 140162782930752] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:24 INFO 140162782930752] #quality_metric: host=algo-1, epoch=87, train loss <loss>=-1.78330653264\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:27 INFO 140162782930752] Epoch[88] Batch[0] avg_epoch_loss=-1.880599\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=-1.88059909527\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:39 INFO 140162782930752] Epoch[88] Batch[5] avg_epoch_loss=-1.806744\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:39 INFO 140162782930752] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=-1.80674357292\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:39 INFO 140162782930752] Epoch[88] Batch [5]#011Speed: 87.36 samples/sec#011loss=-1.806744\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:51 INFO 140162782930752] Epoch[88] Batch[10] avg_epoch_loss=-1.782010\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=-1.75232934218\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:51 INFO 140162782930752] Epoch[88] Batch [10]#011Speed: 87.64 samples/sec#011loss=-1.752329\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:51 INFO 140162782930752] processed a total of 2170 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26542.192220687866, \"sum\": 26542.192220687866, \"min\": 26542.192220687866}}, \"EndTime\": 1600223211.235255, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223184.692742}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:51 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.7563401489 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:51 INFO 140162782930752] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=88, train loss <loss>=-1.78200983168\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:53 INFO 140162782930752] Epoch[89] Batch[0] avg_epoch_loss=-1.809479\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:26:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=-1.80947861305\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:05 INFO 140162782930752] Epoch[89] Batch[5] avg_epoch_loss=-1.815982\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:05 INFO 140162782930752] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=-1.81598171821\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:05 INFO 140162782930752] Epoch[89] Batch [5]#011Speed: 87.39 samples/sec#011loss=-1.815982\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:17 INFO 140162782930752] Epoch[89] Batch[10] avg_epoch_loss=-1.816326\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:17 INFO 140162782930752] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=-1.81673827538\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:17 INFO 140162782930752] Epoch[89] Batch [10]#011Speed: 87.61 samples/sec#011loss=-1.816738\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:17 INFO 140162782930752] processed a total of 2081 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26533.486127853394, \"sum\": 26533.486127853394, \"min\": 26533.486127853394}}, \"EndTime\": 1600223237.769093, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223211.235314}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:17 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.4287533264 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:17 INFO 140162782930752] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:17 INFO 140162782930752] #quality_metric: host=algo-1, epoch=89, train loss <loss>=-1.81632560783\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:20 INFO 140162782930752] Epoch[90] Batch[0] avg_epoch_loss=-1.777509\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:20 INFO 140162782930752] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=-1.77750895574\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:32 INFO 140162782930752] Epoch[90] Batch[5] avg_epoch_loss=-1.837823\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:32 INFO 140162782930752] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=-1.83782347655\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:32 INFO 140162782930752] Epoch[90] Batch [5]#011Speed: 87.64 samples/sec#011loss=-1.837823\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:44 INFO 140162782930752] Epoch[90] Batch[10] avg_epoch_loss=-1.841239\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:44 INFO 140162782930752] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=-1.84533764766\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:44 INFO 140162782930752] Epoch[90] Batch [10]#011Speed: 87.54 samples/sec#011loss=-1.845338\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:44 INFO 140162782930752] processed a total of 2104 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26488.871097564697, \"sum\": 26488.871097564697, \"min\": 26488.871097564697}}, \"EndTime\": 1600223264.258383, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223237.76921}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:44 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.4293404775 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:44 INFO 140162782930752] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:44 INFO 140162782930752] #quality_metric: host=algo-1, epoch=90, train loss <loss>=-1.84123900887\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:47 INFO 140162782930752] Epoch[91] Batch[0] avg_epoch_loss=-1.814365\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=-1.81436450665\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:58 INFO 140162782930752] Epoch[91] Batch[5] avg_epoch_loss=-1.838121\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:58 INFO 140162782930752] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=-1.83812109629\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:27:58 INFO 140162782930752] Epoch[91] Batch [5]#011Speed: 87.56 samples/sec#011loss=-1.838121\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:08 INFO 140162782930752] processed a total of 2048 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24170.966863632202, \"sum\": 24170.966863632202, \"min\": 24170.966863632202}}, \"EndTime\": 1600223288.429712, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223264.258434}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:08 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.7293087283 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:08 INFO 140162782930752] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:08 INFO 140162782930752] #quality_metric: host=algo-1, epoch=91, train loss <loss>=-1.84418355502\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:11 INFO 140162782930752] Epoch[92] Batch[0] avg_epoch_loss=-1.791919\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=-1.79191912138\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:22 INFO 140162782930752] Epoch[92] Batch[5] avg_epoch_loss=-1.864456\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:22 INFO 140162782930752] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=-1.8644557366\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:22 INFO 140162782930752] Epoch[92] Batch [5]#011Speed: 88.20 samples/sec#011loss=-1.864456\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:34 INFO 140162782930752] Epoch[92] Batch[10] avg_epoch_loss=-1.865064\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=-1.8657939324\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:34 INFO 140162782930752] Epoch[92] Batch [10]#011Speed: 88.17 samples/sec#011loss=-1.865794\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:34 INFO 140162782930752] processed a total of 2097 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26328.655004501343, \"sum\": 26328.655004501343, \"min\": 26328.655004501343}}, \"EndTime\": 1600223314.758795, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223288.429804}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:34 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.646798082 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:34 INFO 140162782930752] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=92, train loss <loss>=-1.86506400742\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:37 INFO 140162782930752] Epoch[93] Batch[0] avg_epoch_loss=-1.893131\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:37 INFO 140162782930752] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=-1.89313052251\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:49 INFO 140162782930752] Epoch[93] Batch[5] avg_epoch_loss=-1.863559\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:49 INFO 140162782930752] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=-1.86355852469\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:49 INFO 140162782930752] Epoch[93] Batch [5]#011Speed: 88.07 samples/sec#011loss=-1.863559\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:58 INFO 140162782930752] processed a total of 2069 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24055.78899383545, \"sum\": 24055.78899383545, \"min\": 24055.78899383545}}, \"EndTime\": 1600223338.814868, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223314.758854}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:58 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=86.0079165007 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:58 INFO 140162782930752] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:28:58 INFO 140162782930752] #quality_metric: host=algo-1, epoch=93, train loss <loss>=-1.86585244399\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:01 INFO 140162782930752] Epoch[94] Batch[0] avg_epoch_loss=-1.878133\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:01 INFO 140162782930752] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=-1.87813304021\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:13 INFO 140162782930752] Epoch[94] Batch[5] avg_epoch_loss=-1.887452\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=-1.88745215\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:13 INFO 140162782930752] Epoch[94] Batch [5]#011Speed: 87.18 samples/sec#011loss=-1.887452\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:25 INFO 140162782930752] Epoch[94] Batch[10] avg_epoch_loss=-1.879693\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:25 INFO 140162782930752] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=-1.87038113521\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:25 INFO 140162782930752] Epoch[94] Batch [10]#011Speed: 87.69 samples/sec#011loss=-1.870381\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:25 INFO 140162782930752] processed a total of 2112 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26544.9321269989, \"sum\": 26544.9321269989, \"min\": 26544.9321269989}}, \"EndTime\": 1600223365.360197, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223338.814974}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:25 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.5629638253 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:25 INFO 140162782930752] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:25 INFO 140162782930752] #quality_metric: host=algo-1, epoch=94, train loss <loss>=-1.87969259782\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:28 INFO 140162782930752] Epoch[95] Batch[0] avg_epoch_loss=-1.903688\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:28 INFO 140162782930752] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=-1.90368843079\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:40 INFO 140162782930752] Epoch[95] Batch[5] avg_epoch_loss=-1.886959\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:40 INFO 140162782930752] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=-1.88695936937\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:40 INFO 140162782930752] Epoch[95] Batch [5]#011Speed: 87.48 samples/sec#011loss=-1.886959\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:51 INFO 140162782930752] Epoch[95] Batch[10] avg_epoch_loss=-1.898340\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=-1.9119960198\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:51 INFO 140162782930752] Epoch[95] Batch [10]#011Speed: 87.53 samples/sec#011loss=-1.911996\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:51 INFO 140162782930752] processed a total of 2171 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26541.373014450073, \"sum\": 26541.373014450073, \"min\": 26541.373014450073}}, \"EndTime\": 1600223391.901901, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223365.36025}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:51 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.7965338531 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:51 INFO 140162782930752] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=95, train loss <loss>=-1.89833966502\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:54 INFO 140162782930752] Epoch[96] Batch[0] avg_epoch_loss=-1.847269\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:29:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=-1.84726949838\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:06 INFO 140162782930752] Epoch[96] Batch[5] avg_epoch_loss=-1.881514\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:06 INFO 140162782930752] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=-1.88151376675\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:06 INFO 140162782930752] Epoch[96] Batch [5]#011Speed: 87.21 samples/sec#011loss=-1.881514\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:18 INFO 140162782930752] Epoch[96] Batch[10] avg_epoch_loss=-1.895762\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=-1.91286028348\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:18 INFO 140162782930752] Epoch[96] Batch [10]#011Speed: 87.43 samples/sec#011loss=-1.912860\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:18 INFO 140162782930752] processed a total of 2128 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26591.712951660156, \"sum\": 26591.712951660156, \"min\": 26591.712951660156}}, \"EndTime\": 1600223418.494019, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223391.901965}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:18 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.0246693359 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:18 INFO 140162782930752] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=96, train loss <loss>=-1.89576218345\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:21 INFO 140162782930752] Epoch[97] Batch[0] avg_epoch_loss=-1.881086\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:21 INFO 140162782930752] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=-1.88108561589\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:33 INFO 140162782930752] Epoch[97] Batch[5] avg_epoch_loss=-1.889978\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=-1.88997765076\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:33 INFO 140162782930752] Epoch[97] Batch [5]#011Speed: 87.80 samples/sec#011loss=-1.889978\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:42 INFO 140162782930752] processed a total of 2044 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24113.136053085327, \"sum\": 24113.136053085327, \"min\": 24113.136053085327}}, \"EndTime\": 1600223442.607449, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223418.494078}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:42 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.7667727628 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:42 INFO 140162782930752] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:42 INFO 140162782930752] #quality_metric: host=algo-1, epoch=97, train loss <loss>=-1.89437806056\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:45 INFO 140162782930752] Epoch[98] Batch[0] avg_epoch_loss=-1.921427\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:45 INFO 140162782930752] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=-1.92142662635\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:57 INFO 140162782930752] Epoch[98] Batch[5] avg_epoch_loss=-1.905512\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:57 INFO 140162782930752] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=-1.90551158709\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:30:57 INFO 140162782930752] Epoch[98] Batch [5]#011Speed: 87.86 samples/sec#011loss=-1.905512\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:06 INFO 140162782930752] processed a total of 2070 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24165.086030960083, \"sum\": 24165.086030960083, \"min\": 24165.086030960083}}, \"EndTime\": 1600223466.772892, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223442.607509}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:06 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.6602959122 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:06 INFO 140162782930752] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:06 INFO 140162782930752] #quality_metric: host=algo-1, epoch=98, train loss <loss>=-1.90561012855\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:09 INFO 140162782930752] Epoch[99] Batch[0] avg_epoch_loss=-1.895160\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=-1.89516023489\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:21 INFO 140162782930752] Epoch[99] Batch[5] avg_epoch_loss=-1.910383\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:21 INFO 140162782930752] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=-1.91038322449\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:21 INFO 140162782930752] Epoch[99] Batch [5]#011Speed: 87.78 samples/sec#011loss=-1.910383\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:30 INFO 140162782930752] processed a total of 2071 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24191.247940063477, \"sum\": 24191.247940063477, \"min\": 24191.247940063477}}, \"EndTime\": 1600223490.964523, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223466.772998}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:30 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.6091512187 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:30 INFO 140162782930752] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:30 INFO 140162782930752] #quality_metric: host=algo-1, epoch=99, train loss <loss>=-1.90424986619\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:33 INFO 140162782930752] Epoch[100] Batch[0] avg_epoch_loss=-1.924945\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=-1.9249450977\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:45 INFO 140162782930752] Epoch[100] Batch[5] avg_epoch_loss=-1.902636\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:45 INFO 140162782930752] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=-1.90263628348\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:45 INFO 140162782930752] Epoch[100] Batch [5]#011Speed: 87.16 samples/sec#011loss=-1.902636\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:55 INFO 140162782930752] processed a total of 2035 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24171.14496231079, \"sum\": 24171.14496231079, \"min\": 24171.14496231079}}, \"EndTime\": 1600223515.136047, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223490.964585}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:55 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.1909289411 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:55 INFO 140162782930752] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:55 INFO 140162782930752] #quality_metric: host=algo-1, epoch=100, train loss <loss>=-1.90743145576\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:57 INFO 140162782930752] Epoch[101] Batch[0] avg_epoch_loss=-1.910719\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:31:57 INFO 140162782930752] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=-1.910719358\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:09 INFO 140162782930752] Epoch[101] Batch[5] avg_epoch_loss=-1.917167\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=-1.91716710115\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:09 INFO 140162782930752] Epoch[101] Batch [5]#011Speed: 86.82 samples/sec#011loss=-1.917167\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:19 INFO 140162782930752] processed a total of 2077 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24320.045948028564, \"sum\": 24320.045948028564, \"min\": 24320.045948028564}}, \"EndTime\": 1600223539.456446, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223515.136122}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:19 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.402479351 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:19 INFO 140162782930752] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:19 INFO 140162782930752] #quality_metric: host=algo-1, epoch=101, train loss <loss>=-1.91487579346\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:22 INFO 140162782930752] Epoch[102] Batch[0] avg_epoch_loss=-1.880082\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:22 INFO 140162782930752] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=-1.88008220379\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:34 INFO 140162782930752] Epoch[102] Batch[5] avg_epoch_loss=-1.911073\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=-1.91107317118\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:34 INFO 140162782930752] Epoch[102] Batch [5]#011Speed: 87.77 samples/sec#011loss=-1.911073\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:43 INFO 140162782930752] processed a total of 2056 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24155.69281578064, \"sum\": 24155.69281578064, \"min\": 24155.69281578064}}, \"EndTime\": 1600223563.612509, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223539.456508}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:43 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.1141345527 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:43 INFO 140162782930752] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:43 INFO 140162782930752] #quality_metric: host=algo-1, epoch=102, train loss <loss>=-1.91430376493\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:46 INFO 140162782930752] Epoch[103] Batch[0] avg_epoch_loss=-1.872239\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:46 INFO 140162782930752] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=-1.87223889278\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:58 INFO 140162782930752] Epoch[103] Batch[5] avg_epoch_loss=-1.898576\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:58 INFO 140162782930752] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=-1.8985763452\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:32:58 INFO 140162782930752] Epoch[103] Batch [5]#011Speed: 87.36 samples/sec#011loss=-1.898576\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:10 INFO 140162782930752] Epoch[103] Batch[10] avg_epoch_loss=-1.894745\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:10 INFO 140162782930752] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=-1.89014836825\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:10 INFO 140162782930752] Epoch[103] Batch [10]#011Speed: 86.59 samples/sec#011loss=-1.890148\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:10 INFO 140162782930752] processed a total of 2146 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26703.010082244873, \"sum\": 26703.010082244873, \"min\": 26703.010082244873}}, \"EndTime\": 1600223590.315895, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223563.612586}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:10 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.3652097567 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:10 INFO 140162782930752] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:10 INFO 140162782930752] #quality_metric: host=algo-1, epoch=103, train loss <loss>=-1.89474544659\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:13 INFO 140162782930752] Epoch[104] Batch[0] avg_epoch_loss=-1.863344\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=-1.86334433922\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:24 INFO 140162782930752] Epoch[104] Batch[5] avg_epoch_loss=-1.848192\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:24 INFO 140162782930752] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=-1.84819216606\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:24 INFO 140162782930752] Epoch[104] Batch [5]#011Speed: 88.12 samples/sec#011loss=-1.848192\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:36 INFO 140162782930752] Epoch[104] Batch[10] avg_epoch_loss=-1.873487\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=-1.90384010902\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:36 INFO 140162782930752] Epoch[104] Batch [10]#011Speed: 87.93 samples/sec#011loss=-1.903840\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:36 INFO 140162782930752] processed a total of 2237 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26387.595891952515, \"sum\": 26387.595891952515, \"min\": 26387.595891952515}}, \"EndTime\": 1600223616.703864, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223590.315953}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:36 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.774384427 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:36 INFO 140162782930752] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=104, train loss <loss>=-1.87348668559\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:39 INFO 140162782930752] Epoch[105] Batch[0] avg_epoch_loss=-1.912477\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:39 INFO 140162782930752] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=-1.91247734657\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:51 INFO 140162782930752] Epoch[105] Batch[5] avg_epoch_loss=-1.912069\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=-1.91206929623\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:33:51 INFO 140162782930752] Epoch[105] Batch [5]#011Speed: 88.08 samples/sec#011loss=-1.912069\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:00 INFO 140162782930752] processed a total of 2045 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24060.474157333374, \"sum\": 24060.474157333374, \"min\": 24060.474157333374}}, \"EndTime\": 1600223640.76469, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223616.703924}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:00 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.993702975 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:00 INFO 140162782930752] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=105, train loss <loss>=-1.91433660067\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:03 INFO 140162782930752] Epoch[106] Batch[0] avg_epoch_loss=-1.925612\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:03 INFO 140162782930752] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=-1.92561164269\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:15 INFO 140162782930752] Epoch[106] Batch[5] avg_epoch_loss=-1.906283\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:15 INFO 140162782930752] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=-1.90628264501\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:15 INFO 140162782930752] Epoch[106] Batch [5]#011Speed: 87.69 samples/sec#011loss=-1.906283\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:24 INFO 140162782930752] processed a total of 1984 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24144.611120224, \"sum\": 24144.611120224, \"min\": 24144.611120224}}, \"EndTime\": 1600223664.909687, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223640.764795}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:24 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=82.1710898347 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:24 INFO 140162782930752] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:24 INFO 140162782930752] #quality_metric: host=algo-1, epoch=106, train loss <loss>=-1.91263511364\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:27 INFO 140162782930752] Epoch[107] Batch[0] avg_epoch_loss=-1.888410\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=-1.88840998136\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:39 INFO 140162782930752] Epoch[107] Batch[5] avg_epoch_loss=-1.875887\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:39 INFO 140162782930752] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=-1.87588669704\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:39 INFO 140162782930752] Epoch[107] Batch [5]#011Speed: 87.40 samples/sec#011loss=-1.875887\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:51 INFO 140162782930752] Epoch[107] Batch[10] avg_epoch_loss=-1.866410\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=-1.85503765987\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:51 INFO 140162782930752] Epoch[107] Batch [10]#011Speed: 86.99 samples/sec#011loss=-1.855038\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:51 INFO 140162782930752] processed a total of 2098 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26628.57699394226, \"sum\": 26628.57699394226, \"min\": 26628.57699394226}}, \"EndTime\": 1600223691.538668, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223664.909793}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:51 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.7872945167 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:51 INFO 140162782930752] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=107, train loss <loss>=-1.86640986196\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:54 INFO 140162782930752] Epoch[108] Batch[0] avg_epoch_loss=-1.882844\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:34:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=-1.88284375117\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:06 INFO 140162782930752] Epoch[108] Batch[5] avg_epoch_loss=-1.877550\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:06 INFO 140162782930752] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=-1.87755012512\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:06 INFO 140162782930752] Epoch[108] Batch [5]#011Speed: 86.91 samples/sec#011loss=-1.877550\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:18 INFO 140162782930752] Epoch[108] Batch[10] avg_epoch_loss=-1.892048\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=-1.9094460414\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:18 INFO 140162782930752] Epoch[108] Batch [10]#011Speed: 87.28 samples/sec#011loss=-1.909446\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:18 INFO 140162782930752] processed a total of 2102 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26624.096870422363, \"sum\": 26624.096870422363, \"min\": 26624.096870422363}}, \"EndTime\": 1600223718.163069, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223691.538723}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:18 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.9507704357 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:18 INFO 140162782930752] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=108, train loss <loss>=-1.89204826889\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:20 INFO 140162782930752] Epoch[109] Batch[0] avg_epoch_loss=-1.900536\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:20 INFO 140162782930752] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=-1.90053573022\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:32 INFO 140162782930752] Epoch[109] Batch[5] avg_epoch_loss=-1.892638\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:32 INFO 140162782930752] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=-1.89263791304\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:32 INFO 140162782930752] Epoch[109] Batch [5]#011Speed: 87.10 samples/sec#011loss=-1.892638\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:44 INFO 140162782930752] Epoch[109] Batch[10] avg_epoch_loss=-1.909102\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:44 INFO 140162782930752] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=-1.92885962266\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:44 INFO 140162782930752] Epoch[109] Batch [10]#011Speed: 87.64 samples/sec#011loss=-1.928860\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:44 INFO 140162782930752] processed a total of 2087 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26551.968812942505, \"sum\": 26551.968812942505, \"min\": 26551.968812942505}}, \"EndTime\": 1600223744.715327, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223718.163131}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:44 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.6003196088 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:44 INFO 140162782930752] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:44 INFO 140162782930752] #quality_metric: host=algo-1, epoch=109, train loss <loss>=-1.90910232651\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:47 INFO 140162782930752] Epoch[110] Batch[0] avg_epoch_loss=-1.764670\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=-1.76466956505\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:59 INFO 140162782930752] Epoch[110] Batch[5] avg_epoch_loss=-1.634104\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:59 INFO 140162782930752] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=-1.63410367721\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:35:59 INFO 140162782930752] Epoch[110] Batch [5]#011Speed: 87.63 samples/sec#011loss=-1.634104\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:11 INFO 140162782930752] Epoch[110] Batch[10] avg_epoch_loss=-1.695081\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=-1.76825353182\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:11 INFO 140162782930752] Epoch[110] Batch [10]#011Speed: 87.43 samples/sec#011loss=-1.768254\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:11 INFO 140162782930752] processed a total of 2128 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26544.32988166809, \"sum\": 26544.32988166809, \"min\": 26544.32988166809}}, \"EndTime\": 1600223771.259946, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223744.715387}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:11 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.1675230075 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:11 INFO 140162782930752] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=110, train loss <loss>=-1.69508088385\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:14 INFO 140162782930752] Epoch[111] Batch[0] avg_epoch_loss=-1.322459\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:14 INFO 140162782930752] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=-1.32245944096\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:25 INFO 140162782930752] Epoch[111] Batch[5] avg_epoch_loss=-1.608187\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:25 INFO 140162782930752] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=-1.60818740649\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:25 INFO 140162782930752] Epoch[111] Batch [5]#011Speed: 87.77 samples/sec#011loss=-1.608187\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:37 INFO 140162782930752] Epoch[111] Batch[10] avg_epoch_loss=-1.693581\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:37 INFO 140162782930752] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=-1.79605360765\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:37 INFO 140162782930752] Epoch[111] Batch [10]#011Speed: 87.42 samples/sec#011loss=-1.796054\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:37 INFO 140162782930752] processed a total of 2159 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26522.690057754517, \"sum\": 26522.690057754517, \"min\": 26522.690057754517}}, \"EndTime\": 1600223797.782976, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223771.260005}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:37 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.4017388946 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:37 INFO 140162782930752] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:37 INFO 140162782930752] #quality_metric: host=algo-1, epoch=111, train loss <loss>=-1.69358113429\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:40 INFO 140162782930752] Epoch[112] Batch[0] avg_epoch_loss=-1.462214\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:40 INFO 140162782930752] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=-1.46221410311\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:52 INFO 140162782930752] Epoch[112] Batch[5] avg_epoch_loss=-1.666554\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:52 INFO 140162782930752] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=-1.66655408419\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:36:52 INFO 140162782930752] Epoch[112] Batch [5]#011Speed: 87.81 samples/sec#011loss=-1.666554\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:04 INFO 140162782930752] Epoch[112] Batch[10] avg_epoch_loss=-1.735236\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:04 INFO 140162782930752] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=-1.81765336257\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:04 INFO 140162782930752] Epoch[112] Batch [10]#011Speed: 87.16 samples/sec#011loss=-1.817653\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:04 INFO 140162782930752] processed a total of 2105 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26566.200971603394, \"sum\": 26566.200971603394, \"min\": 26566.200971603394}}, \"EndTime\": 1600223824.349512, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223797.783033}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:04 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.2357592617 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:04 INFO 140162782930752] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:04 INFO 140162782930752] #quality_metric: host=algo-1, epoch=112, train loss <loss>=-1.73523557436\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:07 INFO 140162782930752] Epoch[113] Batch[0] avg_epoch_loss=-1.810174\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=-1.81017391498\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:18 INFO 140162782930752] Epoch[113] Batch[5] avg_epoch_loss=-1.740965\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=-1.74096510961\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:18 INFO 140162782930752] Epoch[113] Batch [5]#011Speed: 87.57 samples/sec#011loss=-1.740965\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:28 INFO 140162782930752] processed a total of 2078 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24125.02694129944, \"sum\": 24125.02694129944, \"min\": 24125.02694129944}}, \"EndTime\": 1600223848.474831, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223824.349573}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:28 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=86.1342936652 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:28 INFO 140162782930752] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:28 INFO 140162782930752] #quality_metric: host=algo-1, epoch=113, train loss <loss>=-1.76391575153\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:31 INFO 140162782930752] Epoch[114] Batch[0] avg_epoch_loss=-1.810548\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:31 INFO 140162782930752] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=-1.81054848891\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:43 INFO 140162782930752] Epoch[114] Batch[5] avg_epoch_loss=-1.840529\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:43 INFO 140162782930752] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=-1.84052861043\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:43 INFO 140162782930752] Epoch[114] Batch [5]#011Speed: 87.48 samples/sec#011loss=-1.840529\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:54 INFO 140162782930752] Epoch[114] Batch[10] avg_epoch_loss=-1.851845\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=-1.86542560871\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:54 INFO 140162782930752] Epoch[114] Batch [10]#011Speed: 87.73 samples/sec#011loss=-1.865426\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:54 INFO 140162782930752] processed a total of 2164 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26491.220951080322, \"sum\": 26491.220951080322, \"min\": 26491.220951080322}}, \"EndTime\": 1600223874.966372, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223848.474893}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:54 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.6871796532 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:54 INFO 140162782930752] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=114, train loss <loss>=-1.85184542783\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:57 INFO 140162782930752] Epoch[115] Batch[0] avg_epoch_loss=-1.903126\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:37:57 INFO 140162782930752] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=-1.90312605638\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:09 INFO 140162782930752] Epoch[115] Batch[5] avg_epoch_loss=-1.886331\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=-1.88633084909\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:09 INFO 140162782930752] Epoch[115] Batch [5]#011Speed: 87.10 samples/sec#011loss=-1.886331\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:19 INFO 140162782930752] processed a total of 2073 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24191.181898117065, \"sum\": 24191.181898117065, \"min\": 24191.181898117065}}, \"EndTime\": 1600223899.157927, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223874.96643}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:19 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.6920416377 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:19 INFO 140162782930752] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:19 INFO 140162782930752] #quality_metric: host=algo-1, epoch=115, train loss <loss>=-1.88607160128\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:21 INFO 140162782930752] Epoch[116] Batch[0] avg_epoch_loss=-1.884757\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:21 INFO 140162782930752] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=-1.88475740873\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:33 INFO 140162782930752] Epoch[116] Batch[5] avg_epoch_loss=-1.890475\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=-1.89047453954\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:33 INFO 140162782930752] Epoch[116] Batch [5]#011Speed: 88.09 samples/sec#011loss=-1.890475\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:45 INFO 140162782930752] Epoch[116] Batch[10] avg_epoch_loss=-1.893319\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:45 INFO 140162782930752] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=-1.89673300523\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:45 INFO 140162782930752] Epoch[116] Batch [10]#011Speed: 87.99 samples/sec#011loss=-1.896733\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:45 INFO 140162782930752] processed a total of 2127 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26364.808082580566, \"sum\": 26364.808082580566, \"min\": 26364.808082580566}}, \"EndTime\": 1600223925.523181, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223899.157991}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:45 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.6754621125 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:45 INFO 140162782930752] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:45 INFO 140162782930752] #quality_metric: host=algo-1, epoch=116, train loss <loss>=-1.89331929667\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:48 INFO 140162782930752] Epoch[117] Batch[0] avg_epoch_loss=-1.909090\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:38:48 INFO 140162782930752] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=-1.90909033555\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:00 INFO 140162782930752] Epoch[117] Batch[5] avg_epoch_loss=-1.896262\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=-1.89626216888\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:00 INFO 140162782930752] Epoch[117] Batch [5]#011Speed: 88.07 samples/sec#011loss=-1.896262\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:09 INFO 140162782930752] processed a total of 2052 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24095.818996429443, \"sum\": 24095.818996429443, \"min\": 24095.818996429443}}, \"EndTime\": 1600223949.619493, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223925.52324}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:09 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.1594966803 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:09 INFO 140162782930752] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=117, train loss <loss>=-1.8989280554\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:12 INFO 140162782930752] Epoch[118] Batch[0] avg_epoch_loss=-1.893902\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:12 INFO 140162782930752] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=-1.89390226511\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:24 INFO 140162782930752] Epoch[118] Batch[5] avg_epoch_loss=-1.901332\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:24 INFO 140162782930752] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=-1.90133160811\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:24 INFO 140162782930752] Epoch[118] Batch [5]#011Speed: 87.42 samples/sec#011loss=-1.901332\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:36 INFO 140162782930752] Epoch[118] Batch[10] avg_epoch_loss=-1.905378\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=-1.91023415786\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:36 INFO 140162782930752] Epoch[118] Batch [10]#011Speed: 87.69 samples/sec#011loss=-1.910234\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:36 INFO 140162782930752] processed a total of 2112 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26516.53289794922, \"sum\": 26516.53289794922, \"min\": 26516.53289794922}}, \"EndTime\": 1600223976.136409, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223949.619604}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:36 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.6481633885 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:36 INFO 140162782930752] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=118, train loss <loss>=-1.90537822163\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:38 INFO 140162782930752] Epoch[119] Batch[0] avg_epoch_loss=-1.911861\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:38 INFO 140162782930752] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=-1.91186112624\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:50 INFO 140162782930752] Epoch[119] Batch[5] avg_epoch_loss=-1.910395\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:50 INFO 140162782930752] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=-1.91039483975\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:39:50 INFO 140162782930752] Epoch[119] Batch [5]#011Speed: 87.63 samples/sec#011loss=-1.910395\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:00 INFO 140162782930752] processed a total of 2016 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24193.82381439209, \"sum\": 24193.82381439209, \"min\": 24193.82381439209}}, \"EndTime\": 1600224000.330525, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600223976.136469}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:00 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.3266991064 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:00 INFO 140162782930752] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=119, train loss <loss>=-1.9134526913\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:03 INFO 140162782930752] Epoch[120] Batch[0] avg_epoch_loss=-1.904959\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:03 INFO 140162782930752] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=-1.90495916513\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:15 INFO 140162782930752] Epoch[120] Batch[5] avg_epoch_loss=-1.914193\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:15 INFO 140162782930752] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=-1.91419300666\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:15 INFO 140162782930752] Epoch[120] Batch [5]#011Speed: 87.26 samples/sec#011loss=-1.914193\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:26 INFO 140162782930752] Epoch[120] Batch[10] avg_epoch_loss=-1.917970\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=-1.92250225361\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:26 INFO 140162782930752] Epoch[120] Batch [10]#011Speed: 87.59 samples/sec#011loss=-1.922502\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:26 INFO 140162782930752] processed a total of 2088 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26548.7859249115, \"sum\": 26548.7859249115, \"min\": 26548.7859249115}}, \"EndTime\": 1600224026.879735, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224000.330593}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:26 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.6474120435 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:26 INFO 140162782930752] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=120, train loss <loss>=-1.91796993709\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:29 INFO 140162782930752] Epoch[121] Batch[0] avg_epoch_loss=-1.899126\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:29 INFO 140162782930752] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=-1.89912575942\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:41 INFO 140162782930752] Epoch[121] Batch[5] avg_epoch_loss=-1.841630\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:41 INFO 140162782930752] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=-1.84162954184\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:41 INFO 140162782930752] Epoch[121] Batch [5]#011Speed: 87.57 samples/sec#011loss=-1.841630\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:53 INFO 140162782930752] Epoch[121] Batch[10] avg_epoch_loss=-1.843192\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=-1.84506698022\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:53 INFO 140162782930752] Epoch[121] Batch [10]#011Speed: 87.92 samples/sec#011loss=-1.845067\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:53 INFO 140162782930752] processed a total of 2148 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26485.51106452942, \"sum\": 26485.51106452942, \"min\": 26485.51106452942}}, \"EndTime\": 1600224053.365537, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224026.879793}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:53 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.1006524184 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:53 INFO 140162782930752] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=121, train loss <loss>=-1.84319201383\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:56 INFO 140162782930752] Epoch[122] Batch[0] avg_epoch_loss=-1.875275\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:40:56 INFO 140162782930752] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=-1.8752746582\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:07 INFO 140162782930752] Epoch[122] Batch[5] avg_epoch_loss=-1.862934\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=-1.86293423481\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:07 INFO 140162782930752] Epoch[122] Batch [5]#011Speed: 87.68 samples/sec#011loss=-1.862934\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:17 INFO 140162782930752] processed a total of 2012 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24160.64476966858, \"sum\": 24160.64476966858, \"min\": 24160.64476966858}}, \"EndTime\": 1600224077.526585, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224053.365601}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:17 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.275608533 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:17 INFO 140162782930752] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:17 INFO 140162782930752] #quality_metric: host=algo-1, epoch=122, train loss <loss>=-1.8535679157\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:20 INFO 140162782930752] Epoch[123] Batch[0] avg_epoch_loss=-1.864225\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:20 INFO 140162782930752] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=-1.86422494742\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:32 INFO 140162782930752] Epoch[123] Batch[5] avg_epoch_loss=-1.869828\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:32 INFO 140162782930752] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=-1.86982778402\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:32 INFO 140162782930752] Epoch[123] Batch [5]#011Speed: 87.85 samples/sec#011loss=-1.869828\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:41 INFO 140162782930752] processed a total of 2065 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24151.592016220093, \"sum\": 24151.592016220093, \"min\": 24151.592016220093}}, \"EndTime\": 1600224101.678502, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224077.526645}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:41 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.5013018625 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:41 INFO 140162782930752] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:41 INFO 140162782930752] #quality_metric: host=algo-1, epoch=123, train loss <loss>=-1.87274442819\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:44 INFO 140162782930752] Epoch[124] Batch[0] avg_epoch_loss=-1.903391\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:44 INFO 140162782930752] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=-1.9033908844\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:56 INFO 140162782930752] Epoch[124] Batch[5] avg_epoch_loss=-1.904151\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:56 INFO 140162782930752] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=-1.90415130517\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:41:56 INFO 140162782930752] Epoch[124] Batch [5]#011Speed: 87.57 samples/sec#011loss=-1.904151\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:08 INFO 140162782930752] Epoch[124] Batch[10] avg_epoch_loss=-1.903412\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:08 INFO 140162782930752] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=-1.90252497746\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:08 INFO 140162782930752] Epoch[124] Batch [10]#011Speed: 87.05 samples/sec#011loss=-1.902525\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:08 INFO 140162782930752] processed a total of 2157 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26560.662984848022, \"sum\": 26560.662984848022, \"min\": 26560.662984848022}}, \"EndTime\": 1600224128.239535, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224101.678563}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:08 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.210071477 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:08 INFO 140162782930752] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:08 INFO 140162782930752] #quality_metric: host=algo-1, epoch=124, train loss <loss>=-1.90341206531\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:11 INFO 140162782930752] Epoch[125] Batch[0] avg_epoch_loss=-1.893064\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=-1.89306376531\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:22 INFO 140162782930752] Epoch[125] Batch[5] avg_epoch_loss=-1.896119\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:22 INFO 140162782930752] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=-1.89611899547\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:22 INFO 140162782930752] Epoch[125] Batch [5]#011Speed: 87.87 samples/sec#011loss=-1.896119\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:34 INFO 140162782930752] Epoch[125] Batch[10] avg_epoch_loss=-1.899498\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=-1.90355303838\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:34 INFO 140162782930752] Epoch[125] Batch [10]#011Speed: 87.70 samples/sec#011loss=-1.903553\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:34 INFO 140162782930752] processed a total of 2216 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26497.55597114563, \"sum\": 26497.55597114563, \"min\": 26497.55597114563}}, \"EndTime\": 1600224154.737398, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224128.239588}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:34 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.630095674 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:34 INFO 140162782930752] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=125, train loss <loss>=-1.89949810588\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:37 INFO 140162782930752] Epoch[126] Batch[0] avg_epoch_loss=-1.919175\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:37 INFO 140162782930752] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=-1.91917492793\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:49 INFO 140162782930752] Epoch[126] Batch[5] avg_epoch_loss=-1.915004\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:49 INFO 140162782930752] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=-1.9150037521\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:49 INFO 140162782930752] Epoch[126] Batch [5]#011Speed: 87.65 samples/sec#011loss=-1.915004\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:58 INFO 140162782930752] processed a total of 2045 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24143.568992614746, \"sum\": 24143.568992614746, \"min\": 24143.568992614746}}, \"EndTime\": 1600224178.881257, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224154.737454}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:58 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.7012481255 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:58 INFO 140162782930752] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:42:58 INFO 140162782930752] #quality_metric: host=algo-1, epoch=126, train loss <loss>=-1.91535789783\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:01 INFO 140162782930752] Epoch[127] Batch[0] avg_epoch_loss=-1.893319\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:01 INFO 140162782930752] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=-1.89331876315\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:13 INFO 140162782930752] Epoch[127] Batch[5] avg_epoch_loss=-1.906315\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=-1.90631546118\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:13 INFO 140162782930752] Epoch[127] Batch [5]#011Speed: 87.67 samples/sec#011loss=-1.906315\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:23 INFO 140162782930752] processed a total of 2059 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24233.006954193115, \"sum\": 24233.006954193115, \"min\": 24233.006954193115}}, \"EndTime\": 1600224203.114729, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224178.881323}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:23 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.9663635569 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:23 INFO 140162782930752] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:23 INFO 140162782930752] #quality_metric: host=algo-1, epoch=127, train loss <loss>=-1.87459096175\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:25 INFO 140162782930752] Epoch[128] Batch[0] avg_epoch_loss=-1.919176\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:25 INFO 140162782930752] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=-1.91917580825\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:37 INFO 140162782930752] Epoch[128] Batch[5] avg_epoch_loss=-1.918872\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:37 INFO 140162782930752] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=-1.91887163505\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:37 INFO 140162782930752] Epoch[128] Batch [5]#011Speed: 88.20 samples/sec#011loss=-1.918872\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:47 INFO 140162782930752] processed a total of 2025 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23989.750862121582, \"sum\": 23989.750862121582, \"min\": 23989.750862121582}}, \"EndTime\": 1600224227.1049, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224203.114808}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:47 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.4107161525 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:47 INFO 140162782930752] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=128, train loss <loss>=-1.90489779252\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:49 INFO 140162782930752] Epoch[129] Batch[0] avg_epoch_loss=-1.913919\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:43:49 INFO 140162782930752] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=-1.9139190087\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:01 INFO 140162782930752] Epoch[129] Batch[5] avg_epoch_loss=-1.905762\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:01 INFO 140162782930752] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=-1.90576154758\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:01 INFO 140162782930752] Epoch[129] Batch [5]#011Speed: 88.12 samples/sec#011loss=-1.905762\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:13 INFO 140162782930752] Epoch[129] Batch[10] avg_epoch_loss=-1.902012\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=-1.89751208379\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:13 INFO 140162782930752] Epoch[129] Batch [10]#011Speed: 87.94 samples/sec#011loss=-1.897512\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:13 INFO 140162782930752] processed a total of 2102 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26364.89701271057, \"sum\": 26364.89701271057, \"min\": 26364.89701271057}}, \"EndTime\": 1600224253.470179, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224227.104964}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:13 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.7269712097 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:13 INFO 140162782930752] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=129, train loss <loss>=-1.90201179131\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:16 INFO 140162782930752] Epoch[130] Batch[0] avg_epoch_loss=-1.920694\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=-1.9206943512\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:28 INFO 140162782930752] Epoch[130] Batch[5] avg_epoch_loss=-1.909756\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:28 INFO 140162782930752] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=-1.90975646484\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:28 INFO 140162782930752] Epoch[130] Batch [5]#011Speed: 88.01 samples/sec#011loss=-1.909756\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:39 INFO 140162782930752] Epoch[130] Batch[10] avg_epoch_loss=-1.893289\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:39 INFO 140162782930752] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=-1.87352787898\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:39 INFO 140162782930752] Epoch[130] Batch [10]#011Speed: 87.75 samples/sec#011loss=-1.873528\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:39 INFO 140162782930752] processed a total of 2097 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26393.12195777893, \"sum\": 26393.12195777893, \"min\": 26393.12195777893}}, \"EndTime\": 1600224279.863672, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224253.470237}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:39 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.452165697 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:39 INFO 140162782930752] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:39 INFO 140162782930752] #quality_metric: host=algo-1, epoch=130, train loss <loss>=-1.89328892581\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:42 INFO 140162782930752] Epoch[131] Batch[0] avg_epoch_loss=-1.872971\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:42 INFO 140162782930752] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=-1.87297102121\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:54 INFO 140162782930752] Epoch[131] Batch[5] avg_epoch_loss=-1.866522\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=-1.86652168861\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:44:54 INFO 140162782930752] Epoch[131] Batch [5]#011Speed: 87.16 samples/sec#011loss=-1.866522\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:06 INFO 140162782930752] Epoch[131] Batch[10] avg_epoch_loss=-1.869833\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:06 INFO 140162782930752] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=-1.8738055596\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:06 INFO 140162782930752] Epoch[131] Batch [10]#011Speed: 87.53 samples/sec#011loss=-1.873806\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:06 INFO 140162782930752] processed a total of 2164 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26607.059001922607, \"sum\": 26607.059001922607, \"min\": 26607.059001922607}}, \"EndTime\": 1600224306.471052, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224279.863762}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:06 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.3315405008 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:06 INFO 140162782930752] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:06 INFO 140162782930752] #quality_metric: host=algo-1, epoch=131, train loss <loss>=-1.86983253906\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:09 INFO 140162782930752] Epoch[132] Batch[0] avg_epoch_loss=-1.868252\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=-1.86825209398\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:21 INFO 140162782930752] Epoch[132] Batch[5] avg_epoch_loss=-1.873880\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:21 INFO 140162782930752] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=-1.87387950604\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:21 INFO 140162782930752] Epoch[132] Batch [5]#011Speed: 87.58 samples/sec#011loss=-1.873880\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:30 INFO 140162782930752] processed a total of 2076 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24110.705852508545, \"sum\": 24110.705852508545, \"min\": 24110.705852508545}}, \"EndTime\": 1600224330.582043, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224306.47111}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:30 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=86.1023435392 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:30 INFO 140162782930752] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:30 INFO 140162782930752] #quality_metric: host=algo-1, epoch=132, train loss <loss>=-1.88186145196\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:33 INFO 140162782930752] Epoch[133] Batch[0] avg_epoch_loss=-1.799339\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=-1.79933944115\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:45 INFO 140162782930752] Epoch[133] Batch[5] avg_epoch_loss=-1.836030\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:45 INFO 140162782930752] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=-1.83602985969\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:45 INFO 140162782930752] Epoch[133] Batch [5]#011Speed: 87.65 samples/sec#011loss=-1.836030\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:57 INFO 140162782930752] Epoch[133] Batch[10] avg_epoch_loss=-1.854062\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:57 INFO 140162782930752] #quality_metric: host=algo-1, epoch=133, batch=10 train loss <loss>=-1.87570040776\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:57 INFO 140162782930752] Epoch[133] Batch [10]#011Speed: 87.18 samples/sec#011loss=-1.875700\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:57 INFO 140162782930752] processed a total of 2093 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26554.052114486694, \"sum\": 26554.052114486694, \"min\": 26554.052114486694}}, \"EndTime\": 1600224357.136491, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224330.582149}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:57 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.8200951902 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:57 INFO 140162782930752] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:57 INFO 140162782930752] #quality_metric: host=algo-1, epoch=133, train loss <loss>=-1.854061927\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:59 INFO 140162782930752] Epoch[134] Batch[0] avg_epoch_loss=-1.915226\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:45:59 INFO 140162782930752] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=-1.9152262761\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:11 INFO 140162782930752] Epoch[134] Batch[5] avg_epoch_loss=-1.913849\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=-1.91384909703\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:11 INFO 140162782930752] Epoch[134] Batch [5]#011Speed: 87.21 samples/sec#011loss=-1.913849\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:21 INFO 140162782930752] processed a total of 2059 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24157.630920410156, \"sum\": 24157.630920410156, \"min\": 24157.630920410156}}, \"EndTime\": 1600224381.294477, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224357.136548}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:21 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.2315672949 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:21 INFO 140162782930752] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:21 INFO 140162782930752] #quality_metric: host=algo-1, epoch=134, train loss <loss>=-1.89662538675\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:24 INFO 140162782930752] Epoch[135] Batch[0] avg_epoch_loss=-1.876438\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:24 INFO 140162782930752] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=-1.87643843431\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:35 INFO 140162782930752] Epoch[135] Batch[5] avg_epoch_loss=-1.875142\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:35 INFO 140162782930752] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=-1.87514182849\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:35 INFO 140162782930752] Epoch[135] Batch [5]#011Speed: 87.76 samples/sec#011loss=-1.875142\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:47 INFO 140162782930752] Epoch[135] Batch[10] avg_epoch_loss=-1.890493\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=-1.90891477145\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:47 INFO 140162782930752] Epoch[135] Batch [10]#011Speed: 87.23 samples/sec#011loss=-1.908915\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:47 INFO 140162782930752] processed a total of 2146 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26548.985958099365, \"sum\": 26548.985958099365, \"min\": 26548.985958099365}}, \"EndTime\": 1600224407.843882, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224381.294534}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:47 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.8314504477 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:47 INFO 140162782930752] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=135, train loss <loss>=-1.8904931662\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:50 INFO 140162782930752] Epoch[136] Batch[0] avg_epoch_loss=-1.883537\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:46:50 INFO 140162782930752] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=-1.8835367056\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:02 INFO 140162782930752] Epoch[136] Batch[5] avg_epoch_loss=-1.770822\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:02 INFO 140162782930752] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=-1.77082181588\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:02 INFO 140162782930752] Epoch[136] Batch [5]#011Speed: 87.21 samples/sec#011loss=-1.770822\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:12 INFO 140162782930752] processed a total of 2060 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24298.694133758545, \"sum\": 24298.694133758545, \"min\": 24298.694133758545}}, \"EndTime\": 1600224432.142895, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224407.843941}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:12 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.7779223428 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:12 INFO 140162782930752] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:12 INFO 140162782930752] #quality_metric: host=algo-1, epoch=136, train loss <loss>=-1.79000888238\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:14 INFO 140162782930752] Epoch[137] Batch[0] avg_epoch_loss=-1.679762\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:14 INFO 140162782930752] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=-1.67976159316\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:26 INFO 140162782930752] Epoch[137] Batch[5] avg_epoch_loss=-1.822643\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=-1.82264320667\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:26 INFO 140162782930752] Epoch[137] Batch [5]#011Speed: 87.79 samples/sec#011loss=-1.822643\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:36 INFO 140162782930752] processed a total of 2019 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24121.6299533844, \"sum\": 24121.6299533844, \"min\": 24121.6299533844}}, \"EndTime\": 1600224456.264912, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224432.142955}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:36 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.7000031609 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:36 INFO 140162782930752] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=137, train loss <loss>=-1.83752168509\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:39 INFO 140162782930752] Epoch[138] Batch[0] avg_epoch_loss=-1.908361\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:39 INFO 140162782930752] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=-1.90836128822\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:50 INFO 140162782930752] Epoch[138] Batch[5] avg_epoch_loss=-1.890011\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:50 INFO 140162782930752] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=-1.89001122499\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:47:50 INFO 140162782930752] Epoch[138] Batch [5]#011Speed: 87.63 samples/sec#011loss=-1.890011\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:02 INFO 140162782930752] Epoch[138] Batch[10] avg_epoch_loss=-1.887190\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:02 INFO 140162782930752] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=-1.8838049962\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:02 INFO 140162782930752] Epoch[138] Batch [10]#011Speed: 87.65 samples/sec#011loss=-1.883805\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:02 INFO 140162782930752] processed a total of 2166 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26488.54899406433, \"sum\": 26488.54899406433, \"min\": 26488.54899406433}}, \"EndTime\": 1600224482.754057, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224456.265099}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:02 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.7709052734 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:02 INFO 140162782930752] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:02 INFO 140162782930752] #quality_metric: host=algo-1, epoch=138, train loss <loss>=-1.8871902119\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:05 INFO 140162782930752] Epoch[139] Batch[0] avg_epoch_loss=-1.902896\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:05 INFO 140162782930752] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=-1.90289614751\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:17 INFO 140162782930752] Epoch[139] Batch[5] avg_epoch_loss=-1.888304\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:17 INFO 140162782930752] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=-1.88830392789\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:17 INFO 140162782930752] Epoch[139] Batch [5]#011Speed: 87.36 samples/sec#011loss=-1.888304\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:26 INFO 140162782930752] processed a total of 2073 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24129.335165023804, \"sum\": 24129.335165023804, \"min\": 24129.335165023804}}, \"EndTime\": 1600224506.883741, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224482.754116}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:26 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.9116716597 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:26 INFO 140162782930752] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=139, train loss <loss>=-1.89414992699\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:29 INFO 140162782930752] Epoch[140] Batch[0] avg_epoch_loss=-1.882298\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:29 INFO 140162782930752] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=-1.88229751587\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:41 INFO 140162782930752] Epoch[140] Batch[5] avg_epoch_loss=-1.895985\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:41 INFO 140162782930752] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=-1.89598528544\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:41 INFO 140162782930752] Epoch[140] Batch [5]#011Speed: 88.24 samples/sec#011loss=-1.895985\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:50 INFO 140162782930752] processed a total of 2067 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23999.047994613647, \"sum\": 23999.047994613647, \"min\": 23999.047994613647}}, \"EndTime\": 1600224530.883212, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224506.883808}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:50 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=86.1280605005 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:50 INFO 140162782930752] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:50 INFO 140162782930752] #quality_metric: host=algo-1, epoch=140, train loss <loss>=-1.90022924863\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:53 INFO 140162782930752] Epoch[141] Batch[0] avg_epoch_loss=-1.926277\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:48:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=-1.92627686721\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:05 INFO 140162782930752] Epoch[141] Batch[5] avg_epoch_loss=-1.918274\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:05 INFO 140162782930752] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=-1.91827439039\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:05 INFO 140162782930752] Epoch[141] Batch [5]#011Speed: 88.19 samples/sec#011loss=-1.918274\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:14 INFO 140162782930752] processed a total of 2071 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24022.418975830078, \"sum\": 24022.418975830078, \"min\": 24022.418975830078}}, \"EndTime\": 1600224554.906077, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224530.88328}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:14 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=86.2107506004 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:14 INFO 140162782930752] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:14 INFO 140162782930752] #quality_metric: host=algo-1, epoch=141, train loss <loss>=-1.91767133566\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:17 INFO 140162782930752] Epoch[142] Batch[0] avg_epoch_loss=-1.915079\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:17 INFO 140162782930752] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=-1.91507882338\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:29 INFO 140162782930752] Epoch[142] Batch[5] avg_epoch_loss=-1.920762\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:29 INFO 140162782930752] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=-1.92076162192\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:29 INFO 140162782930752] Epoch[142] Batch [5]#011Speed: 87.84 samples/sec#011loss=-1.920762\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:38 INFO 140162782930752] processed a total of 2040 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24052.59108543396, \"sum\": 24052.59108543396, \"min\": 24052.59108543396}}, \"EndTime\": 1600224578.95913, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224554.906153}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:38 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.8138091999 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:38 INFO 140162782930752] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:38 INFO 140162782930752] #quality_metric: host=algo-1, epoch=142, train loss <loss>=-1.9200124007\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:41 INFO 140162782930752] Epoch[143] Batch[0] avg_epoch_loss=-1.923931\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:41 INFO 140162782930752] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=-1.92393082839\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:53 INFO 140162782930752] Epoch[143] Batch[5] avg_epoch_loss=-1.913107\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=-1.91310677162\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:49:53 INFO 140162782930752] Epoch[143] Batch [5]#011Speed: 87.55 samples/sec#011loss=-1.913107\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:03 INFO 140162782930752] processed a total of 2033 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24121.439933776855, \"sum\": 24121.439933776855, \"min\": 24121.439933776855}}, \"EndTime\": 1600224603.081048, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224578.959195}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:03 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.2813258383 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:03 INFO 140162782930752] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:03 INFO 140162782930752] #quality_metric: host=algo-1, epoch=143, train loss <loss>=-1.920038414\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:05 INFO 140162782930752] Epoch[144] Batch[0] avg_epoch_loss=-1.927712\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:05 INFO 140162782930752] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=-1.92771192697\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:17 INFO 140162782930752] Epoch[144] Batch[5] avg_epoch_loss=-1.921832\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:17 INFO 140162782930752] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=-1.92183191348\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:17 INFO 140162782930752] Epoch[144] Batch [5]#011Speed: 87.28 samples/sec#011loss=-1.921832\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:29 INFO 140162782930752] Epoch[144] Batch[10] avg_epoch_loss=-1.919831\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:29 INFO 140162782930752] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=-1.91742926378\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:29 INFO 140162782930752] Epoch[144] Batch [10]#011Speed: 87.57 samples/sec#011loss=-1.917429\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:29 INFO 140162782930752] processed a total of 2095 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26591.474056243896, \"sum\": 26591.474056243896, \"min\": 26591.474056243896}}, \"EndTime\": 1600224629.672935, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224603.081154}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:29 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.7843662128 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:29 INFO 140162782930752] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:29 INFO 140162782930752] #quality_metric: host=algo-1, epoch=144, train loss <loss>=-1.91983070907\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:32 INFO 140162782930752] Epoch[145] Batch[0] avg_epoch_loss=-1.876722\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:32 INFO 140162782930752] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=-1.8767221891\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:44 INFO 140162782930752] Epoch[145] Batch[5] avg_epoch_loss=-1.838968\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:44 INFO 140162782930752] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=-1.83896783682\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:44 INFO 140162782930752] Epoch[145] Batch [5]#011Speed: 87.68 samples/sec#011loss=-1.838968\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:56 INFO 140162782930752] Epoch[145] Batch[10] avg_epoch_loss=-1.834298\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:56 INFO 140162782930752] #quality_metric: host=algo-1, epoch=145, batch=10 train loss <loss>=-1.8286935953\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:56 INFO 140162782930752] Epoch[145] Batch [10]#011Speed: 87.39 samples/sec#011loss=-1.828694\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:56 INFO 140162782930752] processed a total of 2118 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26522.083044052124, \"sum\": 26522.083044052124, \"min\": 26522.083044052124}}, \"EndTime\": 1600224656.195373, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224629.673001}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:56 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.857727446 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:56 INFO 140162782930752] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:56 INFO 140162782930752] #quality_metric: host=algo-1, epoch=145, train loss <loss>=-1.83429772704\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:58 INFO 140162782930752] Epoch[146] Batch[0] avg_epoch_loss=-1.735521\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:50:58 INFO 140162782930752] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=-1.73552116981\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:10 INFO 140162782930752] Epoch[146] Batch[5] avg_epoch_loss=-1.812393\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:10 INFO 140162782930752] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=-1.81239321293\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:10 INFO 140162782930752] Epoch[146] Batch [5]#011Speed: 87.63 samples/sec#011loss=-1.812393\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:20 INFO 140162782930752] processed a total of 1919 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24102.509021759033, \"sum\": 24102.509021759033, \"min\": 24102.509021759033}}, \"EndTime\": 1600224680.298169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224656.195429}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:20 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.6179370639 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:20 INFO 140162782930752] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:20 INFO 140162782930752] #quality_metric: host=algo-1, epoch=146, train loss <loss>=-1.83023847433\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:23 INFO 140162782930752] Epoch[147] Batch[0] avg_epoch_loss=-1.808119\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:23 INFO 140162782930752] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=-1.80811896691\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:34 INFO 140162782930752] Epoch[147] Batch[5] avg_epoch_loss=-1.826245\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=-1.82624538128\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:34 INFO 140162782930752] Epoch[147] Batch [5]#011Speed: 87.93 samples/sec#011loss=-1.826245\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:46 INFO 140162782930752] Epoch[147] Batch[10] avg_epoch_loss=-1.837962\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:46 INFO 140162782930752] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=-1.85202269921\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:46 INFO 140162782930752] Epoch[147] Batch [10]#011Speed: 87.38 samples/sec#011loss=-1.852023\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:46 INFO 140162782930752] processed a total of 2137 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26553.36594581604, \"sum\": 26553.36594581604, \"min\": 26553.36594581604}}, \"EndTime\": 1600224706.85196, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224680.298236}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:46 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.4791877244 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:46 INFO 140162782930752] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:46 INFO 140162782930752] #quality_metric: host=algo-1, epoch=147, train loss <loss>=-1.83796234398\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:49 INFO 140162782930752] Epoch[148] Batch[0] avg_epoch_loss=-1.843712\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:51:49 INFO 140162782930752] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=-1.84371229318\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:01 INFO 140162782930752] Epoch[148] Batch[5] avg_epoch_loss=-1.852407\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:01 INFO 140162782930752] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=-1.85240735763\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:01 INFO 140162782930752] Epoch[148] Batch [5]#011Speed: 86.94 samples/sec#011loss=-1.852407\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:13 INFO 140162782930752] Epoch[148] Batch[10] avg_epoch_loss=-1.850108\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=-1.84734928425\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:13 INFO 140162782930752] Epoch[148] Batch [10]#011Speed: 87.31 samples/sec#011loss=-1.847349\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:13 INFO 140162782930752] processed a total of 2081 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26621.187925338745, \"sum\": 26621.187925338745, \"min\": 26621.187925338745}}, \"EndTime\": 1600224733.473418, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224706.852017}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:13 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.1705695052 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:13 INFO 140162782930752] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=148, train loss <loss>=-1.85010823337\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:16 INFO 140162782930752] Epoch[149] Batch[0] avg_epoch_loss=-1.614606\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=-1.61460641714\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:28 INFO 140162782930752] Epoch[149] Batch[5] avg_epoch_loss=-1.708819\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:28 INFO 140162782930752] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=-1.70881860684\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:28 INFO 140162782930752] Epoch[149] Batch [5]#011Speed: 87.83 samples/sec#011loss=-1.708819\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:37 INFO 140162782930752] processed a total of 2070 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24060.54186820984, \"sum\": 24060.54186820984, \"min\": 24060.54186820984}}, \"EndTime\": 1600224757.534279, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224733.473475}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:37 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=86.0325130652 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:37 INFO 140162782930752] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:37 INFO 140162782930752] #quality_metric: host=algo-1, epoch=149, train loss <loss>=-1.74846866314\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:40 INFO 140162782930752] Epoch[150] Batch[0] avg_epoch_loss=-1.749131\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:40 INFO 140162782930752] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=-1.74913112934\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:52 INFO 140162782930752] Epoch[150] Batch[5] avg_epoch_loss=-1.823191\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:52 INFO 140162782930752] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=-1.82319134932\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:52:52 INFO 140162782930752] Epoch[150] Batch [5]#011Speed: 86.44 samples/sec#011loss=-1.823191\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:01 INFO 140162782930752] processed a total of 2015 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24269.033908843994, \"sum\": 24269.033908843994, \"min\": 24269.033908843994}}, \"EndTime\": 1600224781.803703, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224757.534378}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:01 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.0273097868 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:01 INFO 140162782930752] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:01 INFO 140162782930752] #quality_metric: host=algo-1, epoch=150, train loss <loss>=-1.83632922539\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:04 INFO 140162782930752] Epoch[151] Batch[0] avg_epoch_loss=-1.818711\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:04 INFO 140162782930752] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=-1.81871062059\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:16 INFO 140162782930752] Epoch[151] Batch[5] avg_epoch_loss=-1.873098\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=-1.8730978599\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:16 INFO 140162782930752] Epoch[151] Batch [5]#011Speed: 87.26 samples/sec#011loss=-1.873098\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:25 INFO 140162782930752] processed a total of 2080 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24189.872980117798, \"sum\": 24189.872980117798, \"min\": 24189.872980117798}}, \"EndTime\": 1600224805.994081, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224781.803766}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:25 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.9860655922 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:25 INFO 140162782930752] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:25 INFO 140162782930752] #quality_metric: host=algo-1, epoch=151, train loss <loss>=-1.87995643616\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:28 INFO 140162782930752] Epoch[152] Batch[0] avg_epoch_loss=-1.913092\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:28 INFO 140162782930752] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=-1.91309224642\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:40 INFO 140162782930752] Epoch[152] Batch[5] avg_epoch_loss=-1.896978\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:40 INFO 140162782930752] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=-1.89697823158\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:40 INFO 140162782930752] Epoch[152] Batch [5]#011Speed: 87.93 samples/sec#011loss=-1.896978\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:50 INFO 140162782930752] processed a total of 2068 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24088.791131973267, \"sum\": 24088.791131973267, \"min\": 24088.791131973267}}, \"EndTime\": 1600224830.083254, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224805.994145}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:50 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.8487441927 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:50 INFO 140162782930752] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:50 INFO 140162782930752] #quality_metric: host=algo-1, epoch=152, train loss <loss>=-1.89967215611\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:52 INFO 140162782930752] Epoch[153] Batch[0] avg_epoch_loss=-1.900312\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:53:52 INFO 140162782930752] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=-1.90031183683\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:04 INFO 140162782930752] Epoch[153] Batch[5] avg_epoch_loss=-1.908520\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:04 INFO 140162782930752] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=-1.90852006276\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:04 INFO 140162782930752] Epoch[153] Batch [5]#011Speed: 87.84 samples/sec#011loss=-1.908520\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:16 INFO 140162782930752] Epoch[153] Batch[10] avg_epoch_loss=-1.922958\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=-1.94028417147\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:16 INFO 140162782930752] Epoch[153] Batch [10]#011Speed: 87.87 samples/sec#011loss=-1.940284\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:16 INFO 140162782930752] processed a total of 2081 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26406.858921051025, \"sum\": 26406.858921051025, \"min\": 26406.858921051025}}, \"EndTime\": 1600224856.490499, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224830.083315}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:16 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.8050236641 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:16 INFO 140162782930752] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=153, train loss <loss>=-1.92295829399\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:19 INFO 140162782930752] Epoch[154] Batch[0] avg_epoch_loss=-1.893174\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:19 INFO 140162782930752] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=-1.89317439153\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:31 INFO 140162782930752] Epoch[154] Batch[5] avg_epoch_loss=-1.906689\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:31 INFO 140162782930752] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=-1.90668947269\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:31 INFO 140162782930752] Epoch[154] Batch [5]#011Speed: 87.76 samples/sec#011loss=-1.906689\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:40 INFO 140162782930752] processed a total of 2078 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24164.648056030273, \"sum\": 24164.648056030273, \"min\": 24164.648056030273}}, \"EndTime\": 1600224880.65544, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224856.490558}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:40 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.993030074 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:40 INFO 140162782930752] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:40 INFO 140162782930752] #quality_metric: host=algo-1, epoch=154, train loss <loss>=-1.90988452618\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:43 INFO 140162782930752] Epoch[155] Batch[0] avg_epoch_loss=-1.908110\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:43 INFO 140162782930752] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=-1.90811025179\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:55 INFO 140162782930752] Epoch[155] Batch[5] avg_epoch_loss=-1.917818\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:55 INFO 140162782930752] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=-1.91781809391\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:54:55 INFO 140162782930752] Epoch[155] Batch [5]#011Speed: 87.35 samples/sec#011loss=-1.917818\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:07 INFO 140162782930752] Epoch[155] Batch[10] avg_epoch_loss=-1.918517\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=-1.91935506967\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:07 INFO 140162782930752] Epoch[155] Batch [10]#011Speed: 87.18 samples/sec#011loss=-1.919355\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:07 INFO 140162782930752] processed a total of 2149 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26599.39980506897, \"sum\": 26599.39980506897, \"min\": 26599.39980506897}}, \"EndTime\": 1600224907.255285, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224880.655507}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:07 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.7910076987 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:07 INFO 140162782930752] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=155, train loss <loss>=-1.91851671926\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:10 INFO 140162782930752] Epoch[156] Batch[0] avg_epoch_loss=-1.926520\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:10 INFO 140162782930752] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=-1.9265199808\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:21 INFO 140162782930752] Epoch[156] Batch[5] avg_epoch_loss=-1.915587\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:21 INFO 140162782930752] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=-1.91558725406\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:21 INFO 140162782930752] Epoch[156] Batch [5]#011Speed: 87.12 samples/sec#011loss=-1.915587\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:33 INFO 140162782930752] Epoch[156] Batch[10] avg_epoch_loss=-1.915781\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=-1.91601263193\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:33 INFO 140162782930752] Epoch[156] Batch [10]#011Speed: 87.11 samples/sec#011loss=-1.916013\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:33 INFO 140162782930752] processed a total of 2141 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26650.470972061157, \"sum\": 26650.470972061157, \"min\": 26650.470972061157}}, \"EndTime\": 1600224933.906122, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224907.255347}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:33 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.3360354705 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:33 INFO 140162782930752] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=156, train loss <loss>=-1.91578060764\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:36 INFO 140162782930752] Epoch[157] Batch[0] avg_epoch_loss=-1.915825\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=-1.91582474342\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:48 INFO 140162782930752] Epoch[157] Batch[5] avg_epoch_loss=-1.913556\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:48 INFO 140162782930752] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=-1.91355558542\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:55:48 INFO 140162782930752] Epoch[157] Batch [5]#011Speed: 86.82 samples/sec#011loss=-1.913556\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:00 INFO 140162782930752] Epoch[157] Batch[10] avg_epoch_loss=-1.915643\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=-1.91814818749\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:00 INFO 140162782930752] Epoch[157] Batch [10]#011Speed: 87.61 samples/sec#011loss=-1.918148\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:00 INFO 140162782930752] processed a total of 2178 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26626.574993133545, \"sum\": 26626.574993133545, \"min\": 26626.574993133545}}, \"EndTime\": 1600224960.532981, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224933.90618}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:00 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.7977232833 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:00 INFO 140162782930752] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=157, train loss <loss>=-1.91564313182\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:03 INFO 140162782930752] Epoch[158] Batch[0] avg_epoch_loss=-1.917110\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:03 INFO 140162782930752] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=-1.9171102964\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:15 INFO 140162782930752] Epoch[158] Batch[5] avg_epoch_loss=-1.921267\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:15 INFO 140162782930752] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=-1.92126709376\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:15 INFO 140162782930752] Epoch[158] Batch [5]#011Speed: 87.59 samples/sec#011loss=-1.921267\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:27 INFO 140162782930752] Epoch[158] Batch[10] avg_epoch_loss=-1.879858\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=-1.83016721285\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:27 INFO 140162782930752] Epoch[158] Batch [10]#011Speed: 87.78 samples/sec#011loss=-1.830167\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:27 INFO 140162782930752] processed a total of 2085 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26522.297143936157, \"sum\": 26522.297143936157, \"min\": 26522.297143936157}}, \"EndTime\": 1600224987.055568, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224960.533038}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:27 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.6128541658 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:27 INFO 140162782930752] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=158, train loss <loss>=-1.87985805698\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:29 INFO 140162782930752] Epoch[159] Batch[0] avg_epoch_loss=-1.846118\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:29 INFO 140162782930752] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=-1.84611804669\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:41 INFO 140162782930752] Epoch[159] Batch[5] avg_epoch_loss=-1.856486\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:41 INFO 140162782930752] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=-1.8564855869\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:41 INFO 140162782930752] Epoch[159] Batch [5]#011Speed: 87.39 samples/sec#011loss=-1.856486\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:53 INFO 140162782930752] Epoch[159] Batch[10] avg_epoch_loss=-1.881503\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=-1.91152370159\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:53 INFO 140162782930752] Epoch[159] Batch [10]#011Speed: 87.28 samples/sec#011loss=-1.911524\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:53 INFO 140162782930752] processed a total of 2085 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26610.427141189575, \"sum\": 26610.427141189575, \"min\": 26610.427141189575}}, \"EndTime\": 1600225013.666324, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600224987.055625}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:53 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.3524855037 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:53 INFO 140162782930752] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=159, train loss <loss>=-1.88150291176\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:56 INFO 140162782930752] Epoch[160] Batch[0] avg_epoch_loss=-1.911272\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:56:56 INFO 140162782930752] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=-1.91127234239\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:08 INFO 140162782930752] Epoch[160] Batch[5] avg_epoch_loss=-1.911039\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:08 INFO 140162782930752] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=-1.91103854546\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:08 INFO 140162782930752] Epoch[160] Batch [5]#011Speed: 87.25 samples/sec#011loss=-1.911039\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:20 INFO 140162782930752] Epoch[160] Batch[10] avg_epoch_loss=-1.917307\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:20 INFO 140162782930752] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=-1.92482916025\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:20 INFO 140162782930752] Epoch[160] Batch [10]#011Speed: 86.84 samples/sec#011loss=-1.924829\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:20 INFO 140162782930752] processed a total of 2145 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26640.316009521484, \"sum\": 26640.316009521484, \"min\": 26640.316009521484}}, \"EndTime\": 1600225040.306965, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225013.666384}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:20 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.5168056569 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:20 INFO 140162782930752] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:20 INFO 140162782930752] #quality_metric: host=algo-1, epoch=160, train loss <loss>=-1.91730700673\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:23 INFO 140162782930752] Epoch[161] Batch[0] avg_epoch_loss=-1.917246\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:23 INFO 140162782930752] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=-1.91724601159\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:35 INFO 140162782930752] Epoch[161] Batch[5] avg_epoch_loss=-1.922178\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:35 INFO 140162782930752] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=-1.92217829289\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:35 INFO 140162782930752] Epoch[161] Batch [5]#011Speed: 87.10 samples/sec#011loss=-1.922178\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:46 INFO 140162782930752] Epoch[161] Batch[10] avg_epoch_loss=-1.922289\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:46 INFO 140162782930752] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=-1.92242152874\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:46 INFO 140162782930752] Epoch[161] Batch [10]#011Speed: 87.28 samples/sec#011loss=-1.922422\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:46 INFO 140162782930752] processed a total of 2132 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26615.214109420776, \"sum\": 26615.214109420776, \"min\": 26615.214109420776}}, \"EndTime\": 1600225066.92246, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225040.307023}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:46 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.1043010899 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:46 INFO 140162782930752] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:46 INFO 140162782930752] #quality_metric: host=algo-1, epoch=161, train loss <loss>=-1.92228885464\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:49 INFO 140162782930752] Epoch[162] Batch[0] avg_epoch_loss=-1.910813\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:57:49 INFO 140162782930752] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=-1.91081325824\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:01 INFO 140162782930752] Epoch[162] Batch[5] avg_epoch_loss=-1.921181\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:01 INFO 140162782930752] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=-1.92118065174\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:01 INFO 140162782930752] Epoch[162] Batch [5]#011Speed: 86.59 samples/sec#011loss=-1.921181\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:11 INFO 140162782930752] processed a total of 2050 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24647.541999816895, \"sum\": 24647.541999816895, \"min\": 24647.541999816895}}, \"EndTime\": 1600225091.570336, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225066.92252}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:11 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.1722937521 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:11 INFO 140162782930752] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=162, train loss <loss>=-1.91764671619\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:14 INFO 140162782930752] Epoch[163] Batch[0] avg_epoch_loss=-1.922199\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:14 INFO 140162782930752] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=-1.92219924927\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:26 INFO 140162782930752] Epoch[163] Batch[5] avg_epoch_loss=-1.922004\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=-1.92200440627\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:26 INFO 140162782930752] Epoch[163] Batch [5]#011Speed: 87.01 samples/sec#011loss=-1.922004\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:38 INFO 140162782930752] Epoch[163] Batch[10] avg_epoch_loss=-1.928144\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:38 INFO 140162782930752] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=-1.93551142766\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:38 INFO 140162782930752] Epoch[163] Batch [10]#011Speed: 87.96 samples/sec#011loss=-1.935511\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:38 INFO 140162782930752] processed a total of 2136 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26536.508798599243, \"sum\": 26536.508798599243, \"min\": 26536.508798599243}}, \"EndTime\": 1600225118.107329, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225091.570398}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:38 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.4925994343 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:38 INFO 140162782930752] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:38 INFO 140162782930752] #quality_metric: host=algo-1, epoch=163, train loss <loss>=-1.92814396145\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:40 INFO 140162782930752] Epoch[164] Batch[0] avg_epoch_loss=-1.895990\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:40 INFO 140162782930752] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=-1.89599022498\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:52 INFO 140162782930752] Epoch[164] Batch[5] avg_epoch_loss=-1.874832\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:52 INFO 140162782930752] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=-1.87483207996\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:58:52 INFO 140162782930752] Epoch[164] Batch [5]#011Speed: 87.74 samples/sec#011loss=-1.874832\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:04 INFO 140162782930752] Epoch[164] Batch[10] avg_epoch_loss=-1.874975\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:04 INFO 140162782930752] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=-1.87514751141\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:04 INFO 140162782930752] Epoch[164] Batch [10]#011Speed: 87.92 samples/sec#011loss=-1.875148\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:04 INFO 140162782930752] processed a total of 2104 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26419.247150421143, \"sum\": 26419.247150421143, \"min\": 26419.247150421143}}, \"EndTime\": 1600225144.526897, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225118.10739}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:04 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.6386531197 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:04 INFO 140162782930752] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:04 INFO 140162782930752] #quality_metric: host=algo-1, epoch=164, train loss <loss>=-1.87497545789\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:07 INFO 140162782930752] Epoch[165] Batch[0] avg_epoch_loss=-1.916242\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=-1.91624201261\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:19 INFO 140162782930752] Epoch[165] Batch[5] avg_epoch_loss=-1.882452\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:19 INFO 140162782930752] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=-1.88245188884\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:19 INFO 140162782930752] Epoch[165] Batch [5]#011Speed: 87.66 samples/sec#011loss=-1.882452\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:31 INFO 140162782930752] Epoch[165] Batch[10] avg_epoch_loss=-1.896938\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:31 INFO 140162782930752] #quality_metric: host=algo-1, epoch=165, batch=10 train loss <loss>=-1.9143224276\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:31 INFO 140162782930752] Epoch[165] Batch [10]#011Speed: 87.50 samples/sec#011loss=-1.914322\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:31 INFO 140162782930752] processed a total of 2118 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26490.664958953857, \"sum\": 26490.664958953857, \"min\": 26490.664958953857}}, \"EndTime\": 1600225171.017861, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225144.526956}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:31 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.9523935482 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:31 INFO 140162782930752] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:31 INFO 140162782930752] #quality_metric: host=algo-1, epoch=165, train loss <loss>=-1.89693849737\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:33 INFO 140162782930752] Epoch[166] Batch[0] avg_epoch_loss=-1.835108\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=-1.8351082435\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:45 INFO 140162782930752] Epoch[166] Batch[5] avg_epoch_loss=-1.850452\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:45 INFO 140162782930752] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=-1.85045159169\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:45 INFO 140162782930752] Epoch[166] Batch [5]#011Speed: 87.30 samples/sec#011loss=-1.850452\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:57 INFO 140162782930752] Epoch[166] Batch[10] avg_epoch_loss=-1.857774\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:57 INFO 140162782930752] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=-1.86656009968\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:57 INFO 140162782930752] Epoch[166] Batch [10]#011Speed: 87.83 samples/sec#011loss=-1.866560\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:57 INFO 140162782930752] processed a total of 2086 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26488.665103912354, \"sum\": 26488.665103912354, \"min\": 26488.665103912354}}, \"EndTime\": 1600225197.506883, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225171.017915}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:57 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.7504129678 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:57 INFO 140162782930752] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 02:59:57 INFO 140162782930752] #quality_metric: host=algo-1, epoch=166, train loss <loss>=-1.85777364077\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:00 INFO 140162782930752] Epoch[167] Batch[0] avg_epoch_loss=-1.665298\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=-1.66529787504\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:12 INFO 140162782930752] Epoch[167] Batch[5] avg_epoch_loss=-1.782800\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:12 INFO 140162782930752] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=-1.78279998975\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:12 INFO 140162782930752] Epoch[167] Batch [5]#011Speed: 86.94 samples/sec#011loss=-1.782800\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:21 INFO 140162782930752] processed a total of 2006 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24245.70393562317, \"sum\": 24245.70393562317, \"min\": 24245.70393562317}}, \"EndTime\": 1600225221.752938, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225197.506939}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:21 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=82.7358113562 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:21 INFO 140162782930752] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:21 INFO 140162782930752] #quality_metric: host=algo-1, epoch=167, train loss <loss>=-1.80466993772\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:24 INFO 140162782930752] Epoch[168] Batch[0] avg_epoch_loss=-1.812044\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:24 INFO 140162782930752] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=-1.81204399696\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:36 INFO 140162782930752] Epoch[168] Batch[5] avg_epoch_loss=-1.865228\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=-1.86522767483\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:36 INFO 140162782930752] Epoch[168] Batch [5]#011Speed: 87.48 samples/sec#011loss=-1.865228\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:48 INFO 140162782930752] Epoch[168] Batch[10] avg_epoch_loss=-1.881272\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:48 INFO 140162782930752] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=-1.90052522513\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:48 INFO 140162782930752] Epoch[168] Batch [10]#011Speed: 86.20 samples/sec#011loss=-1.900525\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:48 INFO 140162782930752] processed a total of 2130 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26696.308851242065, \"sum\": 26696.308851242065, \"min\": 26696.308851242065}}, \"EndTime\": 1600225248.449678, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225221.753051}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:48 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.7860508981 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:48 INFO 140162782930752] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:48 INFO 140162782930752] #quality_metric: host=algo-1, epoch=168, train loss <loss>=-1.88127201587\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:51 INFO 140162782930752] Epoch[169] Batch[0] avg_epoch_loss=-1.915205\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:00:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=-1.91520544199\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:03 INFO 140162782930752] Epoch[169] Batch[5] avg_epoch_loss=-1.919176\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:03 INFO 140162782930752] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=-1.91917573489\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:03 INFO 140162782930752] Epoch[169] Batch [5]#011Speed: 87.45 samples/sec#011loss=-1.919176\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:15 INFO 140162782930752] Epoch[169] Batch[10] avg_epoch_loss=-1.914427\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:15 INFO 140162782930752] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=-1.90872808603\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:15 INFO 140162782930752] Epoch[169] Batch [10]#011Speed: 87.23 samples/sec#011loss=-1.908728\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:15 INFO 140162782930752] processed a total of 2175 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26596.654176712036, \"sum\": 26596.654176712036, \"min\": 26596.654176712036}}, \"EndTime\": 1600225275.046697, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225248.449735}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:15 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.776927828 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:15 INFO 140162782930752] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:15 INFO 140162782930752] #quality_metric: host=algo-1, epoch=169, train loss <loss>=-1.91442680359\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:17 INFO 140162782930752] Epoch[170] Batch[0] avg_epoch_loss=-1.918543\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:17 INFO 140162782930752] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=-1.91854286194\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:29 INFO 140162782930752] Epoch[170] Batch[5] avg_epoch_loss=-1.915010\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:29 INFO 140162782930752] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=-1.91500998766\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:29 INFO 140162782930752] Epoch[170] Batch [5]#011Speed: 87.57 samples/sec#011loss=-1.915010\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:39 INFO 140162782930752] processed a total of 2061 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24218.005895614624, \"sum\": 24218.005895614624, \"min\": 24218.005895614624}}, \"EndTime\": 1600225299.265047, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225275.046754}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:39 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.101575773 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:39 INFO 140162782930752] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:39 INFO 140162782930752] #quality_metric: host=algo-1, epoch=170, train loss <loss>=-1.9126784398\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:42 INFO 140162782930752] Epoch[171] Batch[0] avg_epoch_loss=-1.919973\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:42 INFO 140162782930752] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=-1.91997263982\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:53 INFO 140162782930752] Epoch[171] Batch[5] avg_epoch_loss=-1.919979\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=-1.91997933999\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:01:53 INFO 140162782930752] Epoch[171] Batch [5]#011Speed: 87.35 samples/sec#011loss=-1.919979\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:03 INFO 140162782930752] processed a total of 1985 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24223.616123199463, \"sum\": 24223.616123199463, \"min\": 24223.616123199463}}, \"EndTime\": 1600225323.489049, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225299.265126}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:03 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.9445006252 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:03 INFO 140162782930752] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:03 INFO 140162782930752] #quality_metric: host=algo-1, epoch=171, train loss <loss>=-1.91997906612\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:06 INFO 140162782930752] Epoch[172] Batch[0] avg_epoch_loss=-1.910661\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:06 INFO 140162782930752] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=-1.91066052363\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:18 INFO 140162782930752] Epoch[172] Batch[5] avg_epoch_loss=-1.907158\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=-1.90715814248\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:18 INFO 140162782930752] Epoch[172] Batch [5]#011Speed: 87.32 samples/sec#011loss=-1.907158\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:27 INFO 140162782930752] processed a total of 2051 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24223.64616394043, \"sum\": 24223.64616394043, \"min\": 24223.64616394043}}, \"EndTime\": 1600225347.713086, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225323.489114}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:27 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.6690270011 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:27 INFO 140162782930752] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=172, train loss <loss>=-1.91127608373\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:30 INFO 140162782930752] Epoch[173] Batch[0] avg_epoch_loss=-1.935147\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:30 INFO 140162782930752] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=-1.93514691866\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:42 INFO 140162782930752] Epoch[173] Batch[5] avg_epoch_loss=-1.919839\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:42 INFO 140162782930752] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=-1.91983927213\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:42 INFO 140162782930752] Epoch[173] Batch [5]#011Speed: 86.80 samples/sec#011loss=-1.919839\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:54 INFO 140162782930752] Epoch[173] Batch[10] avg_epoch_loss=-1.915115\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=-1.90944618812\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:54 INFO 140162782930752] Epoch[173] Batch [10]#011Speed: 87.50 samples/sec#011loss=-1.909446\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:54 INFO 140162782930752] processed a total of 2148 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26618.577003479004, \"sum\": 26618.577003479004, \"min\": 26618.577003479004}}, \"EndTime\": 1600225374.332105, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225347.713146}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:54 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.6951503185 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:54 INFO 140162782930752] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=173, train loss <loss>=-1.91511514304\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:57 INFO 140162782930752] Epoch[174] Batch[0] avg_epoch_loss=-1.798787\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:02:57 INFO 140162782930752] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=-1.79878660349\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:09 INFO 140162782930752] Epoch[174] Batch[5] avg_epoch_loss=-1.862004\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=-1.86200442681\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:09 INFO 140162782930752] Epoch[174] Batch [5]#011Speed: 86.87 samples/sec#011loss=-1.862004\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:21 INFO 140162782930752] Epoch[174] Batch[10] avg_epoch_loss=-1.882090\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:21 INFO 140162782930752] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=-1.9061932197\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:21 INFO 140162782930752] Epoch[174] Batch [10]#011Speed: 86.96 samples/sec#011loss=-1.906193\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:21 INFO 140162782930752] processed a total of 2140 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26698.863983154297, \"sum\": 26698.863983154297, \"min\": 26698.863983154297}}, \"EndTime\": 1600225401.031305, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225374.332195}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:21 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.1529703861 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:21 INFO 140162782930752] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:21 INFO 140162782930752] #quality_metric: host=algo-1, epoch=174, train loss <loss>=-1.88209024176\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:23 INFO 140162782930752] Epoch[175] Batch[0] avg_epoch_loss=-1.901073\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:23 INFO 140162782930752] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=-1.90107330909\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:35 INFO 140162782930752] Epoch[175] Batch[5] avg_epoch_loss=-1.915163\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:35 INFO 140162782930752] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=-1.9151629179\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:35 INFO 140162782930752] Epoch[175] Batch [5]#011Speed: 87.77 samples/sec#011loss=-1.915163\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:45 INFO 140162782930752] processed a total of 2073 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24196.141004562378, \"sum\": 24196.141004562378, \"min\": 24196.141004562378}}, \"EndTime\": 1600225425.227727, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225401.031362}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:45 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.6745141996 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:45 INFO 140162782930752] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:45 INFO 140162782930752] #quality_metric: host=algo-1, epoch=175, train loss <loss>=-1.91454407619\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:47 INFO 140162782930752] Epoch[176] Batch[0] avg_epoch_loss=-1.924046\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=-1.92404570946\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:59 INFO 140162782930752] Epoch[176] Batch[5] avg_epoch_loss=-1.920321\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:59 INFO 140162782930752] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=-1.92032131782\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:03:59 INFO 140162782930752] Epoch[176] Batch [5]#011Speed: 87.90 samples/sec#011loss=-1.920321\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:11 INFO 140162782930752] Epoch[176] Batch[10] avg_epoch_loss=-1.925243\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=-1.93114926265\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:11 INFO 140162782930752] Epoch[176] Batch [10]#011Speed: 87.86 samples/sec#011loss=-1.931149\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:11 INFO 140162782930752] processed a total of 2106 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26436.622858047485, \"sum\": 26436.622858047485, \"min\": 26436.622858047485}}, \"EndTime\": 1600225451.664854, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225425.227787}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:11 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.6619516774 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:11 INFO 140162782930752] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=176, train loss <loss>=-1.92524311092\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:14 INFO 140162782930752] Epoch[177] Batch[0] avg_epoch_loss=-1.920769\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:14 INFO 140162782930752] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=-1.92076917795\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:26 INFO 140162782930752] Epoch[177] Batch[5] avg_epoch_loss=-1.915391\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=-1.9153908216\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:26 INFO 140162782930752] Epoch[177] Batch [5]#011Speed: 87.94 samples/sec#011loss=-1.915391\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:35 INFO 140162782930752] processed a total of 2015 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24077.17204093933, \"sum\": 24077.17204093933, \"min\": 24077.17204093933}}, \"EndTime\": 1600225475.742308, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225451.664913}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:35 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.6889354492 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:35 INFO 140162782930752] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:35 INFO 140162782930752] #quality_metric: host=algo-1, epoch=177, train loss <loss>=-1.91841094677\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:38 INFO 140162782930752] Epoch[178] Batch[0] avg_epoch_loss=-1.923402\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:38 INFO 140162782930752] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=-1.92340219938\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:50 INFO 140162782930752] Epoch[178] Batch[5] avg_epoch_loss=-1.920726\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:50 INFO 140162782930752] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=-1.92072570018\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:50 INFO 140162782930752] Epoch[178] Batch [5]#011Speed: 87.06 samples/sec#011loss=-1.920726\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:59 INFO 140162782930752] processed a total of 2069 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24241.256952285767, \"sum\": 24241.256952285767, \"min\": 24241.256952285767}}, \"EndTime\": 1600225499.984008, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225475.742367}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:59 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.3500566439 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:59 INFO 140162782930752] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:04:59 INFO 140162782930752] #quality_metric: host=algo-1, epoch=178, train loss <loss>=-1.92480430603\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:02 INFO 140162782930752] Epoch[179] Batch[0] avg_epoch_loss=-1.924114\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:02 INFO 140162782930752] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=-1.92411378714\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:14 INFO 140162782930752] Epoch[179] Batch[5] avg_epoch_loss=-1.928513\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:14 INFO 140162782930752] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=-1.92851257324\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:14 INFO 140162782930752] Epoch[179] Batch [5]#011Speed: 87.49 samples/sec#011loss=-1.928513\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:24 INFO 140162782930752] processed a total of 2075 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24201.841115951538, \"sum\": 24201.841115951538, \"min\": 24201.841115951538}}, \"EndTime\": 1600225524.186236, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225499.984066}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:24 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.7369173359 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:24 INFO 140162782930752] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:24 INFO 140162782930752] #quality_metric: host=algo-1, epoch=179, train loss <loss>=-1.92991940425\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:26 INFO 140162782930752] Epoch[180] Batch[0] avg_epoch_loss=-1.934275\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=-1.9342749669\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:38 INFO 140162782930752] Epoch[180] Batch[5] avg_epoch_loss=-1.931998\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:38 INFO 140162782930752] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=-1.93199815506\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:38 INFO 140162782930752] Epoch[180] Batch [5]#011Speed: 87.02 samples/sec#011loss=-1.931998\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:50 INFO 140162782930752] Epoch[180] Batch[10] avg_epoch_loss=-1.929417\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:50 INFO 140162782930752] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=-1.92631973853\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:50 INFO 140162782930752] Epoch[180] Batch [10]#011Speed: 87.42 samples/sec#011loss=-1.926320\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:50 INFO 140162782930752] processed a total of 2081 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26591.447830200195, \"sum\": 26591.447830200195, \"min\": 26591.447830200195}}, \"EndTime\": 1600225550.778162, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225524.186311}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:50 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.2579874199 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:50 INFO 140162782930752] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:50 INFO 140162782930752] #quality_metric: host=algo-1, epoch=180, train loss <loss>=-1.92941705664\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:53 INFO 140162782930752] Epoch[181] Batch[0] avg_epoch_loss=-1.917115\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:05:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=-1.91711528485\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:05 INFO 140162782930752] Epoch[181] Batch[5] avg_epoch_loss=-1.907506\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:05 INFO 140162782930752] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=-1.90750569564\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:05 INFO 140162782930752] Epoch[181] Batch [5]#011Speed: 87.29 samples/sec#011loss=-1.907506\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:17 INFO 140162782930752] Epoch[181] Batch[10] avg_epoch_loss=-1.903840\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:17 INFO 140162782930752] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=-1.89944050129\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:17 INFO 140162782930752] Epoch[181] Batch [10]#011Speed: 87.48 samples/sec#011loss=-1.899441\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:17 INFO 140162782930752] processed a total of 2139 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26556.941032409668, \"sum\": 26556.941032409668, \"min\": 26556.941032409668}}, \"EndTime\": 1600225577.335395, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225550.77822}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:17 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.5436546428 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:17 INFO 140162782930752] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:17 INFO 140162782930752] #quality_metric: host=algo-1, epoch=181, train loss <loss>=-1.9038396982\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:20 INFO 140162782930752] Epoch[182] Batch[0] avg_epoch_loss=-1.911522\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:20 INFO 140162782930752] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=-1.91152191162\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:31 INFO 140162782930752] Epoch[182] Batch[5] avg_epoch_loss=-1.918086\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:31 INFO 140162782930752] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=-1.91808553842\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:31 INFO 140162782930752] Epoch[182] Batch [5]#011Speed: 87.79 samples/sec#011loss=-1.918086\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:43 INFO 140162782930752] Epoch[182] Batch[10] avg_epoch_loss=-1.917074\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:43 INFO 140162782930752] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=-1.91586118845\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:43 INFO 140162782930752] Epoch[182] Batch [10]#011Speed: 87.45 samples/sec#011loss=-1.915861\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:43 INFO 140162782930752] processed a total of 2135 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26539.37816619873, \"sum\": 26539.37816619873, \"min\": 26539.37816619873}}, \"EndTime\": 1600225603.875137, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225577.335452}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:43 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.4462062495 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:43 INFO 140162782930752] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:43 INFO 140162782930752] #quality_metric: host=algo-1, epoch=182, train loss <loss>=-1.91707447025\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:46 INFO 140162782930752] Epoch[183] Batch[0] avg_epoch_loss=-1.911141\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:46 INFO 140162782930752] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=-1.91114146893\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:58 INFO 140162782930752] Epoch[183] Batch[5] avg_epoch_loss=-1.886360\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:58 INFO 140162782930752] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=-1.88635989947\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:06:58 INFO 140162782930752] Epoch[183] Batch [5]#011Speed: 87.47 samples/sec#011loss=-1.886360\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:08 INFO 140162782930752] processed a total of 2072 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24274.957180023193, \"sum\": 24274.957180023193, \"min\": 24274.957180023193}}, \"EndTime\": 1600225628.150378, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225603.875193}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:08 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.3551039548 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:08 INFO 140162782930752] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:08 INFO 140162782930752] #quality_metric: host=algo-1, epoch=183, train loss <loss>=-1.88714783008\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:11 INFO 140162782930752] Epoch[184] Batch[0] avg_epoch_loss=-1.886917\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=-1.88691696754\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:22 INFO 140162782930752] Epoch[184] Batch[5] avg_epoch_loss=-1.903935\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:22 INFO 140162782930752] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=-1.90393494337\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:22 INFO 140162782930752] Epoch[184] Batch [5]#011Speed: 87.03 samples/sec#011loss=-1.903935\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:32 INFO 140162782930752] processed a total of 2034 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24334.394931793213, \"sum\": 24334.394931793213, \"min\": 24334.394931793213}}, \"EndTime\": 1600225652.485187, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225628.150447}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:32 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.5850202359 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:32 INFO 140162782930752] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:32 INFO 140162782930752] #quality_metric: host=algo-1, epoch=184, train loss <loss>=-1.90048439319\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:35 INFO 140162782930752] Epoch[185] Batch[0] avg_epoch_loss=-1.888849\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:35 INFO 140162782930752] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=-1.8888491117\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:47 INFO 140162782930752] Epoch[185] Batch[5] avg_epoch_loss=-1.904389\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=-1.90438864781\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:47 INFO 140162782930752] Epoch[185] Batch [5]#011Speed: 87.72 samples/sec#011loss=-1.904389\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:59 INFO 140162782930752] Epoch[185] Batch[10] avg_epoch_loss=-1.910787\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:59 INFO 140162782930752] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=-1.91846477802\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:59 INFO 140162782930752] Epoch[185] Batch [10]#011Speed: 87.37 samples/sec#011loss=-1.918465\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:59 INFO 140162782930752] processed a total of 2155 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26556.774854660034, \"sum\": 26556.774854660034, \"min\": 26556.774854660034}}, \"EndTime\": 1600225679.042414, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225652.485251}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:59 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.1466110775 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:59 INFO 140162782930752] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:07:59 INFO 140162782930752] #quality_metric: host=algo-1, epoch=185, train loss <loss>=-1.91078688882\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:01 INFO 140162782930752] Epoch[186] Batch[0] avg_epoch_loss=-1.928784\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:01 INFO 140162782930752] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=-1.92878444378\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:13 INFO 140162782930752] Epoch[186] Batch[5] avg_epoch_loss=-1.924718\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=-1.92471844111\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:13 INFO 140162782930752] Epoch[186] Batch [5]#011Speed: 87.88 samples/sec#011loss=-1.924718\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:23 INFO 140162782930752] processed a total of 2067 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24216.275930404663, \"sum\": 24216.275930404663, \"min\": 24216.275930404663}}, \"EndTime\": 1600225703.259061, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225679.042479}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:23 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.3550835204 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:23 INFO 140162782930752] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:23 INFO 140162782930752] #quality_metric: host=algo-1, epoch=186, train loss <loss>=-1.92538518172\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:26 INFO 140162782930752] Epoch[187] Batch[0] avg_epoch_loss=-1.924607\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=-1.92460735028\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:37 INFO 140162782930752] Epoch[187] Batch[5] avg_epoch_loss=-1.919448\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:37 INFO 140162782930752] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=-1.91944833902\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:37 INFO 140162782930752] Epoch[187] Batch [5]#011Speed: 87.75 samples/sec#011loss=-1.919448\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:49 INFO 140162782930752] Epoch[187] Batch[10] avg_epoch_loss=-1.923265\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:49 INFO 140162782930752] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=-1.92784450238\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:49 INFO 140162782930752] Epoch[187] Batch [10]#011Speed: 87.82 samples/sec#011loss=-1.927845\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:49 INFO 140162782930752] processed a total of 2200 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26498.056888580322, \"sum\": 26498.056888580322, \"min\": 26498.056888580322}}, \"EndTime\": 1600225729.757576, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225703.259128}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:49 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.0246516883 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:49 INFO 140162782930752] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:49 INFO 140162782930752] #quality_metric: host=algo-1, epoch=187, train loss <loss>=-1.92326477691\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:52 INFO 140162782930752] Epoch[188] Batch[0] avg_epoch_loss=-1.930073\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:08:52 INFO 140162782930752] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=-1.93007307786\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:04 INFO 140162782930752] Epoch[188] Batch[5] avg_epoch_loss=-1.924391\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:04 INFO 140162782930752] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=-1.92439145308\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:04 INFO 140162782930752] Epoch[188] Batch [5]#011Speed: 87.86 samples/sec#011loss=-1.924391\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:16 INFO 140162782930752] Epoch[188] Batch[10] avg_epoch_loss=-1.922113\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=-1.9193782513\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:16 INFO 140162782930752] Epoch[188] Batch [10]#011Speed: 88.06 samples/sec#011loss=-1.919378\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:16 INFO 140162782930752] processed a total of 2132 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26391.18003845215, \"sum\": 26391.18003845215, \"min\": 26391.18003845215}}, \"EndTime\": 1600225756.149167, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225729.757641}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:16 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.7843015682 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:16 INFO 140162782930752] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=188, train loss <loss>=-1.922112725\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:18 INFO 140162782930752] Epoch[189] Batch[0] avg_epoch_loss=-1.916801\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=-1.91680086576\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:30 INFO 140162782930752] Epoch[189] Batch[5] avg_epoch_loss=-1.919512\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:30 INFO 140162782930752] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=-1.91951235747\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:30 INFO 140162782930752] Epoch[189] Batch [5]#011Speed: 88.27 samples/sec#011loss=-1.919512\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:42 INFO 140162782930752] Epoch[189] Batch[10] avg_epoch_loss=-1.887447\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:42 INFO 140162782930752] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=-1.84896918077\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:42 INFO 140162782930752] Epoch[189] Batch [10]#011Speed: 87.91 samples/sec#011loss=-1.848969\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:42 INFO 140162782930752] processed a total of 2103 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26381.17790222168, \"sum\": 26381.17790222168, \"min\": 26381.17790222168}}, \"EndTime\": 1600225782.530622, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225756.149226}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:42 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.7156433488 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:42 INFO 140162782930752] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:42 INFO 140162782930752] #quality_metric: host=algo-1, epoch=189, train loss <loss>=-1.88744727715\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:45 INFO 140162782930752] Epoch[190] Batch[0] avg_epoch_loss=-1.908417\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:45 INFO 140162782930752] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=-1.90841660133\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:57 INFO 140162782930752] Epoch[190] Batch[5] avg_epoch_loss=-1.908323\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:57 INFO 140162782930752] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=-1.90832294562\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:09:57 INFO 140162782930752] Epoch[190] Batch [5]#011Speed: 86.64 samples/sec#011loss=-1.908323\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:09 INFO 140162782930752] Epoch[190] Batch[10] avg_epoch_loss=-1.907955\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=-1.90751401461\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:09 INFO 140162782930752] Epoch[190] Batch [10]#011Speed: 87.38 samples/sec#011loss=-1.907514\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:09 INFO 140162782930752] processed a total of 2159 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26654.73508834839, \"sum\": 26654.73508834839, \"min\": 26654.73508834839}}, \"EndTime\": 1600225809.185688, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225782.53069}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:09 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.9984865796 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:09 INFO 140162782930752] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=190, train loss <loss>=-1.90795524971\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:11 INFO 140162782930752] Epoch[191] Batch[0] avg_epoch_loss=-1.911468\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=-1.91146821242\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:23 INFO 140162782930752] Epoch[191] Batch[5] avg_epoch_loss=-1.914239\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:23 INFO 140162782930752] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=-1.91423902756\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:23 INFO 140162782930752] Epoch[191] Batch [5]#011Speed: 87.42 samples/sec#011loss=-1.914239\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:33 INFO 140162782930752] processed a total of 2065 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24167.25492477417, \"sum\": 24167.25492477417, \"min\": 24167.25492477417}}, \"EndTime\": 1600225833.353314, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225809.185747}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:33 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.4458950205 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:33 INFO 140162782930752] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=191, train loss <loss>=-1.91619964013\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:36 INFO 140162782930752] Epoch[192] Batch[0] avg_epoch_loss=-1.925128\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=-1.92512820317\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:48 INFO 140162782930752] Epoch[192] Batch[5] avg_epoch_loss=-1.928965\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:48 INFO 140162782930752] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=-1.92896544628\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:10:48 INFO 140162782930752] Epoch[192] Batch [5]#011Speed: 86.95 samples/sec#011loss=-1.928965\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:00 INFO 140162782930752] Epoch[192] Batch[10] avg_epoch_loss=-1.918480\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=-1.90589725788\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:00 INFO 140162782930752] Epoch[192] Batch [10]#011Speed: 87.07 samples/sec#011loss=-1.905897\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:00 INFO 140162782930752] processed a total of 2143 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26657.09400177002, \"sum\": 26657.09400177002, \"min\": 26657.09400177002}}, \"EndTime\": 1600225860.010782, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225833.353373}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:00 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.3910989198 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:00 INFO 140162782930752] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=192, train loss <loss>=-1.9184799061\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:02 INFO 140162782930752] Epoch[193] Batch[0] avg_epoch_loss=-1.918844\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:02 INFO 140162782930752] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=-1.91884378287\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:14 INFO 140162782930752] Epoch[193] Batch[5] avg_epoch_loss=-1.908764\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:14 INFO 140162782930752] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=-1.90876398331\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:14 INFO 140162782930752] Epoch[193] Batch [5]#011Speed: 87.40 samples/sec#011loss=-1.908764\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:26 INFO 140162782930752] Epoch[193] Batch[10] avg_epoch_loss=-1.910958\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=-1.9135899177\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:26 INFO 140162782930752] Epoch[193] Batch [10]#011Speed: 86.52 samples/sec#011loss=-1.913590\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:26 INFO 140162782930752] processed a total of 2104 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26760.071992874146, \"sum\": 26760.071992874146, \"min\": 26760.071992874146}}, \"EndTime\": 1600225886.7712, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225860.01084}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:26 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.6242485759 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:26 INFO 140162782930752] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=193, train loss <loss>=-1.91095758985\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:29 INFO 140162782930752] Epoch[194] Batch[0] avg_epoch_loss=-1.766305\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:29 INFO 140162782930752] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=-1.76630489643\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:41 INFO 140162782930752] Epoch[194] Batch[5] avg_epoch_loss=-1.791289\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:41 INFO 140162782930752] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=-1.79128901164\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:41 INFO 140162782930752] Epoch[194] Batch [5]#011Speed: 87.12 samples/sec#011loss=-1.791289\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:53 INFO 140162782930752] Epoch[194] Batch[10] avg_epoch_loss=-1.808431\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=-1.82900167612\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:53 INFO 140162782930752] Epoch[194] Batch [10]#011Speed: 87.35 samples/sec#011loss=-1.829002\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:53 INFO 140162782930752] processed a total of 2135 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26638.88692855835, \"sum\": 26638.88692855835, \"min\": 26638.88692855835}}, \"EndTime\": 1600225913.410461, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225886.771259}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:53 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.1457086809 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:53 INFO 140162782930752] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=194, train loss <loss>=-1.80843113186\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:56 INFO 140162782930752] Epoch[195] Batch[0] avg_epoch_loss=-1.890420\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:11:56 INFO 140162782930752] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=-1.89042003338\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:08 INFO 140162782930752] Epoch[195] Batch[5] avg_epoch_loss=-1.892182\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:08 INFO 140162782930752] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=-1.89218166547\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:08 INFO 140162782930752] Epoch[195] Batch [5]#011Speed: 87.11 samples/sec#011loss=-1.892182\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:19 INFO 140162782930752] Epoch[195] Batch[10] avg_epoch_loss=-1.896817\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:19 INFO 140162782930752] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=-1.90237987225\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:19 INFO 140162782930752] Epoch[195] Batch [10]#011Speed: 87.53 samples/sec#011loss=-1.902380\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:19 INFO 140162782930752] processed a total of 2099 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26573.503971099854, \"sum\": 26573.503971099854, \"min\": 26573.503971099854}}, \"EndTime\": 1600225939.984322, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225913.410523}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:19 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.9881898094 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:19 INFO 140162782930752] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:19 INFO 140162782930752] #quality_metric: host=algo-1, epoch=195, train loss <loss>=-1.89681721401\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:22 INFO 140162782930752] Epoch[196] Batch[0] avg_epoch_loss=-1.711137\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:22 INFO 140162782930752] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=-1.71113733145\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:34 INFO 140162782930752] Epoch[196] Batch[5] avg_epoch_loss=-1.772114\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=-1.77211350661\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:34 INFO 140162782930752] Epoch[196] Batch [5]#011Speed: 87.77 samples/sec#011loss=-1.772114\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:46 INFO 140162782930752] Epoch[196] Batch[10] avg_epoch_loss=-1.739944\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:46 INFO 140162782930752] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=-1.70134024987\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:46 INFO 140162782930752] Epoch[196] Batch [10]#011Speed: 85.82 samples/sec#011loss=-1.701340\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:46 INFO 140162782930752] processed a total of 2109 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26727.85186767578, \"sum\": 26727.85186767578, \"min\": 26727.85186767578}}, \"EndTime\": 1600225966.71252, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225939.984381}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:46 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.9061965699 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:46 INFO 140162782930752] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:46 INFO 140162782930752] #quality_metric: host=algo-1, epoch=196, train loss <loss>=-1.73994384446\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:49 INFO 140162782930752] Epoch[197] Batch[0] avg_epoch_loss=-1.760818\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:12:49 INFO 140162782930752] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=-1.76081848145\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:01 INFO 140162782930752] Epoch[197] Batch[5] avg_epoch_loss=-1.792294\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:01 INFO 140162782930752] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=-1.79229386648\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:01 INFO 140162782930752] Epoch[197] Batch [5]#011Speed: 87.76 samples/sec#011loss=-1.792294\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:13 INFO 140162782930752] Epoch[197] Batch[10] avg_epoch_loss=-1.776102\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=-1.75667263911\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:13 INFO 140162782930752] Epoch[197] Batch [10]#011Speed: 87.38 samples/sec#011loss=-1.756673\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:13 INFO 140162782930752] processed a total of 2181 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26571.99192047119, \"sum\": 26571.99192047119, \"min\": 26571.99192047119}}, \"EndTime\": 1600225993.284801, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225966.712577}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:13 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=82.0786391209 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:13 INFO 140162782930752] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=197, train loss <loss>=-1.77610239949\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:16 INFO 140162782930752] Epoch[198] Batch[0] avg_epoch_loss=-1.730789\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=-1.73078874441\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:27 INFO 140162782930752] Epoch[198] Batch[5] avg_epoch_loss=-1.796741\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=-1.79674087427\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:27 INFO 140162782930752] Epoch[198] Batch [5]#011Speed: 87.25 samples/sec#011loss=-1.796741\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:39 INFO 140162782930752] Epoch[198] Batch[10] avg_epoch_loss=-1.754826\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:39 INFO 140162782930752] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=-1.70452889663\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:39 INFO 140162782930752] Epoch[198] Batch [10]#011Speed: 87.76 samples/sec#011loss=-1.704529\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:39 INFO 140162782930752] processed a total of 2109 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26513.378143310547, \"sum\": 26513.378143310547, \"min\": 26513.378143310547}}, \"EndTime\": 1600226019.798472, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600225993.284861}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:39 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.5444846959 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:39 INFO 140162782930752] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:39 INFO 140162782930752] #quality_metric: host=algo-1, epoch=198, train loss <loss>=-1.75482633897\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:42 INFO 140162782930752] Epoch[199] Batch[0] avg_epoch_loss=-1.765474\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:42 INFO 140162782930752] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=-1.7654738793\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:54 INFO 140162782930752] Epoch[199] Batch[5] avg_epoch_loss=-1.807292\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=-1.80729174003\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:13:54 INFO 140162782930752] Epoch[199] Batch [5]#011Speed: 87.93 samples/sec#011loss=-1.807292\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:03 INFO 140162782930752] processed a total of 1932 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24047.96600341797, \"sum\": 24047.96600341797, \"min\": 24047.96600341797}}, \"EndTime\": 1600226043.846719, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226019.798533}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:03 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.3384464778 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:03 INFO 140162782930752] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:03 INFO 140162782930752] #quality_metric: host=algo-1, epoch=199, train loss <loss>=-1.77992817805\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:06 INFO 140162782930752] Epoch[200] Batch[0] avg_epoch_loss=-1.816807\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:06 INFO 140162782930752] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=-1.81680723337\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:18 INFO 140162782930752] Epoch[200] Batch[5] avg_epoch_loss=-1.819473\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=-1.81947307098\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:18 INFO 140162782930752] Epoch[200] Batch [5]#011Speed: 87.99 samples/sec#011loss=-1.819473\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:27 INFO 140162782930752] processed a total of 2011 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24014.82391357422, \"sum\": 24014.82391357422, \"min\": 24014.82391357422}}, \"EndTime\": 1600226067.862298, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226043.846981}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:27 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.7396368227 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:27 INFO 140162782930752] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=200, train loss <loss>=-1.83164442503\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:30 INFO 140162782930752] Epoch[201] Batch[0] avg_epoch_loss=-1.850809\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:30 INFO 140162782930752] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=-1.85080865713\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:42 INFO 140162782930752] Epoch[201] Batch[5] avg_epoch_loss=-1.873276\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:42 INFO 140162782930752] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=-1.87327617254\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:42 INFO 140162782930752] Epoch[201] Batch [5]#011Speed: 88.11 samples/sec#011loss=-1.873276\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:52 INFO 140162782930752] processed a total of 2040 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24157.027006149292, \"sum\": 24157.027006149292, \"min\": 24157.027006149292}}, \"EndTime\": 1600226092.019675, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226067.862358}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:52 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.4471318415 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:52 INFO 140162782930752] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:52 INFO 140162782930752] #quality_metric: host=algo-1, epoch=201, train loss <loss>=-1.88154512552\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:54 INFO 140162782930752] Epoch[202] Batch[0] avg_epoch_loss=-1.892645\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:14:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=-1.8926448822\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:06 INFO 140162782930752] Epoch[202] Batch[5] avg_epoch_loss=-1.906739\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:06 INFO 140162782930752] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=-1.90673930828\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:06 INFO 140162782930752] Epoch[202] Batch [5]#011Speed: 87.16 samples/sec#011loss=-1.906739\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:18 INFO 140162782930752] Epoch[202] Batch[10] avg_epoch_loss=-1.907785\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=-1.90903921861\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:18 INFO 140162782930752] Epoch[202] Batch [10]#011Speed: 87.79 samples/sec#011loss=-1.909039\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:18 INFO 140162782930752] processed a total of 2097 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26589.68997001648, \"sum\": 26589.68997001648, \"min\": 26589.68997001648}}, \"EndTime\": 1600226118.609778, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226092.019742}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:18 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.8648664052 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:18 INFO 140162782930752] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=202, train loss <loss>=-1.90778472207\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:21 INFO 140162782930752] Epoch[203] Batch[0] avg_epoch_loss=-1.911529\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:21 INFO 140162782930752] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=-1.91152880742\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:33 INFO 140162782930752] Epoch[203] Batch[5] avg_epoch_loss=-1.914348\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=-1.91434769753\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:33 INFO 140162782930752] Epoch[203] Batch [5]#011Speed: 87.80 samples/sec#011loss=-1.914348\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:45 INFO 140162782930752] Epoch[203] Batch[10] avg_epoch_loss=-1.924319\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:45 INFO 140162782930752] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=-1.93628452008\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:45 INFO 140162782930752] Epoch[203] Batch [10]#011Speed: 87.27 samples/sec#011loss=-1.936285\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:45 INFO 140162782930752] processed a total of 2096 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26551.158905029297, \"sum\": 26551.158905029297, \"min\": 26551.158905029297}}, \"EndTime\": 1600226145.161327, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226118.609849}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:45 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.9416489127 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:45 INFO 140162782930752] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:45 INFO 140162782930752] #quality_metric: host=algo-1, epoch=203, train loss <loss>=-1.9243189805\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:47 INFO 140162782930752] Epoch[204] Batch[0] avg_epoch_loss=-1.936073\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=-1.93607271635\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:59 INFO 140162782930752] Epoch[204] Batch[5] avg_epoch_loss=-1.918882\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:59 INFO 140162782930752] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=-1.91888210101\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:15:59 INFO 140162782930752] Epoch[204] Batch [5]#011Speed: 87.11 samples/sec#011loss=-1.918882\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:11 INFO 140162782930752] Epoch[204] Batch[10] avg_epoch_loss=-1.914407\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=204, batch=10 train loss <loss>=-1.90903710585\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:11 INFO 140162782930752] Epoch[204] Batch [10]#011Speed: 87.79 samples/sec#011loss=-1.909037\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:11 INFO 140162782930752] processed a total of 2089 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26525.993824005127, \"sum\": 26525.993824005127, \"min\": 26525.993824005127}}, \"EndTime\": 1600226171.687705, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226145.161393}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:11 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.7526837603 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:11 INFO 140162782930752] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=204, train loss <loss>=-1.91440710321\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:14 INFO 140162782930752] Epoch[205] Batch[0] avg_epoch_loss=-1.921762\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:14 INFO 140162782930752] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=-1.92176173284\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:26 INFO 140162782930752] Epoch[205] Batch[5] avg_epoch_loss=-1.924016\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=-1.92401594993\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:26 INFO 140162782930752] Epoch[205] Batch [5]#011Speed: 87.50 samples/sec#011loss=-1.924016\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:38 INFO 140162782930752] Epoch[205] Batch[10] avg_epoch_loss=-1.921230\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:38 INFO 140162782930752] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=-1.91788735023\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:38 INFO 140162782930752] Epoch[205] Batch [10]#011Speed: 87.64 samples/sec#011loss=-1.917887\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:38 INFO 140162782930752] processed a total of 2081 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26498.692989349365, \"sum\": 26498.692989349365, \"min\": 26498.692989349365}}, \"EndTime\": 1600226198.186693, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226171.687763}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:38 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.5319052707 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:38 INFO 140162782930752] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:38 INFO 140162782930752] #quality_metric: host=algo-1, epoch=205, train loss <loss>=-1.9212302228\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:40 INFO 140162782930752] Epoch[206] Batch[0] avg_epoch_loss=-1.921099\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:40 INFO 140162782930752] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=-1.92109929598\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:52 INFO 140162782930752] Epoch[206] Batch[5] avg_epoch_loss=-1.912623\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:52 INFO 140162782930752] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=-1.91262269631\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:16:52 INFO 140162782930752] Epoch[206] Batch [5]#011Speed: 87.56 samples/sec#011loss=-1.912623\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:02 INFO 140162782930752] processed a total of 2044 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24206.089973449707, \"sum\": 24206.089973449707, \"min\": 24206.089973449707}}, \"EndTime\": 1600226222.393139, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226198.186756}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:02 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.4410992826 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:02 INFO 140162782930752] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:02 INFO 140162782930752] #quality_metric: host=algo-1, epoch=206, train loss <loss>=-1.91337029384\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:05 INFO 140162782930752] Epoch[207] Batch[0] avg_epoch_loss=-1.911629\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:05 INFO 140162782930752] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=-1.91162857643\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:17 INFO 140162782930752] Epoch[207] Batch[5] avg_epoch_loss=-1.916954\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:17 INFO 140162782930752] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=-1.91695377154\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:17 INFO 140162782930752] Epoch[207] Batch [5]#011Speed: 86.75 samples/sec#011loss=-1.916954\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:26 INFO 140162782930752] processed a total of 1997 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24275.143146514893, \"sum\": 24275.143146514893, \"min\": 24275.143146514893}}, \"EndTime\": 1600226246.668671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226222.393244}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:26 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=82.2649125161 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:26 INFO 140162782930752] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=207, train loss <loss>=-1.92258701324\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:29 INFO 140162782930752] Epoch[208] Batch[0] avg_epoch_loss=-1.899798\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:29 INFO 140162782930752] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=-1.89979787973\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:41 INFO 140162782930752] Epoch[208] Batch[5] avg_epoch_loss=-1.916474\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:41 INFO 140162782930752] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=-1.91647431789\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:41 INFO 140162782930752] Epoch[208] Batch [5]#011Speed: 87.23 samples/sec#011loss=-1.916474\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:53 INFO 140162782930752] Epoch[208] Batch[10] avg_epoch_loss=-1.918962\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=-1.921946775\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:53 INFO 140162782930752] Epoch[208] Batch [10]#011Speed: 87.25 samples/sec#011loss=-1.921947\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:53 INFO 140162782930752] processed a total of 2085 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26600.812911987305, \"sum\": 26600.812911987305, \"min\": 26600.812911987305}}, \"EndTime\": 1600226273.269955, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226246.668728}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:53 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.3807625984 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:53 INFO 140162782930752] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=208, train loss <loss>=-1.91896179839\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:56 INFO 140162782930752] Epoch[209] Batch[0] avg_epoch_loss=-1.854581\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:17:56 INFO 140162782930752] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=-1.85458139273\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:07 INFO 140162782930752] Epoch[209] Batch[5] avg_epoch_loss=-1.895368\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=-1.89536769574\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:07 INFO 140162782930752] Epoch[209] Batch [5]#011Speed: 87.67 samples/sec#011loss=-1.895368\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:19 INFO 140162782930752] Epoch[209] Batch[10] avg_epoch_loss=-1.901027\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:19 INFO 140162782930752] #quality_metric: host=algo-1, epoch=209, batch=10 train loss <loss>=-1.90781740042\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:19 INFO 140162782930752] Epoch[209] Batch [10]#011Speed: 87.45 samples/sec#011loss=-1.907817\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:19 INFO 140162782930752] processed a total of 2134 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26534.642934799194, \"sum\": 26534.642934799194, \"min\": 26534.642934799194}}, \"EndTime\": 1600226299.804968, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226273.270026}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:19 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.4229053813 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:19 INFO 140162782930752] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:19 INFO 140162782930752] #quality_metric: host=algo-1, epoch=209, train loss <loss>=-1.90102665241\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:22 INFO 140162782930752] Epoch[210] Batch[0] avg_epoch_loss=-1.934322\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:22 INFO 140162782930752] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=-1.93432221046\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:34 INFO 140162782930752] Epoch[210] Batch[5] avg_epoch_loss=-1.917055\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=-1.91705535008\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:34 INFO 140162782930752] Epoch[210] Batch [5]#011Speed: 87.79 samples/sec#011loss=-1.917055\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:43 INFO 140162782930752] processed a total of 2061 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24139.256954193115, \"sum\": 24139.256954193115, \"min\": 24139.256954193115}}, \"EndTime\": 1600226323.944569, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226299.805027}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:43 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.3792913092 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:43 INFO 140162782930752] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:43 INFO 140162782930752] #quality_metric: host=algo-1, epoch=210, train loss <loss>=-1.91910158304\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:46 INFO 140162782930752] Epoch[211] Batch[0] avg_epoch_loss=-1.896677\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:46 INFO 140162782930752] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=-1.89667716393\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:58 INFO 140162782930752] Epoch[211] Batch[5] avg_epoch_loss=-1.923935\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:58 INFO 140162782930752] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=-1.92393542559\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:18:58 INFO 140162782930752] Epoch[211] Batch [5]#011Speed: 87.94 samples/sec#011loss=-1.923935\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:10 INFO 140162782930752] Epoch[211] Batch[10] avg_epoch_loss=-1.934091\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:10 INFO 140162782930752] #quality_metric: host=algo-1, epoch=211, batch=10 train loss <loss>=-1.94627758906\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:10 INFO 140162782930752] Epoch[211] Batch [10]#011Speed: 88.00 samples/sec#011loss=-1.946278\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:10 INFO 140162782930752] processed a total of 2114 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26407.284021377563, \"sum\": 26407.284021377563, \"min\": 26407.284021377563}}, \"EndTime\": 1600226350.352275, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226323.944631}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:10 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.053409058 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:10 INFO 140162782930752] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:10 INFO 140162782930752] #quality_metric: host=algo-1, epoch=211, train loss <loss>=-1.93409095444\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:13 INFO 140162782930752] Epoch[212] Batch[0] avg_epoch_loss=-1.922020\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=-1.92201981178\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:24 INFO 140162782930752] Epoch[212] Batch[5] avg_epoch_loss=-1.919023\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:24 INFO 140162782930752] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=-1.91902270684\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:24 INFO 140162782930752] Epoch[212] Batch [5]#011Speed: 87.95 samples/sec#011loss=-1.919023\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:36 INFO 140162782930752] Epoch[212] Batch[10] avg_epoch_loss=-1.915078\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=-1.91034440261\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:36 INFO 140162782930752] Epoch[212] Batch [10]#011Speed: 88.22 samples/sec#011loss=-1.910344\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:36 INFO 140162782930752] processed a total of 2092 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26353.880167007446, \"sum\": 26353.880167007446, \"min\": 26353.880167007446}}, \"EndTime\": 1600226376.706487, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226350.352334}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:36 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.380841585 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:36 INFO 140162782930752] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=212, train loss <loss>=-1.9150780231\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:39 INFO 140162782930752] Epoch[213] Batch[0] avg_epoch_loss=-1.932778\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:39 INFO 140162782930752] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=-1.93277843182\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:51 INFO 140162782930752] Epoch[213] Batch[5] avg_epoch_loss=-1.929663\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=-1.92966250884\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:19:51 INFO 140162782930752] Epoch[213] Batch [5]#011Speed: 87.84 samples/sec#011loss=-1.929663\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:00 INFO 140162782930752] processed a total of 2055 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24160.901069641113, \"sum\": 24160.901069641113, \"min\": 24160.901069641113}}, \"EndTime\": 1600226400.867668, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226376.706546}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:00 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.0544441337 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:00 INFO 140162782930752] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=213, train loss <loss>=-1.92347899217\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:03 INFO 140162782930752] Epoch[214] Batch[0] avg_epoch_loss=-1.918642\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:03 INFO 140162782930752] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=-1.91864233751\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:15 INFO 140162782930752] Epoch[214] Batch[5] avg_epoch_loss=-1.929259\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:15 INFO 140162782930752] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=-1.92925920242\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:15 INFO 140162782930752] Epoch[214] Batch [5]#011Speed: 87.68 samples/sec#011loss=-1.929259\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:27 INFO 140162782930752] Epoch[214] Batch[10] avg_epoch_loss=-1.923754\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=214, batch=10 train loss <loss>=-1.91714721093\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:27 INFO 140162782930752] Epoch[214] Batch [10]#011Speed: 87.12 samples/sec#011loss=-1.917147\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:27 INFO 140162782930752] processed a total of 2096 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26568.22896003723, \"sum\": 26568.22896003723, \"min\": 26568.22896003723}}, \"EndTime\": 1600226427.436267, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226400.867735}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:27 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.8909320175 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:27 INFO 140162782930752] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:27 INFO 140162782930752] #quality_metric: host=algo-1, epoch=214, train loss <loss>=-1.92375375174\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:30 INFO 140162782930752] Epoch[215] Batch[0] avg_epoch_loss=-1.923674\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:30 INFO 140162782930752] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=-1.92367406992\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:42 INFO 140162782930752] Epoch[215] Batch[5] avg_epoch_loss=-1.925092\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:42 INFO 140162782930752] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=-1.92509176792\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:42 INFO 140162782930752] Epoch[215] Batch [5]#011Speed: 87.51 samples/sec#011loss=-1.925092\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:54 INFO 140162782930752] Epoch[215] Batch[10] avg_epoch_loss=-1.930317\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=215, batch=10 train loss <loss>=-1.93658658541\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:54 INFO 140162782930752] Epoch[215] Batch [10]#011Speed: 86.75 samples/sec#011loss=-1.936587\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:54 INFO 140162782930752] processed a total of 2081 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26608.96110534668, \"sum\": 26608.96110534668, \"min\": 26608.96110534668}}, \"EndTime\": 1600226454.045589, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226427.436332}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:54 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.2064719575 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:54 INFO 140162782930752] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=215, train loss <loss>=-1.93031668496\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:56 INFO 140162782930752] Epoch[216] Batch[0] avg_epoch_loss=-1.882308\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:20:56 INFO 140162782930752] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=-1.88230822637\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:08 INFO 140162782930752] Epoch[216] Batch[5] avg_epoch_loss=-1.893991\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:08 INFO 140162782930752] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=-1.89399110354\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:08 INFO 140162782930752] Epoch[216] Batch [5]#011Speed: 86.94 samples/sec#011loss=-1.893991\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:20 INFO 140162782930752] Epoch[216] Batch[10] avg_epoch_loss=-1.898728\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:20 INFO 140162782930752] #quality_metric: host=algo-1, epoch=216, batch=10 train loss <loss>=-1.90441269508\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:20 INFO 140162782930752] Epoch[216] Batch [10]#011Speed: 87.75 samples/sec#011loss=-1.904413\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:20 INFO 140162782930752] processed a total of 2115 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26550.501108169556, \"sum\": 26550.501108169556, \"min\": 26550.501108169556}}, \"EndTime\": 1600226480.596448, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226454.045647}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:20 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.6592587893 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:20 INFO 140162782930752] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:20 INFO 140162782930752] #quality_metric: host=algo-1, epoch=216, train loss <loss>=-1.8987281906\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:23 INFO 140162782930752] Epoch[217] Batch[0] avg_epoch_loss=-1.904909\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:23 INFO 140162782930752] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=-1.90490913391\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:35 INFO 140162782930752] Epoch[217] Batch[5] avg_epoch_loss=-1.922471\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:35 INFO 140162782930752] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=-1.92247092418\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:35 INFO 140162782930752] Epoch[217] Batch [5]#011Speed: 87.77 samples/sec#011loss=-1.922471\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:47 INFO 140162782930752] Epoch[217] Batch[10] avg_epoch_loss=-1.933110\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=217, batch=10 train loss <loss>=-1.94587719257\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:47 INFO 140162782930752] Epoch[217] Batch [10]#011Speed: 87.58 samples/sec#011loss=-1.945877\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:47 INFO 140162782930752] processed a total of 2100 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26526.710987091064, \"sum\": 26526.710987091064, \"min\": 26526.710987091064}}, \"EndTime\": 1600226507.12344, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226480.596506}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:47 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.1652424685 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:47 INFO 140162782930752] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=217, train loss <loss>=-1.93311013709\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:49 INFO 140162782930752] Epoch[218] Batch[0] avg_epoch_loss=-1.935240\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:21:49 INFO 140162782930752] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=-1.93524008531\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:01 INFO 140162782930752] Epoch[218] Batch[5] avg_epoch_loss=-1.928576\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:01 INFO 140162782930752] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=-1.92857561356\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:01 INFO 140162782930752] Epoch[218] Batch [5]#011Speed: 87.51 samples/sec#011loss=-1.928576\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:13 INFO 140162782930752] Epoch[218] Batch[10] avg_epoch_loss=-1.926214\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=218, batch=10 train loss <loss>=-1.92338115986\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:13 INFO 140162782930752] Epoch[218] Batch [10]#011Speed: 86.13 samples/sec#011loss=-1.923381\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:13 INFO 140162782930752] processed a total of 2138 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26727.75888442993, \"sum\": 26727.75888442993, \"min\": 26727.75888442993}}, \"EndTime\": 1600226533.851517, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226507.123495}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:13 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.9914960918 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:13 INFO 140162782930752] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=218, train loss <loss>=-1.92621449824\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:16 INFO 140162782930752] Epoch[219] Batch[0] avg_epoch_loss=-1.919058\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=-1.91905799279\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:28 INFO 140162782930752] Epoch[219] Batch[5] avg_epoch_loss=-1.903218\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:28 INFO 140162782930752] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=-1.90321797591\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:28 INFO 140162782930752] Epoch[219] Batch [5]#011Speed: 87.37 samples/sec#011loss=-1.903218\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:37 INFO 140162782930752] processed a total of 2030 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24144.45400238037, \"sum\": 24144.45400238037, \"min\": 24144.45400238037}}, \"EndTime\": 1600226557.996251, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226533.851572}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:37 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.0769238487 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:37 INFO 140162782930752] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:37 INFO 140162782930752] #quality_metric: host=algo-1, epoch=219, train loss <loss>=-1.91127551152\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:40 INFO 140162782930752] Epoch[220] Batch[0] avg_epoch_loss=-1.911473\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:40 INFO 140162782930752] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=-1.91147334759\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:52 INFO 140162782930752] Epoch[220] Batch[5] avg_epoch_loss=-1.912214\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:52 INFO 140162782930752] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=-1.91221430363\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:22:52 INFO 140162782930752] Epoch[220] Batch [5]#011Speed: 87.26 samples/sec#011loss=-1.912214\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:02 INFO 140162782930752] processed a total of 2026 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24267.048120498657, \"sum\": 24267.048120498657, \"min\": 24267.048120498657}}, \"EndTime\": 1600226582.263798, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226557.996319}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:02 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.4873336157 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:02 INFO 140162782930752] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:02 INFO 140162782930752] #quality_metric: host=algo-1, epoch=220, train loss <loss>=-1.91899587191\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:05 INFO 140162782930752] Epoch[221] Batch[0] avg_epoch_loss=-1.925944\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:05 INFO 140162782930752] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=-1.92594410823\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:16 INFO 140162782930752] Epoch[221] Batch[5] avg_epoch_loss=-1.899093\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=-1.89909296769\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:16 INFO 140162782930752] Epoch[221] Batch [5]#011Speed: 87.72 samples/sec#011loss=-1.899093\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:28 INFO 140162782930752] Epoch[221] Batch[10] avg_epoch_loss=-1.855505\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:28 INFO 140162782930752] #quality_metric: host=algo-1, epoch=221, batch=10 train loss <loss>=-1.80319929857\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:28 INFO 140162782930752] Epoch[221] Batch [10]#011Speed: 87.50 samples/sec#011loss=-1.803199\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:28 INFO 140162782930752] processed a total of 2103 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26518.71609687805, \"sum\": 26518.71609687805, \"min\": 26518.71609687805}}, \"EndTime\": 1600226608.782938, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226582.263868}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:28 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.3022072817 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:28 INFO 140162782930752] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:28 INFO 140162782930752] #quality_metric: host=algo-1, epoch=221, train loss <loss>=-1.85550493627\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:31 INFO 140162782930752] Epoch[222] Batch[0] avg_epoch_loss=-1.888888\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:31 INFO 140162782930752] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=-1.88888813899\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:43 INFO 140162782930752] Epoch[222] Batch[5] avg_epoch_loss=-1.876346\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:43 INFO 140162782930752] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=-1.87634614798\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:43 INFO 140162782930752] Epoch[222] Batch [5]#011Speed: 86.86 samples/sec#011loss=-1.876346\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:52 INFO 140162782930752] processed a total of 2065 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24188.46893310547, \"sum\": 24188.46893310547, \"min\": 24188.46893310547}}, \"EndTime\": 1600226632.971782, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226608.782997}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:52 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.3709255525 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:52 INFO 140162782930752] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:52 INFO 140162782930752] #quality_metric: host=algo-1, epoch=222, train loss <loss>=-1.88707718482\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:55 INFO 140162782930752] Epoch[223] Batch[0] avg_epoch_loss=-1.913896\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:23:55 INFO 140162782930752] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=-1.91389626723\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:07 INFO 140162782930752] Epoch[223] Batch[5] avg_epoch_loss=-1.916251\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=-1.91625142709\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:07 INFO 140162782930752] Epoch[223] Batch [5]#011Speed: 87.98 samples/sec#011loss=-1.916251\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:19 INFO 140162782930752] Epoch[223] Batch[10] avg_epoch_loss=-1.910478\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:19 INFO 140162782930752] #quality_metric: host=algo-1, epoch=223, batch=10 train loss <loss>=-1.9035507789\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:19 INFO 140162782930752] Epoch[223] Batch [10]#011Speed: 88.00 samples/sec#011loss=-1.903551\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:19 INFO 140162782930752] processed a total of 2131 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26409.415006637573, \"sum\": 26409.415006637573, \"min\": 26409.415006637573}}, \"EndTime\": 1600226659.381535, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226632.971845}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:19 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.6906638271 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:19 INFO 140162782930752] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:19 INFO 140162782930752] #quality_metric: host=algo-1, epoch=223, train loss <loss>=-1.91047840519\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:22 INFO 140162782930752] Epoch[224] Batch[0] avg_epoch_loss=-1.921379\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:22 INFO 140162782930752] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=-1.9213786492\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:34 INFO 140162782930752] Epoch[224] Batch[5] avg_epoch_loss=-1.919740\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=-1.9197396743\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:34 INFO 140162782930752] Epoch[224] Batch [5]#011Speed: 87.15 samples/sec#011loss=-1.919740\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:43 INFO 140162782930752] processed a total of 2062 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24127.904176712036, \"sum\": 24127.904176712036, \"min\": 24127.904176712036}}, \"EndTime\": 1600226683.509902, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226659.381591}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:43 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.4603896877 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:43 INFO 140162782930752] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:43 INFO 140162782930752] #quality_metric: host=algo-1, epoch=224, train loss <loss>=-1.92234979776\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:46 INFO 140162782930752] Epoch[225] Batch[0] avg_epoch_loss=-1.934261\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:46 INFO 140162782930752] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=-1.93426102858\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:58 INFO 140162782930752] Epoch[225] Batch[5] avg_epoch_loss=-1.930482\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:58 INFO 140162782930752] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=-1.93048171508\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:24:58 INFO 140162782930752] Epoch[225] Batch [5]#011Speed: 87.08 samples/sec#011loss=-1.930482\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:07 INFO 140162782930752] processed a total of 2042 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24230.11803627014, \"sum\": 24230.11803627014, \"min\": 24230.11803627014}}, \"EndTime\": 1600226707.74053, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226683.510103}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:07 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.2749813877 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:07 INFO 140162782930752] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=225, train loss <loss>=-1.93290149982\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:10 INFO 140162782930752] Epoch[226] Batch[0] avg_epoch_loss=-1.936768\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:10 INFO 140162782930752] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=-1.93676772484\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:22 INFO 140162782930752] Epoch[226] Batch[5] avg_epoch_loss=-1.926923\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:22 INFO 140162782930752] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=-1.92692274925\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:22 INFO 140162782930752] Epoch[226] Batch [5]#011Speed: 87.69 samples/sec#011loss=-1.926923\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:34 INFO 140162782930752] Epoch[226] Batch[10] avg_epoch_loss=-1.937196\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=226, batch=10 train loss <loss>=-1.94952363234\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:34 INFO 140162782930752] Epoch[226] Batch [10]#011Speed: 87.69 samples/sec#011loss=-1.949524\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:34 INFO 140162782930752] processed a total of 2130 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26485.60380935669, \"sum\": 26485.60380935669, \"min\": 26485.60380935669}}, \"EndTime\": 1600226734.226516, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226707.740588}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:34 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.4207889796 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:34 INFO 140162782930752] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=226, train loss <loss>=-1.93719587793\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:37 INFO 140162782930752] Epoch[227] Batch[0] avg_epoch_loss=-1.924080\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:37 INFO 140162782930752] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=-1.92408004174\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:48 INFO 140162782930752] Epoch[227] Batch[5] avg_epoch_loss=-1.920902\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:48 INFO 140162782930752] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=-1.92090186095\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:48 INFO 140162782930752] Epoch[227] Batch [5]#011Speed: 87.49 samples/sec#011loss=-1.920902\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:58 INFO 140162782930752] processed a total of 2042 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24303.429126739502, \"sum\": 24303.429126739502, \"min\": 24303.429126739502}}, \"EndTime\": 1600226758.530295, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226734.226574}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:58 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.0207642152 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:58 INFO 140162782930752] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:25:58 INFO 140162782930752] #quality_metric: host=algo-1, epoch=227, train loss <loss>=-1.91268062592\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:01 INFO 140162782930752] Epoch[228] Batch[0] avg_epoch_loss=-1.898192\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:01 INFO 140162782930752] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=-1.89819159875\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:13 INFO 140162782930752] Epoch[228] Batch[5] avg_epoch_loss=-1.913952\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=-1.9139523873\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:13 INFO 140162782930752] Epoch[228] Batch [5]#011Speed: 87.01 samples/sec#011loss=-1.913952\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:25 INFO 140162782930752] Epoch[228] Batch[10] avg_epoch_loss=-1.912715\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:25 INFO 140162782930752] #quality_metric: host=algo-1, epoch=228, batch=10 train loss <loss>=-1.91122952975\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:25 INFO 140162782930752] Epoch[228] Batch [10]#011Speed: 86.94 samples/sec#011loss=-1.911230\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:25 INFO 140162782930752] processed a total of 2084 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26693.87984275818, \"sum\": 26693.87984275818, \"min\": 26693.87984275818}}, \"EndTime\": 1600226785.224587, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226758.530355}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:25 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.0700835458 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:25 INFO 140162782930752] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:25 INFO 140162782930752] #quality_metric: host=algo-1, epoch=228, train loss <loss>=-1.91271472477\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:28 INFO 140162782930752] Epoch[229] Batch[0] avg_epoch_loss=-1.944644\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:28 INFO 140162782930752] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=-1.94464390094\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:39 INFO 140162782930752] Epoch[229] Batch[5] avg_epoch_loss=-1.931716\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:39 INFO 140162782930752] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=-1.93171552511\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:39 INFO 140162782930752] Epoch[229] Batch [5]#011Speed: 87.73 samples/sec#011loss=-1.931716\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:51 INFO 140162782930752] Epoch[229] Batch[10] avg_epoch_loss=-1.904787\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=229, batch=10 train loss <loss>=-1.87247329125\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:51 INFO 140162782930752] Epoch[229] Batch [10]#011Speed: 87.41 samples/sec#011loss=-1.872473\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:51 INFO 140162782930752] processed a total of 2081 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26543.244123458862, \"sum\": 26543.244123458862, \"min\": 26543.244123458862}}, \"EndTime\": 1600226811.768152, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226785.224643}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:51 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.400121713 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:51 INFO 140162782930752] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=229, train loss <loss>=-1.90478723699\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:54 INFO 140162782930752] Epoch[230] Batch[0] avg_epoch_loss=-1.849260\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:26:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=-1.84925974332\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:06 INFO 140162782930752] Epoch[230] Batch[5] avg_epoch_loss=-1.875716\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:06 INFO 140162782930752] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=-1.8757157448\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:06 INFO 140162782930752] Epoch[230] Batch [5]#011Speed: 86.80 samples/sec#011loss=-1.875716\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:16 INFO 140162782930752] processed a total of 2066 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24262.009859085083, \"sum\": 24262.009859085083, \"min\": 24262.009859085083}}, \"EndTime\": 1600226836.030447, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226811.768209}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:16 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.1534016729 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:16 INFO 140162782930752] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=230, train loss <loss>=-1.87411642808\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:18 INFO 140162782930752] Epoch[231] Batch[0] avg_epoch_loss=-1.891504\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=-1.89150399428\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:30 INFO 140162782930752] Epoch[231] Batch[5] avg_epoch_loss=-1.886798\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:30 INFO 140162782930752] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=-1.88679800278\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:30 INFO 140162782930752] Epoch[231] Batch [5]#011Speed: 87.54 samples/sec#011loss=-1.886798\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:40 INFO 140162782930752] processed a total of 2041 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24178.409099578857, \"sum\": 24178.409099578857, \"min\": 24178.409099578857}}, \"EndTime\": 1600226860.209246, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226836.030506}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:40 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.4138456199 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:40 INFO 140162782930752] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:40 INFO 140162782930752] #quality_metric: host=algo-1, epoch=231, train loss <loss>=-1.8911958401\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:42 INFO 140162782930752] Epoch[232] Batch[0] avg_epoch_loss=-1.931469\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:42 INFO 140162782930752] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=-1.9314688169\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:54 INFO 140162782930752] Epoch[232] Batch[5] avg_epoch_loss=-1.877815\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:54 INFO 140162782930752] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=-1.87781529549\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:27:54 INFO 140162782930752] Epoch[232] Batch [5]#011Speed: 87.48 samples/sec#011loss=-1.877815\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:06 INFO 140162782930752] Epoch[232] Batch[10] avg_epoch_loss=-1.888946\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:06 INFO 140162782930752] #quality_metric: host=algo-1, epoch=232, batch=10 train loss <loss>=-1.90230340224\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:06 INFO 140162782930752] Epoch[232] Batch [10]#011Speed: 86.92 samples/sec#011loss=-1.902303\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:06 INFO 140162782930752] processed a total of 2094 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26606.913089752197, \"sum\": 26606.913089752197, \"min\": 26606.913089752197}}, \"EndTime\": 1600226886.816642, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226860.209307}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:06 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.7010672711 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:06 INFO 140162782930752] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:06 INFO 140162782930752] #quality_metric: host=algo-1, epoch=232, train loss <loss>=-1.8889462531\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:09 INFO 140162782930752] Epoch[233] Batch[0] avg_epoch_loss=-1.914950\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=-1.91495044415\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:21 INFO 140162782930752] Epoch[233] Batch[5] avg_epoch_loss=-1.891336\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:21 INFO 140162782930752] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=-1.89133612315\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:21 INFO 140162782930752] Epoch[233] Batch [5]#011Speed: 87.34 samples/sec#011loss=-1.891336\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:31 INFO 140162782930752] processed a total of 2019 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24251.44100189209, \"sum\": 24251.44100189209, \"min\": 24251.44100189209}}, \"EndTime\": 1600226911.068419, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226886.816708}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:31 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.2524689215 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:31 INFO 140162782930752] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:31 INFO 140162782930752] #quality_metric: host=algo-1, epoch=233, train loss <loss>=-1.88992636754\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:33 INFO 140162782930752] Epoch[234] Batch[0] avg_epoch_loss=-1.919121\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=-1.91912064186\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:45 INFO 140162782930752] Epoch[234] Batch[5] avg_epoch_loss=-1.913584\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:45 INFO 140162782930752] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=-1.91358419565\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:45 INFO 140162782930752] Epoch[234] Batch [5]#011Speed: 86.92 samples/sec#011loss=-1.913584\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:57 INFO 140162782930752] Epoch[234] Batch[10] avg_epoch_loss=-1.922213\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:57 INFO 140162782930752] #quality_metric: host=algo-1, epoch=234, batch=10 train loss <loss>=-1.93256800725\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:57 INFO 140162782930752] Epoch[234] Batch [10]#011Speed: 87.87 samples/sec#011loss=-1.932568\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:57 INFO 140162782930752] processed a total of 2105 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26571.155786514282, \"sum\": 26571.155786514282, \"min\": 26571.155786514282}}, \"EndTime\": 1600226937.6399, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226911.068482}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:57 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.2209953186 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:57 INFO 140162782930752] #progress_metric: host=algo-1, completed 89 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:28:57 INFO 140162782930752] #quality_metric: host=algo-1, epoch=234, train loss <loss>=-1.92221320092\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:00 INFO 140162782930752] Epoch[235] Batch[0] avg_epoch_loss=-1.725867\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=-1.72586675791\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:12 INFO 140162782930752] Epoch[235] Batch[5] avg_epoch_loss=-1.817144\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:12 INFO 140162782930752] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=-1.81714429611\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:12 INFO 140162782930752] Epoch[235] Batch [5]#011Speed: 87.74 samples/sec#011loss=-1.817144\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:24 INFO 140162782930752] Epoch[235] Batch[10] avg_epoch_loss=-1.841734\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:24 INFO 140162782930752] #quality_metric: host=algo-1, epoch=235, batch=10 train loss <loss>=-1.87124102666\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:24 INFO 140162782930752] Epoch[235] Batch [10]#011Speed: 88.13 samples/sec#011loss=-1.871241\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:24 INFO 140162782930752] processed a total of 2145 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26437.113046646118, \"sum\": 26437.113046646118, \"min\": 26437.113046646118}}, \"EndTime\": 1600226964.077287, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226937.639957}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:24 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.1356729802 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:24 INFO 140162782930752] #progress_metric: host=algo-1, completed 89 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:24 INFO 140162782930752] #quality_metric: host=algo-1, epoch=235, train loss <loss>=-1.84173371909\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:26 INFO 140162782930752] Epoch[236] Batch[0] avg_epoch_loss=-1.889231\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=-1.88923058143\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:38 INFO 140162782930752] Epoch[236] Batch[5] avg_epoch_loss=-1.886722\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:38 INFO 140162782930752] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=-1.88672224681\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:38 INFO 140162782930752] Epoch[236] Batch [5]#011Speed: 87.91 samples/sec#011loss=-1.886722\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:50 INFO 140162782930752] Epoch[236] Batch[10] avg_epoch_loss=-1.896281\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:50 INFO 140162782930752] #quality_metric: host=algo-1, epoch=236, batch=10 train loss <loss>=-1.90775123009\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:50 INFO 140162782930752] Epoch[236] Batch [10]#011Speed: 87.91 samples/sec#011loss=-1.907751\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:50 INFO 140162782930752] processed a total of 2134 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26425.016164779663, \"sum\": 26425.016164779663, \"min\": 26425.016164779663}}, \"EndTime\": 1600226990.502697, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226964.077346}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:50 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.7565349436 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:50 INFO 140162782930752] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:50 INFO 140162782930752] #quality_metric: host=algo-1, epoch=236, train loss <loss>=-1.89628087557\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:53 INFO 140162782930752] Epoch[237] Batch[0] avg_epoch_loss=-1.891277\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:29:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=-1.89127657964\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:05 INFO 140162782930752] Epoch[237] Batch[5] avg_epoch_loss=-1.911534\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:05 INFO 140162782930752] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=-1.91153396704\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:05 INFO 140162782930752] Epoch[237] Batch [5]#011Speed: 87.09 samples/sec#011loss=-1.911534\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:17 INFO 140162782930752] Epoch[237] Batch[10] avg_epoch_loss=-1.912534\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:17 INFO 140162782930752] #quality_metric: host=algo-1, epoch=237, batch=10 train loss <loss>=-1.91373464144\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:17 INFO 140162782930752] Epoch[237] Batch [10]#011Speed: 87.31 samples/sec#011loss=-1.913735\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:17 INFO 140162782930752] processed a total of 2144 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26629.607915878296, \"sum\": 26629.607915878296, \"min\": 26629.607915878296}}, \"EndTime\": 1600227017.132656, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600226990.502755}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:17 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.5116310081 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:17 INFO 140162782930752] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:17 INFO 140162782930752] #quality_metric: host=algo-1, epoch=237, train loss <loss>=-1.91253427359\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:19 INFO 140162782930752] Epoch[238] Batch[0] avg_epoch_loss=-1.882656\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:19 INFO 140162782930752] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=-1.88265551054\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:31 INFO 140162782930752] Epoch[238] Batch[5] avg_epoch_loss=-1.893404\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:31 INFO 140162782930752] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=-1.89340403141\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:31 INFO 140162782930752] Epoch[238] Batch [5]#011Speed: 87.36 samples/sec#011loss=-1.893404\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:41 INFO 140162782930752] processed a total of 2012 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24234.12299156189, \"sum\": 24234.12299156189, \"min\": 24234.12299156189}}, \"EndTime\": 1600227041.367059, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227017.132713}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:41 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.023128034 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:41 INFO 140162782930752] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:41 INFO 140162782930752] #quality_metric: host=algo-1, epoch=238, train loss <loss>=-1.89431670262\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:44 INFO 140162782930752] Epoch[239] Batch[0] avg_epoch_loss=-1.877652\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:44 INFO 140162782930752] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=-1.8776519482\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:56 INFO 140162782930752] Epoch[239] Batch[5] avg_epoch_loss=-1.908036\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:56 INFO 140162782930752] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=-1.9080362809\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:30:56 INFO 140162782930752] Epoch[239] Batch [5]#011Speed: 87.34 samples/sec#011loss=-1.908036\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:08 INFO 140162782930752] Epoch[239] Batch[10] avg_epoch_loss=-1.918670\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:08 INFO 140162782930752] #quality_metric: host=algo-1, epoch=239, batch=10 train loss <loss>=-1.93143149156\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:08 INFO 140162782930752] Epoch[239] Batch [10]#011Speed: 87.22 samples/sec#011loss=-1.931431\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:08 INFO 140162782930752] processed a total of 2129 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26636.881113052368, \"sum\": 26636.881113052368, \"min\": 26636.881113052368}}, \"EndTime\": 1600227068.004404, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227041.367118}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:08 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.9265051665 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:08 INFO 140162782930752] #progress_metric: host=algo-1, completed 91 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:08 INFO 140162782930752] #quality_metric: host=algo-1, epoch=239, train loss <loss>=-1.91867046756\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:10 INFO 140162782930752] Epoch[240] Batch[0] avg_epoch_loss=-1.914665\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:10 INFO 140162782930752] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=-1.91466463529\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:22 INFO 140162782930752] Epoch[240] Batch[5] avg_epoch_loss=-1.928093\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:22 INFO 140162782930752] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=-1.92809254084\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:22 INFO 140162782930752] Epoch[240] Batch [5]#011Speed: 87.69 samples/sec#011loss=-1.928093\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:34 INFO 140162782930752] Epoch[240] Batch[10] avg_epoch_loss=-1.913495\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=240, batch=10 train loss <loss>=-1.89597792992\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:34 INFO 140162782930752] Epoch[240] Batch [10]#011Speed: 87.30 samples/sec#011loss=-1.895978\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:34 INFO 140162782930752] processed a total of 2082 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26567.991971969604, \"sum\": 26567.991971969604, \"min\": 26567.991971969604}}, \"EndTime\": 1600227094.57269, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227068.004466}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:34 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.364729269 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:34 INFO 140162782930752] #progress_metric: host=algo-1, completed 91 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:34 INFO 140162782930752] #quality_metric: host=algo-1, epoch=240, train loss <loss>=-1.91349499042\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:37 INFO 140162782930752] Epoch[241] Batch[0] avg_epoch_loss=-1.886808\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:37 INFO 140162782930752] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=-1.88680751507\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:49 INFO 140162782930752] Epoch[241] Batch[5] avg_epoch_loss=-1.904872\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:49 INFO 140162782930752] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=-1.90487172053\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:49 INFO 140162782930752] Epoch[241] Batch [5]#011Speed: 86.94 samples/sec#011loss=-1.904872\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:58 INFO 140162782930752] processed a total of 2052 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24312.803030014038, \"sum\": 24312.803030014038, \"min\": 24312.803030014038}}, \"EndTime\": 1600227118.885815, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227094.572747}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:58 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.3993895191 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:58 INFO 140162782930752] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:31:58 INFO 140162782930752] #quality_metric: host=algo-1, epoch=241, train loss <loss>=-1.89824744004\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:01 INFO 140162782930752] Epoch[242] Batch[0] avg_epoch_loss=-1.883194\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:01 INFO 140162782930752] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=-1.88319440988\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:13 INFO 140162782930752] Epoch[242] Batch[5] avg_epoch_loss=-1.916490\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:13 INFO 140162782930752] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=-1.91649048145\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:13 INFO 140162782930752] Epoch[242] Batch [5]#011Speed: 87.58 samples/sec#011loss=-1.916490\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:25 INFO 140162782930752] Epoch[242] Batch[10] avg_epoch_loss=-1.923897\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:25 INFO 140162782930752] #quality_metric: host=algo-1, epoch=242, batch=10 train loss <loss>=-1.93278567974\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:25 INFO 140162782930752] Epoch[242] Batch [10]#011Speed: 86.11 samples/sec#011loss=-1.932786\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:25 INFO 140162782930752] processed a total of 2088 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26790.081024169922, \"sum\": 26790.081024169922, \"min\": 26790.081024169922}}, \"EndTime\": 1600227145.676372, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227118.885951}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:25 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=77.9390463321 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:25 INFO 140162782930752] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:25 INFO 140162782930752] #quality_metric: host=algo-1, epoch=242, train loss <loss>=-1.92389738977\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:28 INFO 140162782930752] Epoch[243] Batch[0] avg_epoch_loss=-1.903596\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:28 INFO 140162782930752] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=-1.90359643789\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:40 INFO 140162782930752] Epoch[243] Batch[5] avg_epoch_loss=-1.922388\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:40 INFO 140162782930752] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=-1.92238805233\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:40 INFO 140162782930752] Epoch[243] Batch [5]#011Speed: 87.51 samples/sec#011loss=-1.922388\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:49 INFO 140162782930752] processed a total of 2065 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24203.06086540222, \"sum\": 24203.06086540222, \"min\": 24203.06086540222}}, \"EndTime\": 1600227169.879715, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227145.676429}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:49 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.319480323 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:49 INFO 140162782930752] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:49 INFO 140162782930752] #quality_metric: host=algo-1, epoch=243, train loss <loss>=-1.92686795455\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:52 INFO 140162782930752] Epoch[244] Batch[0] avg_epoch_loss=-1.934960\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:32:52 INFO 140162782930752] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=-1.93495955834\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:04 INFO 140162782930752] Epoch[244] Batch[5] avg_epoch_loss=-1.931865\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:04 INFO 140162782930752] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=-1.93186488518\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:04 INFO 140162782930752] Epoch[244] Batch [5]#011Speed: 86.97 samples/sec#011loss=-1.931865\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:14 INFO 140162782930752] processed a total of 2061 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24189.81909751892, \"sum\": 24189.81909751892, \"min\": 24189.81909751892}}, \"EndTime\": 1600227194.069881, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227169.879774}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:14 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=85.200777186 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:14 INFO 140162782930752] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:14 INFO 140162782930752] #quality_metric: host=algo-1, epoch=244, train loss <loss>=-1.93265479161\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:16 INFO 140162782930752] Epoch[245] Batch[0] avg_epoch_loss=-1.933765\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:16 INFO 140162782930752] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=-1.93376511794\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:28 INFO 140162782930752] Epoch[245] Batch[5] avg_epoch_loss=-1.934139\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:28 INFO 140162782930752] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=-1.934138836\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:28 INFO 140162782930752] Epoch[245] Batch [5]#011Speed: 87.36 samples/sec#011loss=-1.934139\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:40 INFO 140162782930752] Epoch[245] Batch[10] avg_epoch_loss=-1.938974\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:40 INFO 140162782930752] #quality_metric: host=algo-1, epoch=245, batch=10 train loss <loss>=-1.9447762416\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:40 INFO 140162782930752] Epoch[245] Batch [10]#011Speed: 87.53 samples/sec#011loss=-1.944776\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:40 INFO 140162782930752] processed a total of 2081 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26556.64610862732, \"sum\": 26556.64610862732, \"min\": 26556.64610862732}}, \"EndTime\": 1600227220.626985, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227194.069945}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:40 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.360539817 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:40 INFO 140162782930752] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:40 INFO 140162782930752] #quality_metric: host=algo-1, epoch=245, train loss <loss>=-1.93897402036\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:43 INFO 140162782930752] Epoch[246] Batch[0] avg_epoch_loss=-1.921016\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:43 INFO 140162782930752] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=-1.92101595952\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:55 INFO 140162782930752] Epoch[246] Batch[5] avg_epoch_loss=-1.919342\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:55 INFO 140162782930752] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=-1.91934231\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:33:55 INFO 140162782930752] Epoch[246] Batch [5]#011Speed: 87.72 samples/sec#011loss=-1.919342\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:07 INFO 140162782930752] Epoch[246] Batch[10] avg_epoch_loss=-1.925095\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=246, batch=10 train loss <loss>=-1.93199779804\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:07 INFO 140162782930752] Epoch[246] Batch [10]#011Speed: 87.78 samples/sec#011loss=-1.931998\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:07 INFO 140162782930752] processed a total of 2081 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26442.044973373413, \"sum\": 26442.044973373413, \"min\": 26442.044973373413}}, \"EndTime\": 1600227247.069378, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227220.627039}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:07 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.700162126 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:07 INFO 140162782930752] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:07 INFO 140162782930752] #quality_metric: host=algo-1, epoch=246, train loss <loss>=-1.92509480456\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:09 INFO 140162782930752] Epoch[247] Batch[0] avg_epoch_loss=-1.914522\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=-1.91452231774\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:21 INFO 140162782930752] Epoch[247] Batch[5] avg_epoch_loss=-1.899400\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:21 INFO 140162782930752] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=-1.89939997746\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:21 INFO 140162782930752] Epoch[247] Batch [5]#011Speed: 88.02 samples/sec#011loss=-1.899400\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:33 INFO 140162782930752] Epoch[247] Batch[10] avg_epoch_loss=-1.905600\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=247, batch=10 train loss <loss>=-1.91304063063\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:33 INFO 140162782930752] Epoch[247] Batch [10]#011Speed: 87.82 samples/sec#011loss=-1.913041\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:33 INFO 140162782930752] processed a total of 2104 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26403.071880340576, \"sum\": 26403.071880340576, \"min\": 26403.071880340576}}, \"EndTime\": 1600227273.472811, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227247.069434}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:33 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.6874281873 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:33 INFO 140162782930752] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=247, train loss <loss>=-1.90560027436\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:36 INFO 140162782930752] Epoch[248] Batch[0] avg_epoch_loss=-1.908277\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=-1.908276778\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:48 INFO 140162782930752] Epoch[248] Batch[5] avg_epoch_loss=-1.904863\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:48 INFO 140162782930752] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=-1.90486306411\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:34:48 INFO 140162782930752] Epoch[248] Batch [5]#011Speed: 87.97 samples/sec#011loss=-1.904863\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:00 INFO 140162782930752] Epoch[248] Batch[10] avg_epoch_loss=-1.902635\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=248, batch=10 train loss <loss>=-1.89996032715\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:00 INFO 140162782930752] Epoch[248] Batch [10]#011Speed: 86.72 samples/sec#011loss=-1.899960\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:00 INFO 140162782930752] processed a total of 2157 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26561.149835586548, \"sum\": 26561.149835586548, \"min\": 26561.149835586548}}, \"EndTime\": 1600227300.034314, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227273.472872}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:00 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=81.2085399396 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:00 INFO 140162782930752] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:00 INFO 140162782930752] #quality_metric: host=algo-1, epoch=248, train loss <loss>=-1.90263454731\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:02 INFO 140162782930752] Epoch[249] Batch[0] avg_epoch_loss=-1.923225\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:02 INFO 140162782930752] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=-1.92322496267\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:14 INFO 140162782930752] Epoch[249] Batch[5] avg_epoch_loss=-1.917048\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:14 INFO 140162782930752] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=-1.91704847874\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:14 INFO 140162782930752] Epoch[249] Batch [5]#011Speed: 87.34 samples/sec#011loss=-1.917048\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:26 INFO 140162782930752] Epoch[249] Batch[10] avg_epoch_loss=-1.926484\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=249, batch=10 train loss <loss>=-1.93780599741\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:26 INFO 140162782930752] Epoch[249] Batch [10]#011Speed: 85.94 samples/sec#011loss=-1.937806\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:26 INFO 140162782930752] processed a total of 2111 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26957.21483230591, \"sum\": 26957.21483230591, \"min\": 26957.21483230591}}, \"EndTime\": 1600227326.991908, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227300.03438}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:26 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.3090240762 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:26 INFO 140162782930752] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=249, train loss <loss>=-1.9264837145\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:29 INFO 140162782930752] Epoch[250] Batch[0] avg_epoch_loss=-1.885910\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:29 INFO 140162782930752] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=-1.8859101809\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:41 INFO 140162782930752] Epoch[250] Batch[5] avg_epoch_loss=-1.899898\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:41 INFO 140162782930752] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=-1.899897771\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:41 INFO 140162782930752] Epoch[250] Batch [5]#011Speed: 86.92 samples/sec#011loss=-1.899898\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:51 INFO 140162782930752] processed a total of 2010 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24243.448972702026, \"sum\": 24243.448972702026, \"min\": 24243.448972702026}}, \"EndTime\": 1600227351.235775, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227326.991965}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:51 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=82.9086431941 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:51 INFO 140162782930752] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:51 INFO 140162782930752] #quality_metric: host=algo-1, epoch=250, train loss <loss>=-1.89873058613\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:53 INFO 140162782930752] Epoch[251] Batch[0] avg_epoch_loss=-1.862264\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:35:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=-1.86226375286\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:05 INFO 140162782930752] Epoch[251] Batch[5] avg_epoch_loss=-1.887998\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:05 INFO 140162782930752] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=-1.88799779843\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:05 INFO 140162782930752] Epoch[251] Batch [5]#011Speed: 86.96 samples/sec#011loss=-1.887998\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:18 INFO 140162782930752] Epoch[251] Batch[10] avg_epoch_loss=-1.894263\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=251, batch=10 train loss <loss>=-1.90178028987\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:18 INFO 140162782930752] Epoch[251] Batch [10]#011Speed: 86.19 samples/sec#011loss=-1.901780\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:18 INFO 140162782930752] processed a total of 2132 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26777.477025985718, \"sum\": 26777.477025985718, \"min\": 26777.477025985718}}, \"EndTime\": 1600227378.013738, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227351.235844}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:18 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.6188693524 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:18 INFO 140162782930752] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:18 INFO 140162782930752] #quality_metric: host=algo-1, epoch=251, train loss <loss>=-1.89426256727\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:20 INFO 140162782930752] Epoch[252] Batch[0] avg_epoch_loss=-1.923802\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:20 INFO 140162782930752] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=-1.92380156884\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:32 INFO 140162782930752] Epoch[252] Batch[5] avg_epoch_loss=-1.875145\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:32 INFO 140162782930752] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=-1.8751445917\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:32 INFO 140162782930752] Epoch[252] Batch [5]#011Speed: 87.32 samples/sec#011loss=-1.875145\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:44 INFO 140162782930752] Epoch[252] Batch[10] avg_epoch_loss=-1.886013\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:44 INFO 140162782930752] #quality_metric: host=algo-1, epoch=252, batch=10 train loss <loss>=-1.89905460064\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:44 INFO 140162782930752] Epoch[252] Batch [10]#011Speed: 87.51 samples/sec#011loss=-1.899055\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:44 INFO 140162782930752] processed a total of 2114 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26535.423040390015, \"sum\": 26535.423040390015, \"min\": 26535.423040390015}}, \"EndTime\": 1600227404.549557, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227378.013802}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:44 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.666831162 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:44 INFO 140162782930752] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:44 INFO 140162782930752] #quality_metric: host=algo-1, epoch=252, train loss <loss>=-1.88601277758\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:47 INFO 140162782930752] Epoch[253] Batch[0] avg_epoch_loss=-1.925939\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=-1.92593882634\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:59 INFO 140162782930752] Epoch[253] Batch[5] avg_epoch_loss=-1.925846\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:59 INFO 140162782930752] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=-1.9258464911\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:36:59 INFO 140162782930752] Epoch[253] Batch [5]#011Speed: 86.74 samples/sec#011loss=-1.925846\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:11 INFO 140162782930752] Epoch[253] Batch[10] avg_epoch_loss=-1.934457\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=253, batch=10 train loss <loss>=-1.94479026794\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:11 INFO 140162782930752] Epoch[253] Batch [10]#011Speed: 87.40 samples/sec#011loss=-1.944790\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:11 INFO 140162782930752] processed a total of 2139 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26721.110105514526, \"sum\": 26721.110105514526, \"min\": 26721.110105514526}}, \"EndTime\": 1600227431.271032, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227404.549613}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:11 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.0487973787 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:11 INFO 140162782930752] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:11 INFO 140162782930752] #quality_metric: host=algo-1, epoch=253, train loss <loss>=-1.93445729876\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:14 INFO 140162782930752] Epoch[254] Batch[0] avg_epoch_loss=-1.892970\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:14 INFO 140162782930752] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=-1.89296986507\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:25 INFO 140162782930752] Epoch[254] Batch[5] avg_epoch_loss=-1.897993\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:25 INFO 140162782930752] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=-1.89799345457\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:25 INFO 140162782930752] Epoch[254] Batch [5]#011Speed: 87.67 samples/sec#011loss=-1.897993\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:35 INFO 140162782930752] processed a total of 2033 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24163.743019104004, \"sum\": 24163.743019104004, \"min\": 24163.743019104004}}, \"EndTime\": 1600227455.435127, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227431.271092}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:35 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.1339992655 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:35 INFO 140162782930752] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:35 INFO 140162782930752] #quality_metric: host=algo-1, epoch=254, train loss <loss>=-1.90572031461\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:38 INFO 140162782930752] Epoch[255] Batch[0] avg_epoch_loss=-1.916507\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:38 INFO 140162782930752] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=-1.91650698735\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:50 INFO 140162782930752] Epoch[255] Batch[5] avg_epoch_loss=-1.916890\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:50 INFO 140162782930752] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=-1.91689024216\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:37:50 INFO 140162782930752] Epoch[255] Batch [5]#011Speed: 87.05 samples/sec#011loss=-1.916890\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:02 INFO 140162782930752] Epoch[255] Batch[10] avg_epoch_loss=-1.931223\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:02 INFO 140162782930752] #quality_metric: host=algo-1, epoch=255, batch=10 train loss <loss>=-1.94842185974\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:02 INFO 140162782930752] Epoch[255] Batch [10]#011Speed: 87.32 samples/sec#011loss=-1.948422\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:02 INFO 140162782930752] processed a total of 2122 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26626.14393234253, \"sum\": 26626.14393234253, \"min\": 26626.14393234253}}, \"EndTime\": 1600227482.061686, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227455.435188}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:02 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=79.6958430794 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:02 INFO 140162782930752] #progress_metric: host=algo-1, completed 97 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:02 INFO 140162782930752] #quality_metric: host=algo-1, epoch=255, train loss <loss>=-1.93122279561\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:04 INFO 140162782930752] Epoch[256] Batch[0] avg_epoch_loss=-1.916492\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:04 INFO 140162782930752] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=-1.91649172856\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:19 INFO 140162782930752] Epoch[256] Batch[5] avg_epoch_loss=-1.926525\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:19 INFO 140162782930752] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=-1.92652482253\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:19 INFO 140162782930752] Epoch[256] Batch [5]#011Speed: 73.40 samples/sec#011loss=-1.926525\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:30 INFO 140162782930752] Epoch[256] Batch[10] avg_epoch_loss=-1.939556\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:30 INFO 140162782930752] #quality_metric: host=algo-1, epoch=256, batch=10 train loss <loss>=-1.95519394508\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:30 INFO 140162782930752] Epoch[256] Batch [10]#011Speed: 87.35 samples/sec#011loss=-1.955194\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:30 INFO 140162782930752] processed a total of 2088 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 28860.602855682373, \"sum\": 28860.602855682373, \"min\": 28860.602855682373}}, \"EndTime\": 1600227510.922597, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227482.061746}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:30 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=72.347550103 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:30 INFO 140162782930752] #progress_metric: host=algo-1, completed 97 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:30 INFO 140162782930752] #quality_metric: host=algo-1, epoch=256, train loss <loss>=-1.93955624187\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:33 INFO 140162782930752] Epoch[257] Batch[0] avg_epoch_loss=-1.803821\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:33 INFO 140162782930752] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=-1.80382097684\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:45 INFO 140162782930752] Epoch[257] Batch[5] avg_epoch_loss=-1.832256\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:45 INFO 140162782930752] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=-1.83225619487\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:45 INFO 140162782930752] Epoch[257] Batch [5]#011Speed: 87.60 samples/sec#011loss=-1.832256\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:55 INFO 140162782930752] processed a total of 2045 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24130.987882614136, \"sum\": 24130.987882614136, \"min\": 24130.987882614136}}, \"EndTime\": 1600227535.05391, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227510.922652}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:55 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.7454963029 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:55 INFO 140162782930752] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:55 INFO 140162782930752] #quality_metric: host=algo-1, epoch=257, train loss <loss>=-1.83001587208\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:57 INFO 140162782930752] Epoch[258] Batch[0] avg_epoch_loss=-1.836460\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:38:57 INFO 140162782930752] #quality_metric: host=algo-1, epoch=258, batch=0 train loss <loss>=-1.83645996681\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:09 INFO 140162782930752] Epoch[258] Batch[5] avg_epoch_loss=-1.869934\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:09 INFO 140162782930752] #quality_metric: host=algo-1, epoch=258, batch=5 train loss <loss>=-1.86993422875\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:09 INFO 140162782930752] Epoch[258] Batch [5]#011Speed: 87.65 samples/sec#011loss=-1.869934\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:21 INFO 140162782930752] Epoch[258] Batch[10] avg_epoch_loss=-1.881522\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:21 INFO 140162782930752] #quality_metric: host=algo-1, epoch=258, batch=10 train loss <loss>=-1.8954267942\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:21 INFO 140162782930752] Epoch[258] Batch [10]#011Speed: 88.01 samples/sec#011loss=-1.895427\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:21 INFO 140162782930752] processed a total of 2197 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26429.378032684326, \"sum\": 26429.378032684326, \"min\": 26429.378032684326}}, \"EndTime\": 1600227561.48367, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227535.053971}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:21 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=83.1269249658 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:21 INFO 140162782930752] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:21 INFO 140162782930752] #quality_metric: host=algo-1, epoch=258, train loss <loss>=-1.8815217585\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:24 INFO 140162782930752] Epoch[259] Batch[0] avg_epoch_loss=-1.860118\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:24 INFO 140162782930752] #quality_metric: host=algo-1, epoch=259, batch=0 train loss <loss>=-1.86011813237\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:36 INFO 140162782930752] Epoch[259] Batch[5] avg_epoch_loss=-1.909725\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:36 INFO 140162782930752] #quality_metric: host=algo-1, epoch=259, batch=5 train loss <loss>=-1.90972496913\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:36 INFO 140162782930752] Epoch[259] Batch [5]#011Speed: 87.82 samples/sec#011loss=-1.909725\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:47 INFO 140162782930752] Epoch[259] Batch[10] avg_epoch_loss=-1.907290\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=259, batch=10 train loss <loss>=-1.90436803378\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:47 INFO 140162782930752] Epoch[259] Batch [10]#011Speed: 88.04 samples/sec#011loss=-1.904368\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:47 INFO 140162782930752] processed a total of 2131 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26392.79794692993, \"sum\": 26392.79794692993, \"min\": 26392.79794692993}}, \"EndTime\": 1600227587.8768, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227561.483727}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:47 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.7414385331 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:47 INFO 140162782930752] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:47 INFO 140162782930752] #quality_metric: host=algo-1, epoch=259, train loss <loss>=-1.90728999851\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:50 INFO 140162782930752] Epoch[260] Batch[0] avg_epoch_loss=-1.926167\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:39:50 INFO 140162782930752] #quality_metric: host=algo-1, epoch=260, batch=0 train loss <loss>=-1.92616697458\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:02 INFO 140162782930752] Epoch[260] Batch[5] avg_epoch_loss=-1.917772\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:02 INFO 140162782930752] #quality_metric: host=algo-1, epoch=260, batch=5 train loss <loss>=-1.91777163285\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:02 INFO 140162782930752] Epoch[260] Batch [5]#011Speed: 87.00 samples/sec#011loss=-1.917772\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:12 INFO 140162782930752] processed a total of 2056 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 24293.59197616577, \"sum\": 24293.59197616577, \"min\": 24293.59197616577}}, \"EndTime\": 1600227612.170772, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227587.876863}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:12 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=84.6310464327 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:12 INFO 140162782930752] #progress_metric: host=algo-1, completed 99 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:12 INFO 140162782930752] #quality_metric: host=algo-1, epoch=260, train loss <loss>=-1.91827294276\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:14 INFO 140162782930752] Epoch[261] Batch[0] avg_epoch_loss=-1.937029\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:14 INFO 140162782930752] #quality_metric: host=algo-1, epoch=261, batch=0 train loss <loss>=-1.93702932505\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:26 INFO 140162782930752] Epoch[261] Batch[5] avg_epoch_loss=-1.928204\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:26 INFO 140162782930752] #quality_metric: host=algo-1, epoch=261, batch=5 train loss <loss>=-1.92820372948\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:26 INFO 140162782930752] Epoch[261] Batch [5]#011Speed: 87.13 samples/sec#011loss=-1.928204\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:38 INFO 140162782930752] Epoch[261] Batch[10] avg_epoch_loss=-1.926250\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:38 INFO 140162782930752] #quality_metric: host=algo-1, epoch=261, batch=10 train loss <loss>=-1.92390582745\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:38 INFO 140162782930752] Epoch[261] Batch [10]#011Speed: 87.07 samples/sec#011loss=-1.923906\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:38 INFO 140162782930752] processed a total of 2092 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26669.329166412354, \"sum\": 26669.329166412354, \"min\": 26669.329166412354}}, \"EndTime\": 1600227638.840573, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227612.170834}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:38 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=78.4418924473 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:38 INFO 140162782930752] #progress_metric: host=algo-1, completed 99 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:38 INFO 140162782930752] #quality_metric: host=algo-1, epoch=261, train loss <loss>=-1.92625013765\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:41 INFO 140162782930752] Epoch[262] Batch[0] avg_epoch_loss=-1.879918\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:41 INFO 140162782930752] #quality_metric: host=algo-1, epoch=262, batch=0 train loss <loss>=-1.87991758493\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:53 INFO 140162782930752] Epoch[262] Batch[5] avg_epoch_loss=-1.873228\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:53 INFO 140162782930752] #quality_metric: host=algo-1, epoch=262, batch=5 train loss <loss>=-1.87322773078\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:40:53 INFO 140162782930752] Epoch[262] Batch [5]#011Speed: 87.46 samples/sec#011loss=-1.873228\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:41:05 INFO 140162782930752] Epoch[262] Batch[10] avg_epoch_loss=-1.871274\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:41:05 INFO 140162782930752] #quality_metric: host=algo-1, epoch=262, batch=10 train loss <loss>=-1.86892855718\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:41:05 INFO 140162782930752] Epoch[262] Batch [10]#011Speed: 86.50 samples/sec#011loss=-1.868929\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:41:05 INFO 140162782930752] processed a total of 2145 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 26660.79807281494, \"sum\": 26660.79807281494, \"min\": 26660.79807281494}}, \"EndTime\": 1600227665.501772, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227638.840637}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:41:05 INFO 140162782930752] #throughput_metric: host=algo-1, train throughput=80.4548289519 records/second\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:41:05 INFO 140162782930752] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:41:05 INFO 140162782930752] #quality_metric: host=algo-1, epoch=262, train loss <loss>=-1.87127356096\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:41:05 INFO 140162782930752] Final loss: -1.87127356096 (occurred at epoch 262)\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:41:05 INFO 140162782930752] #quality_metric: host=algo-1, train final_loss <loss>=-1.87127356096\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:41:05 INFO 140162782930752] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:41:05 WARNING 140162782930752] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:41:05 INFO 140162782930752] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 445.9559917449951, \"sum\": 445.9559917449951, \"min\": 445.9559917449951}}, \"EndTime\": 1600227665.948483, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227665.501864}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:41:06 INFO 140162782930752] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 697.8349685668945, \"sum\": 697.8349685668945, \"min\": 697.8349685668945}}, \"EndTime\": 1600227666.200323, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227665.948547}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:41:06 INFO 140162782930752] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:41:06 INFO 140162782930752] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 49.12996292114258, \"sum\": 49.12996292114258, \"min\": 49.12996292114258}}, \"EndTime\": 1600227666.249544, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227666.200376}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:41:06 INFO 140162782930752] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:41:06 INFO 140162782930752] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.03504753112792969, \"sum\": 0.03504753112792969, \"min\": 0.03504753112792969}}, \"EndTime\": 1600227666.250256, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227666.249587}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 111236.59706115723, \"sum\": 111236.59706115723, \"min\": 111236.59706115723}}, \"EndTime\": 1600227777.486817, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227666.250298}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:42:57 INFO 140162782930752] #test_score (algo-1, RMSE): 0.0732010508236\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:42:57 INFO 140162782930752] #test_score (algo-1, mean_absolute_QuantileLoss): 520.145909096135\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:42:57 INFO 140162782930752] #test_score (algo-1, mean_wQuantileLoss): 0.07528536800468567\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:42:57 INFO 140162782930752] #test_score (algo-1, wQuantileLoss[0.1]): 0.046358683232015425\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:42:57 INFO 140162782930752] #test_score (algo-1, wQuantileLoss[0.2]): 0.07090252464489609\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:42:57 INFO 140162782930752] #test_score (algo-1, wQuantileLoss[0.3]): 0.0863308707042872\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:42:57 INFO 140162782930752] #test_score (algo-1, wQuantileLoss[0.4]): 0.09473663681397895\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:42:57 INFO 140162782930752] #test_score (algo-1, wQuantileLoss[0.5]): 0.09672489744652435\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:42:57 INFO 140162782930752] #test_score (algo-1, wQuantileLoss[0.6]): 0.09253814621569179\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:42:57 INFO 140162782930752] #test_score (algo-1, wQuantileLoss[0.7]): 0.08246175326808738\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:42:57 INFO 140162782930752] #test_score (algo-1, wQuantileLoss[0.8]): 0.06612728187878071\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:42:57 INFO 140162782930752] #test_score (algo-1, wQuantileLoss[0.9]): 0.04138751783790918\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:42:57 INFO 140162782930752] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.0752853680047\u001b[0m\n",
      "\u001b[34m[09/16/2020 03:42:57 INFO 140162782930752] #quality_metric: host=algo-1, test RMSE <loss>=0.0732010508236\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 6846957.91888237, \"sum\": 6846957.91888237, \"min\": 6846957.91888237}, \"setuptime\": {\"count\": 1, \"max\": 7.009029388427734, \"sum\": 7.009029388427734, \"min\": 7.009029388427734}}, \"EndTime\": 1600227777.559449, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1600227777.486877}\n",
      "\u001b[0m\n",
      "Training seconds: 6894\n",
      "Billable seconds: 6894\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator.attach('forecasting-deepar-2020-09-16-01-46-26-545')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "Using already existing model: forecasting-deepar-2020-09-16-01-46-26-545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    content_type=\"application/json\")# specify that it will accept/produce JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying batch transform to `estimator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "Using already existing model: forecasting-deepar-2020-09-16-01-46-26-545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................\u001b[32m2020-09-25T16:46:36.150:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34mNo handlers could be found for logger \"root\"\u001b[0m\n",
      "\u001b[34m[09/25/2020 16:46:35 INFO 140201474492224] Estimated memory required per model 85MB.\u001b[0m\n",
      "\u001b[34m[09/25/2020 16:46:35 INFO 140201474492224] Estimated available memory 14796MB.\u001b[0m\n",
      "\u001b[34m[09/25/2020 16:46:35 INFO 140201474492224] Estimated maximum number of workers for the available memory is 173.\u001b[0m\n",
      "\u001b[34m[09/25/2020 16:46:35 INFO 140201474492224] Using 4 workers\u001b[0m\n",
      "\u001b[34m[09/25/2020 16:46:35 INFO 140201474492224] loading entry points\u001b[0m\n",
      "\u001b[34m[09/25/2020 16:46:35 INFO 140201474492224] Prediction endpoint operating in batch mode\u001b[0m\n",
      "\u001b[34m[09/25/2020 16:46:35 INFO 140201474492224] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[09/25/2020 16:46:35 INFO 140201474492224] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[09/25/2020 16:46:35 INFO 140201474492224] loaded model class model\u001b[0m\n",
      "\u001b[34m[09/25/2020 16:46:35 WARNING 140201474492224] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[09/25/2020 16:46:35 INFO 140201474492224] nvidia-smi took: 0.0252318382263 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[09/25/2020 16:46:35 INFO 140201474492224] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35mNo handlers could be found for logger \"root\"\u001b[0m\n",
      "\u001b[35m[09/25/2020 16:46:35 INFO 140201474492224] Estimated memory required per model 85MB.\u001b[0m\n",
      "\u001b[35m[09/25/2020 16:46:35 INFO 140201474492224] Estimated available memory 14796MB.\u001b[0m\n",
      "\u001b[35m[09/25/2020 16:46:35 INFO 140201474492224] Estimated maximum number of workers for the available memory is 173.\u001b[0m\n",
      "\u001b[35m[09/25/2020 16:46:35 INFO 140201474492224] Using 4 workers\u001b[0m\n",
      "\u001b[35m[09/25/2020 16:46:35 INFO 140201474492224] loading entry points\u001b[0m\n",
      "\u001b[35m[09/25/2020 16:46:35 INFO 140201474492224] Prediction endpoint operating in batch mode\u001b[0m\n",
      "\u001b[35m[09/25/2020 16:46:35 INFO 140201474492224] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[35m[09/25/2020 16:46:35 INFO 140201474492224] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[35m[09/25/2020 16:46:35 INFO 140201474492224] loaded model class model\u001b[0m\n",
      "\u001b[35m[09/25/2020 16:46:35 WARNING 140201474492224] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[09/25/2020 16:46:35 INFO 140201474492224] nvidia-smi took: 0.0252318382263 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[35m[09/25/2020 16:46:35 INFO 140201474492224] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[09/25/2020 16:46:35 INFO 140201474492224] Loading Config from /opt/ml/model/model_algo-1-config.json\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.deserialize_phase1.time\": {\"count\": 1, \"max\": 1.1560916900634766, \"sum\": 1.1560916900634766, \"min\": 1.1560916900634766}}, \"EndTime\": 1601052395.665392, \"Dimensions\": {}, \"StartTime\": 1601052395.586162}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/25/2020 16:46:35 INFO 140201474492224] Deserializing model parameters from /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[16:46:35] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.202184.0/RHEL5_64/generic-flavor/src/src/engine/engine.cc:55: MXNet start using engine: NaiveEngine\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 204.81419563293457, \"sum\": 204.81419563293457, \"min\": 204.81419563293457}}, \"EndTime\": 1601052396.063522, \"Dimensions\": {}, \"StartTime\": 1601052395.66551}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.deserialize_phase2.time\": {\"count\": 1, \"max\": 398.09107780456543, \"sum\": 398.09107780456543, \"min\": 398.09107780456543}}, \"EndTime\": 1601052396.063623, \"Dimensions\": {}, \"StartTime\": 1601052396.063603}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-09-25 16:46:36 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-09-25 16:46:36 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-09-25 16:46:36 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-09-25 16:46:36 +0000] [31] [INFO] Booting worker with pid: 31\u001b[0m\n",
      "\u001b[34m[2020-09-25 16:46:36 +0000] [32] [INFO] Booting worker with pid: 32\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0629425048828125, \"sum\": 0.0629425048828125, \"min\": 0.0629425048828125}}, \"EndTime\": 1601052396.225993, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052396.20433}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.05698204040527344, \"sum\": 0.05698204040527344, \"min\": 0.05698204040527344}}, \"EndTime\": 1601052396.228467, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052396.100238}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-09-25 16:46:36 +0000] [33] [INFO] Booting worker with pid: 33\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.05984306335449219, \"sum\": 0.05984306335449219, \"min\": 0.05984306335449219}}, \"EndTime\": 1601052396.311644, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052396.293595}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-09-25 16:46:36 +0000] [34] [INFO] Booting worker with pid: 34\u001b[0m\n",
      "\u001b[35m[09/25/2020 16:46:35 INFO 140201474492224] Loading Config from /opt/ml/model/model_algo-1-config.json\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.deserialize_phase1.time\": {\"count\": 1, \"max\": 1.1560916900634766, \"sum\": 1.1560916900634766, \"min\": 1.1560916900634766}}, \"EndTime\": 1601052395.665392, \"Dimensions\": {}, \"StartTime\": 1601052395.586162}\n",
      "\u001b[0m\n",
      "\u001b[35m[09/25/2020 16:46:35 INFO 140201474492224] Deserializing model parameters from /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[35m[16:46:35] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.202184.0/RHEL5_64/generic-flavor/src/src/engine/engine.cc:55: MXNet start using engine: NaiveEngine\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 204.81419563293457, \"sum\": 204.81419563293457, \"min\": 204.81419563293457}}, \"EndTime\": 1601052396.063522, \"Dimensions\": {}, \"StartTime\": 1601052395.66551}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.deserialize_phase2.time\": {\"count\": 1, \"max\": 398.09107780456543, \"sum\": 398.09107780456543, \"min\": 398.09107780456543}}, \"EndTime\": 1601052396.063623, \"Dimensions\": {}, \"StartTime\": 1601052396.063603}\n",
      "\u001b[0m\n",
      "\u001b[35m[2020-09-25 16:46:36 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-09-25 16:46:36 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-09-25 16:46:36 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[35m[2020-09-25 16:46:36 +0000] [31] [INFO] Booting worker with pid: 31\u001b[0m\n",
      "\u001b[35m[2020-09-25 16:46:36 +0000] [32] [INFO] Booting worker with pid: 32\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.0629425048828125, \"sum\": 0.0629425048828125, \"min\": 0.0629425048828125}}, \"EndTime\": 1601052396.225993, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052396.20433}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.05698204040527344, \"sum\": 0.05698204040527344, \"min\": 0.05698204040527344}}, \"EndTime\": 1601052396.228467, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052396.100238}\n",
      "\u001b[0m\n",
      "\u001b[35m[2020-09-25 16:46:36 +0000] [33] [INFO] Booting worker with pid: 33\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.05984306335449219, \"sum\": 0.05984306335449219, \"min\": 0.05984306335449219}}, \"EndTime\": 1601052396.311644, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052396.293595}\n",
      "\u001b[0m\n",
      "\u001b[35m[2020-09-25 16:46:36 +0000] [34] [INFO] Booting worker with pid: 34\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.06699562072753906, \"sum\": 0.06699562072753906, \"min\": 0.06699562072753906}}, \"EndTime\": 1601052396.366951, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052396.348374}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.06699562072753906, \"sum\": 0.06699562072753906, \"min\": 0.06699562072753906}}, \"EndTime\": 1601052396.366951, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052396.348374}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.331878662109375, \"sum\": 0.331878662109375, \"min\": 0.331878662109375}}, \"EndTime\": 1601052398.051103, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052396.226233}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052398.051789, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.051309}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.331878662109375, \"sum\": 0.331878662109375, \"min\": 0.331878662109375}}, \"EndTime\": 1601052398.051103, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052396.226233}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052398.051789, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.051309}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.2899169921875, \"sum\": 0.2899169921875, \"min\": 0.2899169921875}}, \"EndTime\": 1601052398.084402, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052396.228684}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052398.084753, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.084526}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.3001689910888672, \"sum\": 0.3001689910888672, \"min\": 0.3001689910888672}}, \"EndTime\": 1601052398.161471, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052396.311883}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052398.162239, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.161593}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.024080276489257812, \"sum\": 0.024080276489257812, \"min\": 0.024080276489257812}}, \"EndTime\": 1601052398.180728, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.084828}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.028133392333984375, \"sum\": 0.028133392333984375, \"min\": 0.028133392333984375}}, \"EndTime\": 1601052398.181955, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.16232}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.30803680419921875, \"sum\": 0.30803680419921875, \"min\": 0.30803680419921875}}, \"EndTime\": 1601052398.185722, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052396.367178}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052398.186203, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.185813}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.023126602172851562, \"sum\": 0.023126602172851562, \"min\": 0.023126602172851562}}, \"EndTime\": 1601052398.204656, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.052114}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.025987625122070312, \"sum\": 0.025987625122070312, \"min\": 0.025987625122070312}}, \"EndTime\": 1601052398.20545, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.186279}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.2899169921875, \"sum\": 0.2899169921875, \"min\": 0.2899169921875}}, \"EndTime\": 1601052398.084402, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052396.228684}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052398.084753, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.084526}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.3001689910888672, \"sum\": 0.3001689910888672, \"min\": 0.3001689910888672}}, \"EndTime\": 1601052398.161471, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052396.311883}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052398.162239, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.161593}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.024080276489257812, \"sum\": 0.024080276489257812, \"min\": 0.024080276489257812}}, \"EndTime\": 1601052398.180728, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.084828}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.028133392333984375, \"sum\": 0.028133392333984375, \"min\": 0.028133392333984375}}, \"EndTime\": 1601052398.181955, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.16232}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.30803680419921875, \"sum\": 0.30803680419921875, \"min\": 0.30803680419921875}}, \"EndTime\": 1601052398.185722, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052396.367178}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052398.186203, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.185813}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.023126602172851562, \"sum\": 0.023126602172851562, \"min\": 0.023126602172851562}}, \"EndTime\": 1601052398.204656, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.052114}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.025987625122070312, \"sum\": 0.025987625122070312, \"min\": 0.025987625122070312}}, \"EndTime\": 1601052398.20545, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.186279}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.3020763397216797, \"sum\": 0.3020763397216797, \"min\": 0.3020763397216797}}, \"EndTime\": 1601052399.942872, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.182044}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052399.943205, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052399.942977}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.2779960632324219, \"sum\": 0.2779960632324219, \"min\": 0.2779960632324219}}, \"EndTime\": 1601052399.961761, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.205242}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052399.96232, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052399.961914}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.3151893615722656, \"sum\": 0.3151893615722656, \"min\": 0.3151893615722656}}, \"EndTime\": 1601052399.970439, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.181149}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052399.970829, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052399.970534}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.024080276489257812, \"sum\": 0.024080276489257812, \"min\": 0.024080276489257812}}, \"EndTime\": 1601052399.974421, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052399.943261}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.29397010803222656, \"sum\": 0.29397010803222656, \"min\": 0.29397010803222656}}, \"EndTime\": 1601052399.989223, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.205555}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052399.989556, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052399.989327}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}}, \"EndTime\": 1601052399.994125, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052399.970894}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.3020763397216797, \"sum\": 0.3020763397216797, \"min\": 0.3020763397216797}}, \"EndTime\": 1601052399.942872, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.182044}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052399.943205, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052399.942977}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.2779960632324219, \"sum\": 0.2779960632324219, \"min\": 0.2779960632324219}}, \"EndTime\": 1601052399.961761, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.205242}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052399.96232, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052399.961914}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.3151893615722656, \"sum\": 0.3151893615722656, \"min\": 0.3151893615722656}}, \"EndTime\": 1601052399.970439, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.181149}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052399.970829, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052399.970534}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.024080276489257812, \"sum\": 0.024080276489257812, \"min\": 0.024080276489257812}}, \"EndTime\": 1601052399.974421, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052399.943261}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.29397010803222656, \"sum\": 0.29397010803222656, \"min\": 0.29397010803222656}}, \"EndTime\": 1601052399.989223, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052398.205555}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052399.989556, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052399.989327}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"model.evaluate.time\": {\"count\": 1, \"max\": 0.019073486328125, \"sum\": 0.019073486328125, \"min\": 0.019073486328125}}, \"EndTime\": 1601052399.994125, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052399.970894}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.1678466796875, \"sum\": 0.1678466796875, \"min\": 0.1678466796875}}, \"EndTime\": 1601052401.129568, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052399.974515}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052401.129878, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052401.129654}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.17499923706054688, \"sum\": 0.17499923706054688, \"min\": 0.17499923706054688}}, \"EndTime\": 1601052401.149793, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052399.99419}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052401.150059, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052401.149877}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.1678466796875, \"sum\": 0.1678466796875, \"min\": 0.1678466796875}}, \"EndTime\": 1601052401.129568, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052399.974515}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052401.129878, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052401.129654}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"serve.jsonlines_encoder.time\": {\"count\": 1, \"max\": 0.17499923706054688, \"sum\": 0.17499923706054688, \"min\": 0.17499923706054688}}, \"EndTime\": 1601052401.149793, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052399.99419}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601052401.150059, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"DeepARModel\"}, \"StartTime\": 1601052401.149877}\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer = estimator.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "transformer.transform(test_path, split_type='Line')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting output from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-1-560434839557/forecasting-deepar-2020-09-16-01-46-26--2020-09-25-16-41-26-900/test.json.out to json_temp_data/test.json.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $transformer.output_path $data_dir\n",
    "data = os.path.join(data_dir, 'test.json.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading model output into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_orig = pd.read_csv(data, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposing output csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_orig_transposed = predictions_orig.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing transposed csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"quantiles\":{\"0.9\":[0.4988225698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.541064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.554976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.565387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.574226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16586</th>\n",
       "      <td>0.519231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16587</th>\n",
       "      <td>0.516828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16588</th>\n",
       "      <td>0.519977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16589</th>\n",
       "      <td>0.512825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16590</th>\n",
       "      <td>0.5096415281]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16591 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0\n",
       "0      {\"quantiles\":{\"0.9\":[0.4988225698\n",
       "1                               0.541064\n",
       "2                               0.554976\n",
       "3                               0.565387\n",
       "4                               0.574226\n",
       "...                                  ...\n",
       "16586                           0.519231\n",
       "16587                           0.516828\n",
       "16588                           0.519977\n",
       "16589                           0.512825\n",
       "16590                     0.5096415281]}\n",
       "\n",
       "[16591 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predictions_orig_transposed \n",
    "#predictions.index = df_van_normal[25568:29220].index\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning CSV file (to get rid of json characters, `pd.read_json()` did not work for me. Kept getting errors, asked a mentor for help but didn't get a reponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16586</th>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16587</th>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16588</th>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16589</th>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16590</th>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16591 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0      0.49\n",
       "1      0.54\n",
       "2      0.55\n",
       "3      0.56\n",
       "4      0.57\n",
       "...     ...\n",
       "16586  0.51\n",
       "16587  0.51\n",
       "16588  0.51\n",
       "16589  0.51\n",
       "16590  0.50\n",
       "\n",
       "[16591 rows x 1 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0] = [str(x).replace('}', '') for x in predictions[0].values]\n",
    "predictions[0] = [str(x).replace('{', '') for x in predictions[0].values]\n",
    "predictions[0] = [str(x).replace('[', '') for x in predictions[0].values]\n",
    "predictions[0] = [str(x).replace(']', '') for x in predictions[0].values]\n",
    "predictions[0] = [str(x).replace('{', '') for x in predictions[0].values]\n",
    "predictions[0] = [str(x).replace('}', '') for x in predictions[0].values]\n",
    "predictions[0] = [str(x).replace(':', '') for x in predictions[0].values]\n",
    "predictions[0] = [str(x).replace('\"quantiles\"\"0.9\"', '') for x in predictions[0].values]\n",
    "predictions[0] = [str(x).replace('mean', '') for x in predictions[0].values]\n",
    "\n",
    "predictions[0] = [str(x)[0:4] for x in predictions[0].values]\n",
    "\n",
    "del predictions[0][0]\n",
    "del predictions[0][166]\n",
    "\n",
    "predictions[[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting all datapoints in the file to float (as they were converted to string when I was getting rid of json characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0] = predictions[0].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making list with all non nan values in csv file, calling it `no_nans`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_nans = []\n",
    "for i in list(predictions[0]):\n",
    "    if np.isnan(i):\n",
    "        x = 0.5\n",
    "        no_nans.append(x)\n",
    "    else:\n",
    "        no_nans.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting average MSE for all the 10 years of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019151047617197037"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = []\n",
    "for i in range(10):\n",
    "    mse.append(keras.metrics.mean_squared_error(test_series_sep[i], no_nans[i]).numpy())\n",
    "\n",
    "score = 0\n",
    "for element in mse:\n",
    "    score += element\n",
    "\n",
    "score /= 10\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final MSE: 0.01915\n",
    "\n",
    "Lower than the moving average, model ready for production, task completed, YAY!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ps: I was struggling to understand things from the course but this project cleared all my doubt. Thank you also to the Udacity Mentors for answering my many questions quickly. I couldn't have done this project without them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, thank you for marking my project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
